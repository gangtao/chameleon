I0917 02:10:16.994311     309 [logdeviced-main] main.cpp:399] main() Command line arguments: --local-log-store-path /data/store/N1:1/db --num-shards 2 --server-id gmqmmb2lfk --log-file /data/store/N1:1/log --name Node1 --config-path file:/data/store/logdevice.conf --client-thrift-api-port 39360 --gossip-port 39354 --server-thrift-api-port 39359 --test-mode true --server-to-server-port 39358 --admin-port 39355 --loglevel info --port 39352 --sequencers lazy 
I0917 02:10:16.995464     309 [logdeviced-main] main.cpp:403] main() Plugins loaded: {"Thrift client factory plugin":"built-in","ZookeeperClient factory":"built-in","ConfigSource factory":["built-in"],"PermissionChecker factory":"built-in","Build Info":"built-in","Plugin provider":["Built-in plugin provider","Static plug-in loader","Dynamic plugin loader"]}
I0917 02:10:16.996416     309 [logdeviced-main] main.cpp:405] main() server starting
I0917 02:10:16.997402     309 [logdeviced-main] main.cpp:410] main() version 99.99.99
I0917 02:10:16.998106     309 [logdeviced-main] main.cpp:418] main() asserts off (NDEBUG set)
I0917 02:10:17.000380     309 [logdeviced-main] TextConfigUpdater.cpp:56] fetchFromSource() Requesting main config "/data/store/logdevice.conf" (source: file)
I0917 02:10:17.002592     309 [logdeviced-main] TextConfigUpdater.cpp:116] onContents() Main config from file, hash = 9egjnxotid
I0917 02:10:17.175117     309 [logdeviced-main] Server.cpp:185] operator()() Updating settings from config took 171ms
I0917 02:10:17.176259     309 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 172ms, config update: 0ms, notifications: 0ms
I0917 02:10:17.177127     309 [logdeviced-main] TextConfigUpdater.cpp:306] pushServerConfig() Updated config (version: 1 - hash: 9egjnxotid)
I0917 02:10:17.177832     309 [logdeviced-main] TextConfigUpdater.cpp:397] pushLogsConfig() Ignoring changes in the 'logs' section in the config file because LogsConfigManager is ENABLED
I0917 02:10:17.178547     309 [logdeviced-main] TextConfigUpdater.cpp:174] update() Config update result: ServerConfig=updated, ZK=skipped, LogsConfig=updated
I0917 02:10:17.179472     309 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:10:17.183128     309 [logdeviced-main] NodesConfigurationInit.cpp:233] operator()() Fetching initial nodes configuration (Attempt 1)...
I0917 02:10:17.186205     318 [ld:file-ncs] NodesConfigurationInit.cpp:290] operator()() Got a NodesConfiguration of version: 5
I0917 02:10:17.187237     318 [ld:file-ncs] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:10:17.192885     309 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:10:17.193762     309 [logdeviced-main] Server.cpp:510] init() My Node ID is N1:1
I0917 02:10:17.194540     309 [logdeviced-main] Server.cpp:517] init() My version is 0
I0917 02:10:17.195397     309 [logdeviced-main] NoopTraceLogger.cpp:22] NoopTraceLogger() NOOP TraceLogger is ON, no trace samples will be published.
I0917 02:10:17.197932     309 [logdeviced-main] FileBasedVersionedConfigStore.cpp:46] stopAndJoin() FileBasedVersionedConfigStore threads stopped.
I0917 02:10:17.198726     309 [logdeviced-main] main.cpp:144] set_fd_limit() Limit on number of file descriptors is 1048576
W0917 02:10:17.199629     309 [logdeviced-main] main.cpp:192] drop_root() Running under root, but no --user command line option specified. Will keep running as root
I0917 02:10:17.202537     309 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 39352
I0917 02:10:17.205954     309 [logdeviced-main] Server.cpp:781] initListeners() Initializing a gossip listener.
I0917 02:10:17.208386     309 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 39354
I0917 02:10:17.210782     309 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 39358 (SSL)
I0917 02:10:17.211884     309 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 39362 (SSL)
I0917 02:10:17.213038     309 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 39361 (SSL)
I0917 02:10:17.238433     349 [io-stall:s0] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 0
I0917 02:10:17.242248     350 [io-stall:s1] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 1
I0917 02:10:17.242486     309 [logdeviced-main] RocksDBLogStoreConfig.cpp:162] RocksDBLogStoreConfig() LD manages flushes and all memory budgets on the node. atomic_flush is set to true.
I0917 02:10:17.257058     379 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:10:17.257673     378 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:10:17.523361     379 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000015.log.trash as trash -- OK
I0917 02:10:17.526604     378 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000015.log.trash as trash -- OK
I0917 02:10:17.532912     381 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N1:1/db/shard1/000015.log.trash
I0917 02:10:17.535192     380 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N1:1/db/shard0/000015.log.trash
I0917 02:10:17.596685     379 [ld:open-rocks1] PartitionedRocksDBStore.cpp:897] open() Shard[1] dirty ranges: []
I0917 02:10:17.597007     378 [ld:open-rocks0] PartitionedRocksDBStore.cpp:897] open() Shard[0] dirty ranges: []
I0917 02:10:17.602507     379 [ld:open-rocks1] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.000s. Read 2 records, 214 bytes. Wrote 0 records, 0 bytes.
I0917 02:10:17.604043     378 [ld:open-rocks0] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.000s. Read 2 records, 214 bytes. Wrote 0 records, 0 bytes.
I0917 02:10:17.671189     358 [rocks-high-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000021.log.trash as trash -- OK
I0917 02:10:17.676986     356 [rocks-high-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000021.log.trash as trash -- OK
I0917 02:10:17.678471     379 [ld:open-rocks1] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N1:1/db/shard1 in 419 ms
I0917 02:10:17.678834     381 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N1:1/db/shard1/000021.log.trash
I0917 02:10:17.685647     380 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N1:1/db/shard0/000021.log.trash
I0917 02:10:17.687150     378 [ld:open-rocks0] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N1:1/db/shard0 in 425 ms
I0917 02:10:17.703729     309 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:691] printDiskShardMapping() Disk -> Shard mapping: /data/store/N1:1/db/shard0 -> [0,1]
I0917 02:10:17.706666     309 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:285] init() Initialized sharded RocksDB instance at /data/store/N1:1/db with 2 shards
E0917 02:10:17.708779    1088 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState0"!
E0917 02:10:17.708779    1089 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState1"!
I0917 02:10:17.717859     309 [logdeviced-main] Server.cpp:1173] initLogStorageStateMap() Populating log storage state map successful.
E0917 02:10:17.722967     309 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:10:17.724248     309 [logdeviced-main] RecordCacheMonitorThread.cpp:27] RecordCacheMonitorThread() Record cache monitor thread started.
I0917 02:10:17.725637     309 [logdeviced-main] ClusterState.cpp:356] resizeClusterState() Cluster state size updated from 0 to 5
I0917 02:10:17.724992    1112 [ld:cache-evict] RecordCacheMonitorThread.cpp:44] threadMain() Record cache eviction thread started. Size limit is set to 4294967296 bytes.
E0917 02:10:17.728942     309 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.733606     309 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.737896     309 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.742792     309 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.754043     309 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:10:17.755962     309 [logdeviced-main] Processor.cpp:247] init() Initialized 5 workers of type GENERAL
E0917 02:10:17.758959     309 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:10:17.762390     309 [logdeviced-main] Processor.cpp:247] init() Initialized 1 workers of type FAILURE_DETECTOR
E0917 02:10:17.765179     309 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.767964     309 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.770880     309 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.774418     309 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:10:17.777363     309 [logdeviced-main] Processor.cpp:247] init() Initialized 4 workers of type BACKGROUND
I0917 02:10:17.782761     309 [logdeviced-main] FailureDetector.cpp:139] FailureDetector() Failure Detector created with instance id: 1631844617782
I0917 02:10:17.784575     309 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N0 changed from UNKNOWN to DEAD
I0917 02:10:17.785646     309 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from HEALTHY to UNHEALTHY
I0917 02:10:17.786917     309 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N1 changed from UNKNOWN to DEAD
I0917 02:10:17.788533     309 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from HEALTHY to UNHEALTHY
I0917 02:10:17.789825     309 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N2 changed from UNKNOWN to DEAD
I0917 02:10:17.791505     309 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from HEALTHY to UNHEALTHY
I0917 02:10:17.792352     309 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N3 changed from UNKNOWN to DEAD
I0917 02:10:17.794095     309 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from HEALTHY to UNHEALTHY
I0917 02:10:17.795527     309 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N4 changed from UNKNOWN to DEAD
I0917 02:10:17.801431     309 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from HEALTHY to UNHEALTHY
W0917 02:10:17.805607    1124 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 23 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967296), p :HI_PRI
W0917 02:10:17.810677    1140 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 28 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967298), p :HI_PRI
I0917 02:10:17.807034    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 1ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
W0917 02:10:17.815489    1136 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 29 msec: NODE_STATE_UPDATED (id: 4294967302), p :LO_PRI
W0917 02:10:17.817716    1136 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 32 msec: NODE_STATE_UPDATED (id: 4294967308), p :LO_PRI
W0917 02:10:17.819031    1136 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 30 msec: NODE_STATE_UPDATED (id: 4294967312), p :LO_PRI
W0917 02:10:17.820773    1136 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 32 msec: NODE_STATE_UPDATED (id: 4294967318), p :LO_PRI
W0917 02:10:17.823691    1136 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 32 msec: NODE_STATE_UPDATED (id: 4294967322), p :LO_PRI
W0917 02:10:17.826920    1136 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 35 msec: NODE_STATE_UPDATED (id: 4294967328), p :LO_PRI
W0917 02:10:17.829501    1136 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 35 msec: NODE_STATE_UPDATED (id: 4294967332), p :LO_PRI
W0917 02:10:17.830660    1136 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 36 msec: NODE_STATE_UPDATED (id: 4294967338), p :LO_PRI
I0917 02:10:17.835578     309 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:10:17.850250    1190 [ld:srv:WB0] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:10:17.851659    1190 [ld:srv:WB0] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 1ms
I0917 02:10:17.855881    1190 [ld:srv:WB0] NodesConfigurationManager.cpp:507] onProcessingFinished() Updated local nodes config to version 5...
I0917 02:10:17.857511    1107 [ld:s1:default:0] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:10:17.857531    1100 [ld:s0:default:1] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:10:17.861743    1100 [ld:s0:default:1] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 0, totaling 0 bytes.
I0917 02:10:17.859755    1107 [ld:s1:default:0] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 1, totaling 0 bytes.
I0917 02:10:17.864351     309 [logdeviced-main] Server.cpp:1319] initSequencers() Initializing FileEpochStore
I0917 02:10:17.865069     309 [logdeviced-main] Server.cpp:1398] initSequencerPlacement() using SequencerOptions::LAZY
I0917 02:10:17.866470     309 [logdeviced-main] Server.cpp:1430] initRebuildingCoordinator() Initializing EventLog RSM and RebuildingCoordinator
I0917 02:10:17.867706     309 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387903)
I0917 02:10:17.868943     309 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387903, is_server:1)
I0917 02:10:17.872170     309 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:10:17.875472     309 [logdeviced-main] Server.cpp:1467] initRebuildingCoordinator() Starting RebuildingSupervisor
I0917 02:10:17.876698     309 [logdeviced-main] Server.cpp:1480] initRebuildingCoordinator() Starting RebuildingCoordinator
I0917 02:10:17.877089    1162 [ld:srv:WG4] RebuildingSupervisor.cpp:62] init() Starting Rebuilding Supervisor
I0917 02:10:17.879570    1162 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N4 to execute in 1200s
I0917 02:10:17.880880    1162 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N3 to execute in 1200s
I0917 02:10:17.880977     309 [logdeviced-main] LogStoreMonitor.cpp:190] start() Logstore monitoring thread started.
I0917 02:10:17.881044    1201 [ld:srv:WB3] RebuildingCoordinator.cpp:309] subscribeToEventLogIfNeeded() RebuildingCoordinator did not start yet because LogsConfig is not fully loaded yet
I0917 02:10:17.882209    1162 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N2 to execute in 1200s
I0917 02:10:17.885542     309 [logdeviced-main] UnreleasedRecordDetector.cpp:106] start() Unreleased record detector thread started.
I0917 02:10:17.893051     309 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387901)
I0917 02:10:17.889173    1201 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [eventlog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:10:17.891219    1162 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N0 to execute in 1200s
I0917 02:10:17.893915     309 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387901, is_server:1)
I0917 02:10:17.895446    1201 [ld:srv:WB3] EventLogStateMachine.cpp:146] gotInitialState() Got base rebuilding set: {}
I0917 02:10:17.901155    1201 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [eventlog] Retrieving tail lsn of delta log...
W0917 02:10:17.898170    1162 [ld:srv:WG4] RebuildingSupervisor.cpp:705] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:10:17.899758     309 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:10:17.911815    1194 [ld:srv:WB1] LogsConfigManager.cpp:38] execute() Starting LogsConfigManager on Worker 1 in pool: BACKGROUND
W0917 02:10:17.908344    1201 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.019s, source: [Request: START_EVENT_LOG_READER]
I0917 02:10:17.913779    1201 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [maintenancelog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
E0917 02:10:17.908451    1149 [ld:srv:WG3] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387903. All sequencer nodes are unavailable.
I0917 02:10:17.910719    1162 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:10:17.912863    1194 [ld:srv:WB1] LogsConfigManager.cpp:165] start() Starting LogsConfig Manager RSM
I0917 02:10:17.919849    1194 [ld:srv:WB1] LogsConfigManager.cpp:206] start() Starting LogsConfig Replicated State Machine
I0917 02:10:17.914974    1201 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [maintenancelog] Retrieving tail lsn of delta log...
E0917 02:10:17.915837    1149 [ld:srv:WG3] SequencerRouter.cpp:56] operator()() Error during sequencer lookup for log 4611686018427387903 (NOSEQUENCER), reporting NOSEQUENCER.
E0917 02:10:17.923602    1149 [ld:srv:WG3] SequencerRouter.cpp:105] onFailure() Error during sequencer routing for log 4611686018427387903 (NOSEQUENCER), request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7f78b29a3028].
W0917 02:10:17.916872    1162 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.040s, source: [Request: REBUILDING_SUPERVISOR]
I0917 02:10:17.920927    1194 [ld:srv:WB1] ReplicatedStateMachine-inl.h:38] startFetchingSnapshot() [logsconfig] Using RSMSnapshotStore...
I0917 02:10:17.929353    1194 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1294] initSnapshotFetchTimer() [logsconfig] Creating timer to fetch snapshots ...
W0917 02:10:17.925464    1149 [ld:srv:WG3] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387903, rqid:25769803777, ctx:rsm, err(NOSEQUENCER)
E0917 02:10:17.928050    1162 [ld:srv:WG4] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387899. All sequencer nodes are unavailable.
W0917 02:10:17.933728    1162 [ld:srv:WG4] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387899, rqid:25769803779, ctx:rsm, err(NOSEQUENCER)
W0917 02:10:17.932375    1149 [ld:srv:WG3] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387903 (rqid:25769803777, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
I0917 02:10:17.932645     309 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server LogDevice Admin API Service will listen on port 39355
E0917 02:10:17.934818    1201 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:25769803779) for log:4611686018427387899, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:10:17.940383     309 [logdeviced-main] Server.cpp:1540] createAndAttachMaintenanceManager() Not initializing MaintenanceManager since it is disabled in settings
E0917 02:10:17.941349    1201 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:25769803777) for log:4611686018427387903, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:10:17.942321     309 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: s2s-api
I0917 02:10:17.946356     309 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server s2s-api will listen on port 39359
I0917 02:10:17.946997     309 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: c2s-api
I0917 02:10:17.948163     309 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server c2s-api will listen on port 39360
I0917 02:10:17.948995     309 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:10:17.950185     322 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:10:17.955710     309 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:10:17.958921     324 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:10:17.960223     309 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server s2s-api
I0917 02:10:17.960308    1186 [ld:srv:WF0] FailureDetector.cpp:228] startGetClusterState() Sending GET_CLUSTER_STATE to build initial FD cluster view
I0917 02:10:17.963664    1186 [ld:srv:WF0] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket N3:1(127.0.0.1:39332) hit error AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused)
I0917 02:10:17.965909    1186 [ld:srv:WF0] GET_CLUSTER_STATE_Message.cpp:49] onReceived() Failure detector is not ready
W0917 02:10:17.975692    1186 [ld:srv:WF0] GetClusterStateRequest.cpp:289] onReply() Could not retrieve the state of the cluster from WF0:N4:1 (127.0.0.1:39321): NOTREADY: operation cannot be processed at this time
I0917 02:10:17.976518    1186 [ld:srv:WF0] GetClusterStateRequest.cpp:252] onError() Retrieving the state of the cluster failed. sending another wave.
W0917 02:10:17.988372    1186 [ld:srv:WF0] GetClusterStateRequest.cpp:289] onReply() Could not retrieve the state of the cluster from WF0:N2:1 (127.0.0.1:39343): NOTREADY: operation cannot be processed at this time
E0917 02:10:17.989910    1186 [ld:srv:WF0] GetClusterStateRequest.cpp:243] onError() Retrieving the state of the cluster failed. giving up.
E0917 02:10:17.990886    1186 [ld:srv:WF0] FailureDetector.cpp:243] operator()() Unable to refresh cluster state: FAILED: request failed
I0917 02:10:17.990821     309 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server c2s-api
I0917 02:10:17.991634    1186 [ld:srv:WF0] FailureDetector.cpp:288] buildInitialState() Wait over
I0917 02:10:17.993573    1186 [ld:srv:WF0] FailureDetector.cpp:344] buildInitialState() Initializing DomainIsolationChecker
I0917 02:10:17.994414    1186 [ld:srv:WF0] FailureDetector.cpp:915] startSuspectTimer() Starting suspect state timer
I0917 02:10:17.995260    1186 [ld:srv:WF0] FailureDetector.cpp:1285] updateNodeState() N1 transitioned from DEAD to ALIVE, FD State:(gossip: 0, instance-id: 0, failover: 0, starting: 1)
I0917 02:10:17.996468    1186 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N1 changed from DEAD to STARTING
I0917 02:10:17.998049    1186 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting suspect-state-finished message.
I0917 02:10:17.998839    1186 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844617782 to node WF0:N4:1 (127.0.0.1:39321)
I0917 02:10:17.999677    1186 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844617782 to node WF0:N3:1 (127.0.0.1:39332)
I0917 02:10:18.001545    1186 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting bringup message.
I0917 02:10:18.005498    1186 [ld:srv:WF0] FailureDetector.cpp:937] startGossiping() Start Gossiping.
I0917 02:10:18.007403    1186 [ld:srv:WF0] FailureDetector.cpp:925] operator()() Suspect timeout expired
I0917 02:10:18.009643    1186 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N4:1 with instance id:1631844617777, sent_time:1631844617994ms
I0917 02:10:18.008713     309 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server LogDevice Admin API Service
I0917 02:10:18.010782    1186 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from DEAD to STARTING
I0917 02:10:18.013132    1162 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N4
I0917 02:10:18.013198    1186 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N4 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844617777, failover: 0, starting: 1)
I0917 02:10:18.015057    1186 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N4:1 with instance id:1631844617777, sent_time:1631844617996ms
I0917 02:10:18.016087    1186 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N4
I0917 02:10:18.033359     309 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:10:18.036673     327 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:10:18.038093     309 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:10:18.039544     322 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:10:18.042167    1186 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N2:1 with instance id:1631844617789, sent_time:1631844618032ms
I0917 02:10:18.041169     309 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:10:18.046330    1186 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from DEAD to STARTING
I0917 02:10:18.048162     322 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:10:18.050466    1186 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N2 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844617789, failover: 0, starting: 1)
I0917 02:10:18.050557    1162 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N2
I0917 02:10:18.051652     309 [logdeviced-main] main.cpp:464] main() Listeners initialized
I0917 02:10:18.052103    1186 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N2:1 with instance id:1631844617789, sent_time:1631844618035ms
I0917 02:10:18.055635    1186 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N2
I0917 02:10:18.083215    1186 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N3:1 with instance id:1631844617866, sent_time:1631844618047ms
I0917 02:10:18.084447    1186 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N3 changed from DEAD to STARTING
I0917 02:10:18.085733    1186 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N3 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844617866, failover: 0, starting: 1)
I0917 02:10:18.085905    1162 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N3
I0917 02:10:18.086480    1186 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N3
W0917 02:10:18.087232    1162 [ld:srv:WG4] RebuildingSupervisor.cpp:734] adjustRebuildingThrottle() Exiting throttling mode: #draining=0, #rebuilding=0, #triggers=1, #adjusted cluster size=5, threshold=35%, actual=20%
I0917 02:10:18.089414    1162 [ld:srv:WG4] RebuildingSupervisor.cpp:751] adjustRebuildingThrottle() Not triggering new rebuildings until 2021-09-17 02:30:18.089: It's too soon after exiting throttling mode
I0917 02:10:18.108434    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from UNHEALTHY to UNDEFINED
I0917 02:10:18.161618    1186 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from DEAD to STARTING
I0917 02:10:18.165803    1186 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N0 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844617844, failover: 0, starting: 1)
I0917 02:10:18.165977    1162 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N0
I0917 02:10:18.167701    1186 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N0
I0917 02:10:18.212210    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from UNHEALTHY to UNDEFINED
I0917 02:10:18.212930    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from UNHEALTHY to UNDEFINED
I0917 02:10:18.213418    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from UNHEALTHY to UNDEFINED
I0917 02:10:18.315460    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from UNHEALTHY to UNDEFINED
I0917 02:10:18.492984    1136 [ld:srv:WG1] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG1:C5 (127.0.0.1:59968)
I0917 02:10:18.497609    1136 [ld:srv:WG1] Connection.cpp:724] close() Closing socket C5(127.0.0.1:59968). Reason: PEER_CLOSED: connection closed by peer
I0917 02:10:18.521212    1099 [ld:s0:default:0] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 4611686018427387900 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:18.527461    1100 [ld:s0:default:1] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 13835058055282163708 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:18.625899    1162 [ld:srv:WG4] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 13835058055282163708 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:18.647989    1162 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387900 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:18.741086    1162 [ld:srv:WG4] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [0, 0] for log 4611686018427387900.
I0917 02:10:18.933107    1194 [ld:srv:WB1] ReplicatedStateMachine-inl.h:130] getSnapshot() [logsconfig] Fetching snapshot with ver:e0n1, (waiting_for_snapshot_:LSN_INVALID, version_:e0n1). sync_state_:0
I0917 02:10:18.935204    1194 [ld:srv:WB1] LogBasedRSMSnapshotStore.cpp:298] onGotLastReleased() Returning EMPTY for log:4611686018427387900, last_released_real_lsn:LSN_INVALID
I0917 02:10:18.935893    1194 [ld:srv:WB1] ReplicatedStateMachine-inl.h:83] operator()() [logsconfig] getSnapshot()'s callback. st:EMPTY, snapshot blob size:0, attrs:(base_ver:LSN_INVALID, ts:0)
I0917 02:10:18.936464    1194 [ld:srv:WB1] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [logsconfig] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:10:18.937081    1194 [ld:srv:WB1] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [logsconfig] Retrieving tail lsn of delta log...
I0917 02:10:18.943296    1136 [ld:srv:WG1] GET_SEQ_STATE_Message.cpp:238] getSequencer() Sequencer for log:4611686018427387899 is absent, state=UNAVAILABLE, cur_epoch=0, attempting to activate it upon receiving GSS (rqid:25769803780, ctx:rsm, min_epoch:none) from WG1:C12 (127.0.0.1:60046)
I0917 02:10:18.943828    1124 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:238] getSequencer() Sequencer for log:4611686018427387899 is absent, state=UNAVAILABLE, cur_epoch=0, attempting to activate it upon receiving GSS (rqid:25769803780, ctx:rsm, min_epoch:none) from WG0:C13 (127.0.0.1:60048)
I0917 02:10:18.944463    1124 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387899, rqid:25769803780, ctx:rsm) from WG0:C13 (127.0.0.1:60048), but its data log sequencer's state is ACTIVATING
I0917 02:10:18.958602    1136 [ld:srv:WG1] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387899, rqid:25769803780, ctx:rsm) from WG1:C12 (127.0.0.1:60046), but its data log sequencer's state is ACTIVATING
W0917 02:10:18.959860    1136 [ld:srv:WG1] Worker.cpp:1000] onStoppedRunning() skipped at least 4 log entries
W0917 02:10:18.961981    1136 [ld:srv:WG1] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.017s, source: [Message sent/received: GET_SEQ_STATE]
I0917 02:10:18.963407    1136 [ld:srv:WG1] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 4611686018427387899 epoch 2.
I0917 02:10:18.964676    1136 [ld:srv:WG1] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 4611686018427387899: {[E:1 (at 2021-09-17 02:10:18.949) since:1 (at 2021-09-17 02:10:15.170) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S1,N1:S1,N2:S1,N3:S1,N4:S1} W:[]], Until:2}.
I0917 02:10:18.965603    1136 [ld:srv:WG1] AllSequencers.cpp:527] onEpochMetaDataFromEpochStore() Activated a sequencer for log 4611686018427387899 (reason: GET_SEQ_STATE) with epoch 2, metadata: [E:2 (at 2021-09-17 02:10:18.949) since:1 (at 2021-09-17 02:10:15.170) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S1,N1:S1,N2:S1,N3:S1,N4:S1} W:[]]. Activation Result: RECOVERY.
I0917 02:10:18.968592    1162 [ld:srv:WG4] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 4611686018427387899 with next_epoch 2
I0917 02:10:18.965690    1124 [ld:srv:WG0] PeriodicReleases.cpp:416] execute() Start broadcasting releases for log 4611686018427387899.
I0917 02:10:18.968831    1136 [ld:srv:WG1] MetaDataLogTrimmer.cpp:115] schedulePeriodicTrimming() Will run periodic trimming every ~7200000 s for 4611686018427387899
I0917 02:10:18.968941    1140 [ld:srv:WG2] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 13835058055282163707 epoch 2.
I0917 02:10:18.976064    1140 [ld:srv:WG2] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 13835058055282163707: {[E:1 (at -inf) since:1 (at -inf) R:[node: 3] V:2 flags: params:{target:0 seed:0 signature:0} N:{N0:S1,N1:S1,N2:S1,N3:S1,N4:S1} W:[]], Until:2}.
I0917 02:10:18.977491    1140 [ld:srv:WG2] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 13835058055282163707 with next_epoch 2
I0917 02:10:18.978123    1162 [ld:srv:WG4] LogRecoveryRequest.cpp:1013] sealLog() Starting recovery of epoch 1 of log 4611686018427387899
W0917 02:10:18.988077    1140 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.011s, source: [Request: LOG_RECOVERY]
I0917 02:10:18.991119    1140 [ld:srv:WG2] LogRecoveryRequest.cpp:1013] sealLog() Starting recovery of epoch 1 of log 13835058055282163707
I0917 02:10:19.014974    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:10:19.019084    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:10:19.023833    1140 [ld:srv:WG2] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:13835058055282163707, rqid:81604378627, ctx:start-message) from WG2:C23 (127.0.0.1:60138), but its data log sequencer's state is Recovery Incomplete
I0917 02:10:19.027119    1140 [ld:srv:WG2] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:13835058055282163707, rqid:17179869185, ctx:start-message) from WG2:C24 (127.0.0.1:60140), but its data log sequencer's state is Recovery Incomplete
I0917 02:10:19.030387    1140 [ld:srv:WG2] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:13835058055282163707, rqid:64424509479, ctx:start-message) from WG2:C15 (127.0.0.1:60060), but its data log sequencer's state is Recovery Incomplete
I0917 02:10:19.092506    1149 [ld:srv:WG3] RecordCache.cpp:257] getEpochRecordCache() skipped at least 10 log entries
I0917 02:10:19.094092    1149 [ld:srv:WG3] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 13835058055282163711 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:19.096421    1149 [ld:srv:WG3] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 13835058055282163709 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
E0917 02:10:19.096540    1140 [ld:srv:WG2] EpochRecovery.cpp:394] onDigestComplete() All SEALED messages contained zero last_timestamp for a nonempty epoch (recovery: epoch 1 of log 13835058055282163707). This is unexpected, please investigate. Using current time instead. Log: 13835058055282163707, lng: 1.
I0917 02:10:19.101893    1140 [ld:srv:WG2] EpochRecovery.cpp:566] startMutations() Log 13835058055282163707 epoch 1 final digest before mutation: consensus LNG 1, start esn: 2, 0 entries, first esn: 0, last esn: 0, bridge esn: 2, tail esn: 1, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S1, N1:S1, N2:S1, N3:S1, N4:S1}, last timestamp: 2021-09-17 02:10:19.096, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163707 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:13835058055282163707 N:e1n1 T:0 OM:{} F:528], final tail record: [L:13835058055282163707 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {m:N0:S1,N1:S1,N2:S1,N3:S1,N4:S1 MUTATION}.
I0917 02:10:19.103795    1162 [ld:srv:WG4] EpochRecovery.cpp:566] startMutations() Log 4611686018427387899 epoch 1 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S1, N1:S1, N2:S1, N3:S1, N4:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {m:N0:S1,N1:S1,N2:S1,N3:S1,N4:S1 MUTATION}.
I0917 02:10:19.105959    1124 [ld:srv:WG0] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 13835058055282163707 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:19.112209    1162 [ld:srv:WG4] Mutator.cpp:400] finalize() Mutator 4611686018427387899e1n1 completed (OK). Trace: W1{N1:S1,N4:S1};X:N1:S1:K;X:N4:S1:K;Y1:N4:S1:K;Y1:N1:S1:K;done:can_replicate:OK;
I0917 02:10:19.114569    1136 [ld:srv:WG1] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.126047    1140 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387901 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.136480    1124 [ld:srv:WG0] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387903 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.219850    1140 [ld:srv:WG2] Mutator.cpp:400] finalize() Mutator 13835058055282163707e1n2 completed (OK). Trace: W1{N3:S1,N1:S1,N0:S1};X:N3:S1:K;X:N1:S1:K;X:N0:S1:K;Y1:N3:S1:K;Y1:N1:S1:K;Y1:N0:S1:K;done:can_replicate:OK;
I0917 02:10:19.222107    1124 [ld:srv:WG0] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163707 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.332783    1162 [ld:srv:WG4] LogRecoveryRequest.cpp:1463] complete() Log recovery completed for log 4611686018427387899, next_epoch:2
I0917 02:10:19.432372    1140 [ld:srv:WG2] LogRecoveryRequest.cpp:1463] complete() Log recovery completed for log 13835058055282163707, next_epoch:2
I0917 02:10:19.436781    1186 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from STARTING to FULLY_STARTED
I0917 02:10:19.526943    1124 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:238] getSequencer() Sequencer for log:4611686018427387898 is absent, state=UNAVAILABLE, cur_epoch=0, attempting to activate it upon receiving GSS (rqid:30064771076, ctx:historical-metadata, min_epoch:none) from WG0:C31 (127.0.0.1:60200)
I0917 02:10:19.537077    1124 [ld:srv:WG0] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 4611686018427387898 epoch 2.
I0917 02:10:19.538020    1124 [ld:srv:WG0] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 4611686018427387898: {[E:1 (at 2021-09-17 02:10:19.531) since:1 (at 2021-09-17 02:10:14.514) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S0,N1:S0,N2:S0,N3:S0,N4:S0} W:[]], Until:2}.
I0917 02:10:19.539143    1124 [ld:srv:WG0] AllSequencers.cpp:527] onEpochMetaDataFromEpochStore() Activated a sequencer for log 4611686018427387898 (reason: GET_SEQ_STATE) with epoch 2, metadata: [E:2 (at 2021-09-17 02:10:19.531) since:1 (at 2021-09-17 02:10:14.514) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S0,N1:S0,N2:S0,N3:S0,N4:S0} W:[]]. Activation Result: RECOVERY.
I0917 02:10:19.539377    1186 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from STARTING to FULLY_STARTED
I0917 02:10:19.540388    1136 [ld:srv:WG1] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 13835058055282163706 epoch 2.
I0917 02:10:19.540758    1124 [ld:srv:WG0] PeriodicReleases.cpp:416] execute() Start broadcasting releases for log 4611686018427387898.
I0917 02:10:19.542631    1136 [ld:srv:WG1] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 13835058055282163706: {[E:1 (at -inf) since:1 (at -inf) R:[node: 3] V:2 flags: params:{target:0 seed:0 signature:0} N:{N0:S0,N1:S0,N2:S0,N3:S0,N4:S0} W:[]], Until:2}.
I0917 02:10:19.543483    1124 [ld:srv:WG0] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 4611686018427387898 with next_epoch 2
I0917 02:10:19.543908    1136 [ld:srv:WG1] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 13835058055282163706 with next_epoch 2
I0917 02:10:19.547912    1124 [ld:srv:WG0] LogRecoveryRequest.cpp:1013] sealLog() Starting recovery of epoch 1 of log 4611686018427387898
I0917 02:10:19.550384    1136 [ld:srv:WG1] LogRecoveryRequest.cpp:1013] sealLog() Starting recovery of epoch 1 of log 13835058055282163706
I0917 02:10:19.572639    1136 [ld:srv:WG1] Connection.cpp:724] close() Closing socket C9(127.0.0.1:60002). Reason: PEER_CLOSED: connection closed by peer
I0917 02:10:19.643448    1186 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N3 changed from STARTING to FULLY_STARTED
I0917 02:10:19.663520    1124 [ld:srv:WG0] EpochRecovery.cpp:566] startMutations() Log 4611686018427387898 epoch 1 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S0, N1:S0, N2:S0, N3:S0, N4:S0}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387898 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387898 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {m:N0:S0,N1:S0,N2:S0,N3:S0,N4:S0 MUTATION}.
E0917 02:10:19.663542    1136 [ld:srv:WG1] EpochRecovery.cpp:394] onDigestComplete() All SEALED messages contained zero last_timestamp for a nonempty epoch (recovery: epoch 1 of log 13835058055282163706). This is unexpected, please investigate. Using current time instead. Log: 13835058055282163706, lng: 1.
I0917 02:10:19.665168    1136 [ld:srv:WG1] EpochRecovery.cpp:566] startMutations() Log 13835058055282163706 epoch 1 final digest before mutation: consensus LNG 1, start esn: 2, 0 entries, first esn: 0, last esn: 0, bridge esn: 2, tail esn: 1, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S0, N1:S0, N2:S0, N3:S0, N4:S0}, last timestamp: 2021-09-17 02:10:19.663, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163706 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:13835058055282163706 N:e1n1 T:0 OM:{} F:528], final tail record: [L:13835058055282163706 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {m:N0:S0,N1:S0,N2:S0,N3:S0,N4:S0 MUTATION}.
I0917 02:10:19.666603    1162 [ld:srv:WG4] GET_SEQ_STATE_Message.cpp:567] continueExecution() skipped at least 10 log entries
I0917 02:10:19.667815    1162 [ld:srv:WG4] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:13835058055282163706, rqid:85899345922, ctx:start-message) from WG4:C37 (127.0.0.1:60224), but its data log sequencer's state is Recovery Incomplete
I0917 02:10:19.669632    1149 [ld:srv:WG3] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:13835058055282163706, rqid:34359738401, ctx:start-message) from WG3:C10 (127.0.0.1:60036), but its data log sequencer's state is Recovery Incomplete
I0917 02:10:19.671123    1136 [ld:srv:WG1] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387898, rqid:90194313237, ctx:start-message) from WG1:C18 (127.0.0.1:60088), but its data log sequencer's state is Recovery Incomplete
I0917 02:10:19.673825    1124 [ld:srv:WG0] Mutator.cpp:400] finalize() Mutator 4611686018427387898e1n1 completed (OK). Trace: W1{N3:S0,N0:S0};X:N3:S0:K;X:N0:S0:K;Y1:N3:S0:K;Y1:N0:S0:K;done:can_replicate:OK;
I0917 02:10:19.674936    1124 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387898, rqid:73014444040, ctx:start-message) from WG0:C39 (127.0.0.1:60232), but its data log sequencer's state is Recovery Incomplete
I0917 02:10:19.676042    1136 [ld:srv:WG1] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387898 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.773849    1149 [ld:srv:WG3] PurgeUncleanEpochs.cpp:592] complete() skipped at least 4 log entries
I0917 02:10:19.774522    1136 [ld:srv:WG1] Mutator.cpp:400] finalize() Mutator 13835058055282163706e1n2 completed (OK). Trace: W1{N3:S0,N1:S0,N2:S0};X:N3:S0:K;X:N1:S0:K;X:N2:S0:K;Y1:N3:S0:K;Y1:N2:S0:K;Y1:N1:S0:K;done:can_replicate:OK;
I0917 02:10:19.774573    1149 [ld:srv:WG3] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [0, 0] for log 4611686018427387902.
I0917 02:10:19.778584    1140 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163710 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.888746    1124 [ld:srv:WG0] LogRecoveryRequest.cpp:1463] complete() Log recovery completed for log 4611686018427387898, next_epoch:2
I0917 02:10:19.952917    1201 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [eventlog] Tail lsn of delta log is e2n0
I0917 02:10:19.965592    1201 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 2 is not available. Highest epoch known is 1.
I0917 02:10:19.966508    1201 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [eventlog] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:10:19.967202    1201 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (1)
I0917 02:10:19.970867    1194 [ld:srv:WB1] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [logsconfig] Tail lsn of delta log is e2n1
I0917 02:10:19.980084    1194 [ld:srv:WB1] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387901 epoch 2 is not available. Highest epoch known is 1.
I0917 02:10:19.980804    1194 [ld:srv:WB1] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [logsconfig] Applied delta record with lsn=e2n1 ts=2021-09-17 02:10:19.558
I0917 02:10:19.981409    1194 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [logsconfig] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:10:19.982170    1194 [ld:srv:WB1] LogsConfigManager.cpp:193] operator()() Received update from LogsConfigStateMachine, version 8589934593
I0917 02:10:19.983043    1194 [ld:srv:WB1] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:10:19.983985    1194 [ld:srv:WB1] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 1ms
I0917 02:10:19.984738    1194 [ld:srv:WB1] LogsConfigManager.cpp:331] updateLogsConfig() Published new LogsConfig (fully loaded? yes) version (8589934593) from LogsConfigManager
I0917 02:10:19.984208    1201 [ld:srv:WB3] RebuildingCoordinator.cpp:1740] publishDirtyShards() Publishing dirty shards.
I0917 02:10:19.989551    1201 [ld:srv:WB3] RebuildingCoordinator.cpp:2064] subscribeToEventLog() Subscribed to EventLog
W0917 02:10:19.995600    1136 [ld:srv:WG1] Worker.cpp:1000] onStoppedRunning() skipped at least 1 log entries
W0917 02:10:19.996791    1136 [ld:srv:WG1] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.015s, source: [Message sent/received: CLEANED]
I0917 02:10:19.999945    1136 [ld:srv:WG1] LogRecoveryRequest.cpp:1463] complete() Log recovery completed for log 13835058055282163706, next_epoch:2
I0917 02:10:20.000090    1201 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [maintenancelog] Tail lsn of delta log is e2n0
I0917 02:10:20.009718    1201 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387899 epoch 2 is not available. Highest epoch known is 1.
I0917 02:10:20.010567    1201 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [maintenancelog] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:10:20.011219    1201 [ld:srv:WB3] ClusterMaintenanceStateMachine.cpp:112] onUpdate() [maintenancelog] Published new ClusterMaintenanceState version (1)
I0917 02:10:20.049951    1186 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N1 changed from STARTING to FULLY_STARTED
I0917 02:10:20.154301    1186 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from STARTING to FULLY_STARTED
I0917 02:10:27.833119    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 86 log entries
I0917 02:10:27.834008    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.005MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.003MB, [unpartitioned A:0.002MB]
I0917 02:10:28.838349    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:10:28.839302    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.004MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.002MB, [unpartitioned A:0.001MB]
I0917 02:10:29.967976    1201 [ld:srv:WB3] ShardAuthoritativeStatusMap.cpp:165] broadcastToAllWorkers() Posting shard status update to workers: , version=e0n1
I0917 02:10:37.850394    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:10:37.851882    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.005MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.003MB, [unpartitioned A:0.002MB]
I0917 02:10:38.858727    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:10:38.859727    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.004MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.002MB, [unpartitioned A:0.001MB]
I0917 02:10:47.652354     358 [rocks-high-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000024.log.trash as trash -- OK
I0917 02:10:47.657580     381 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 16after deleting file /data/store/N1:1/db/shard1/000024.log.trash
I0917 02:10:47.659967     356 [rocks-high-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000024.log.trash as trash -- OK
I0917 02:10:47.667520     380 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N1:1/db/shard0/000024.log.trash
I0917 02:10:47.697292     352 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000027.sst.trash as trash -- OK
I0917 02:10:47.702489     354 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000027.sst.trash as trash -- OK
I0917 02:10:47.707051     352 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000025.sst.trash as trash -- OK
I0917 02:10:47.707668     380 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 12after deleting file /data/store/N1:1/db/shard0/000027.sst.trash
I0917 02:10:47.709051     381 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 13after deleting file /data/store/N1:1/db/shard1/000027.sst.trash
I0917 02:10:47.713954     381 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 23after deleting file /data/store/N1:1/db/shard1/000025.sst.trash
I0917 02:10:47.717548     354 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000025.sst.trash as trash -- OK
I0917 02:10:47.720863     352 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000019.sst.trash as trash -- OK
I0917 02:10:47.722974     380 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N1:1/db/shard0/000025.sst.trash
I0917 02:10:47.729907     354 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000019.sst.trash as trash -- OK
I0917 02:10:47.731217     381 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N1:1/db/shard1/000019.sst.trash
I0917 02:10:47.734180     352 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000016.sst.trash as trash -- OK
I0917 02:10:47.739673     380 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N1:1/db/shard0/000019.sst.trash
I0917 02:10:47.743215     381 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N1:1/db/shard1/000016.sst.trash
I0917 02:10:47.744950     354 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000016.sst.trash as trash -- OK
I0917 02:10:47.751674     352 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000014.sst.trash as trash -- OK
I0917 02:10:47.752306     380 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N1:1/db/shard0/000016.sst.trash
I0917 02:10:47.760166     354 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000014.sst.trash as trash -- OK
I0917 02:10:47.760591     381 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N1:1/db/shard1/000014.sst.trash
I0917 02:10:47.768608     380 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N1:1/db/shard0/000014.sst.trash
I0917 02:10:47.870086    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:10:47.871219    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:10:48.878922    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:10:48.880087    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:10:57.889287    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:10:57.906312    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:10:59.100105    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:10:59.100748    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:07.904626    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 85 log entries
W0917 02:11:07.964109    1136 [ld:srv:WG1] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.013s, source: [None]
I0917 02:11:08.353660    1136 [ld:srv:WG1] debug.cpp:573] log() Slow log() call: it took 0.122s to prepare, 0.266s to write().
I0917 02:11:08.229215    1031 [ld:s1:db-bg-fl] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.276s to write().
I0917 02:11:08.299438    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() skipped at least 5 log entries
I0917 02:11:08.399422    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:08.471856    1186 [ld:srv:WF0] debug.cpp:573] log() Slow log() call: it took 0.001s to prepare, 0.172s to write().
I0917 02:11:08.474347    1031 [ld:s1:db-bg-fl] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.075s to write().
I0917 02:11:08.479868    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from HEALTHY to UNHEALTHY
W0917 02:11:08.483028    1186 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.187s, source: [Message sent/received: GET_CLUSTER_STATE_REPLY]
I0917 02:11:08.584923    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from HEALTHY to UNHEALTHY
I0917 02:11:08.690846    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from HEALTHY to UNHEALTHY
I0917 02:11:08.692135    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from HEALTHY to UNHEALTHY
I0917 02:11:08.693075    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from HEALTHY to UNHEALTHY
I0917 02:11:09.407175    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from UNHEALTHY to HEALTHY
I0917 02:11:09.407834    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from UNHEALTHY to HEALTHY
I0917 02:11:09.568703    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:09.569262    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:10.672301    1124 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() skipped at least 1 log entries
I0917 02:11:10.672875    1124 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG0:C46 (127.0.0.1:60698)
I0917 02:11:10.684779    1124 [ld:srv:WG0] ProtocolHandler.cpp:127] notifyErrorOnSocket() skipped at least 6 log entries
I0917 02:11:10.686300    1124 [ld:srv:WG0] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket C46(127.0.0.1:60698) hit error AsyncSocketException: Socket read end of file., type = End of file
I0917 02:11:10.687638    1124 [ld:srv:WG0] Connection.cpp:724] close() Closing socket C46(127.0.0.1:60698). Reason: PEER_CLOSED: connection closed by peer
I0917 02:11:11.948230    1194 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1179] operator()() [logsconfig] Successfully wrote delta with lsn e2n2
I0917 02:11:11.949856    1194 [ld:srv:WB1] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [logsconfig] Applied delta record with lsn=e2n2 ts=2021-09-17 02:11:11.944
I0917 02:11:11.951211    1194 [ld:srv:WB1] LogsConfigManager.cpp:193] operator()() Received update from LogsConfigStateMachine, version 8589934594
I0917 02:11:11.953631    1194 [ld:srv:WB1] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:11:11.955328    1194 [ld:srv:WB1] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 2ms
I0917 02:11:11.956565    1194 [ld:srv:WB1] LogsConfigManager.cpp:331] updateLogsConfig() Published new LogsConfig (fully loaded? yes) version (8589934594) from LogsConfigManager
I0917 02:11:16.133452    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from UNHEALTHY to HEALTHY
I0917 02:11:17.982848    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 83 log entries
I0917 02:11:17.983653    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:19.098681    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:19.099604    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:11:28.000625    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:11:28.001848    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:29.115458    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:29.116153    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:11:38.022630    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:11:38.024118    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:39.132896    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:39.137249    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:11:48.041463    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:11:48.042910    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:49.152777    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:49.153482    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:11:58.061221    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:11:58.062389    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:59.171449    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:59.172382    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:12:08.079494    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:08.080416    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:09.188170    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:09.189128    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:12:18.098609    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:18.100124    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:19.206859    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:19.207429    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:12:28.115927    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:28.116750    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:29.223853    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:29.224374    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:12:38.135655    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:38.136903    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:39.240607    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:39.241227    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:12:48.152901    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:48.154445    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:49.260897    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:49.261580    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:12:52.935328    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from UNHEALTHY to HEALTHY
I0917 02:12:53.037294    1186 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from UNHEALTHY to HEALTHY
I0917 02:12:58.172379    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:58.172941    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:59.278801    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:59.279511    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:13:08.189689    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:13:08.191308    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:09.295545    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:13:09.296613    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:13:18.209876    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:13:18.210529    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:19.317159    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:13:19.318393    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:13:28.227981    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:13:28.229247    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:29.334273    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:13:29.335083    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:13:33.779890     313 [ld:conf] FileConfigSource.cpp:86] checkForUpdates() Change detected in config file /data/store/logdevice.conf, mtime = 1631844813641395829
I0917 02:13:33.782088     313 [ld:conf] TextConfigUpdater.cpp:116] onContents() Main config from file, hash = vj0b5rfpgt
I0917 02:13:33.784368     313 [ld:conf] TextConfigUpdater.cpp:245] compareServerConfig() Comparing new config (version 1) with existing config (version 1)
W0917 02:13:33.785697     313 [ld:conf] TextConfigUpdater.cpp:264] compareServerConfig() Received config with same version (1) but mismatched hash (9egjnxotid != vj0b5rfpgt)
I0917 02:13:33.940656    1186 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() skipped at least 3 log entries
I0917 02:13:33.942745    1186 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received starting_state_finished message from N4:1 with instance id:1631844617777, sent_time:1631844813939ms
I0917 02:13:33.944452    1186 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N4
I0917 02:13:33.948122    1186 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received starting_state_finished message from N3:1 with instance id:1631844617866, sent_time:1631844813945ms
I0917 02:13:33.955481    1186 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N3
I0917 02:13:33.969313    1186 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received starting_state_finished message from N2:1 with instance id:1631844617789, sent_time:1631844813966ms
I0917 02:13:33.970531    1186 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N2
I0917 02:13:33.977887     313 [ld:conf] Server.cpp:185] operator()() Updating settings from config took 191ms
I0917 02:13:33.978747     313 [ld:conf] UpdateableSecurityInfo.cpp:124] onConfigUpdate() PermissionChecker is changed
I0917 02:13:33.979449     313 [ld:conf] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:13:33.980582    1186 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting starting_state_finished message.
I0917 02:13:33.980645     313 [ld:conf] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 192ms, config update: 0ms, notifications: 1ms
I0917 02:13:33.981923     313 [ld:conf] TextConfigUpdater.cpp:306] pushServerConfig() Updated config (version: 1 - hash: vj0b5rfpgt)
I0917 02:13:33.981315    1186 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() skipped at least 6 log entries
I0917 02:13:33.983294    1186 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending starting_state_finished message with instance id:1631844617782 to node WF0:N4:1 (127.0.0.1:39321)
I0917 02:13:33.982557     313 [ld:conf] TextConfigUpdater.cpp:397] pushLogsConfig() Ignoring changes in the 'logs' section in the config file because LogsConfigManager is ENABLED
I0917 02:13:33.983936    1186 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending starting_state_finished message with instance id:1631844617782 to node WF0:N3:1 (127.0.0.1:39332)
I0917 02:13:33.984423     313 [ld:conf] TextConfigUpdater.cpp:174] update() Config update result: ServerConfig=updated, ZK=skipped, LogsConfig=updated
I0917 02:13:34.000338    1186 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received starting_state_finished message from N0:1 with instance id:1631844617844, sent_time:1631844813999ms
I0917 02:13:34.001924    1186 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N0
I0917 02:13:38.246691    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:13:38.247705    1034 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:39.352182    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:13:39.353028    1031 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:13:41.348620    1140 [ld:srv:WG2] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket C49(127.0.0.1:60736) hit error AsyncSocketException: Socket read end of file., type = End of file
I0917 02:13:41.348886    1162 [ld:srv:WG4] Connection.cpp:724] close() Closing socket C48(127.0.0.1:60724). Reason: PEER_CLOSED: connection closed by peer
I0917 02:14:07.378433     761 [logdeviced-main] main.cpp:399] main() Command line arguments: --local-log-store-path /data/store/N1:1/db --num-shards 2 --server-id 6jrupmbru5 --log-file /data/store/N1:1/log --name Node1 --config-path file:/data/store/logdevice.conf --client-thrift-api-port 48354 --gossip-port 48348 --server-thrift-api-port 48353 --test-mode true --server-to-server-port 48352 --admin-port 48349 --loglevel info --port 48346 --sequencers lazy 
I0917 02:14:07.383498     761 [logdeviced-main] main.cpp:403] main() Plugins loaded: {"Thrift client factory plugin":"built-in","ZookeeperClient factory":"built-in","ConfigSource factory":["built-in"],"PermissionChecker factory":"built-in","Build Info":"built-in","Plugin provider":["Built-in plugin provider","Static plug-in loader","Dynamic plugin loader"]}
I0917 02:14:07.385291     761 [logdeviced-main] main.cpp:405] main() server starting
I0917 02:14:07.386543     761 [logdeviced-main] main.cpp:410] main() version 99.99.99
I0917 02:14:07.394531     761 [logdeviced-main] main.cpp:418] main() asserts off (NDEBUG set)
I0917 02:14:07.411566     761 [logdeviced-main] TextConfigUpdater.cpp:56] fetchFromSource() Requesting main config "/data/store/logdevice.conf" (source: file)
I0917 02:14:07.413761     761 [logdeviced-main] TextConfigUpdater.cpp:116] onContents() Main config from file, hash = hyg3dqvegx
I0917 02:14:08.497682     761 [logdeviced-main] Server.cpp:185] operator()() Updating settings from config took 1079ms
I0917 02:14:08.502382     761 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 1084ms, config update: 0ms, notifications: 0ms
I0917 02:14:08.508347     761 [logdeviced-main] TextConfigUpdater.cpp:306] pushServerConfig() Updated config (version: 1 - hash: hyg3dqvegx)
I0917 02:14:08.509579     761 [logdeviced-main] TextConfigUpdater.cpp:397] pushLogsConfig() Ignoring changes in the 'logs' section in the config file because LogsConfigManager is ENABLED
I0917 02:14:08.510378     761 [logdeviced-main] TextConfigUpdater.cpp:174] update() Config update result: ServerConfig=updated, ZK=skipped, LogsConfig=updated
I0917 02:14:08.511761     761 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:14:08.515545     761 [logdeviced-main] NodesConfigurationInit.cpp:233] operator()() Fetching initial nodes configuration (Attempt 1)...
I0917 02:14:08.522819    1238 [ld:file-ncs] NodesConfigurationInit.cpp:290] operator()() Got a NodesConfiguration of version: 5
I0917 02:14:08.524509    1238 [ld:file-ncs] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:08.529772     761 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:08.533324     761 [logdeviced-main] Server.cpp:510] init() My Node ID is N1:1
I0917 02:14:08.534226     761 [logdeviced-main] Server.cpp:517] init() My version is 0
I0917 02:14:08.535073     761 [logdeviced-main] NoopTraceLogger.cpp:22] NoopTraceLogger() NOOP TraceLogger is ON, no trace samples will be published.
I0917 02:14:08.538868     761 [logdeviced-main] FileBasedVersionedConfigStore.cpp:46] stopAndJoin() FileBasedVersionedConfigStore threads stopped.
I0917 02:14:08.541628     761 [logdeviced-main] main.cpp:144] set_fd_limit() Limit on number of file descriptors is 1048576
W0917 02:14:08.542824     761 [logdeviced-main] main.cpp:192] drop_root() Running under root, but no --user command line option specified. Will keep running as root
I0917 02:14:08.550582     761 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48346
I0917 02:14:08.564561     761 [logdeviced-main] Server.cpp:781] initListeners() Initializing a gossip listener.
I0917 02:14:08.566667     761 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48348
I0917 02:14:08.569743     761 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48352 (SSL)
I0917 02:14:08.574496     761 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48356 (SSL)
I0917 02:14:08.579800     761 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48355 (SSL)
I0917 02:14:08.620373     761 [logdeviced-main] RocksDBLogStoreConfig.cpp:162] RocksDBLogStoreConfig() LD manages flushes and all memory budgets on the node. atomic_flush is set to true.
I0917 02:14:08.621085    1262 [io-stall:s1] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 1
I0917 02:14:08.658029    1261 [io-stall:s0] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 0
I0917 02:14:08.658267    1271 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:08.658766    1272 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:09.149715    1271 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000037.log.trash as trash -- OK
I0917 02:14:09.162946    1273 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N1:1/db/shard0/000037.log.trash
I0917 02:14:09.224553    1271 [ld:open-rocks0] PartitionedRocksDBStore.cpp:891] open() Partition s0:1000000 is under-replicated: Start:2021-09-17 02:10:15.092, Min:2021-09-17 02:10:10.092, Max: 2021-09-17 02:10:20.092
I0917 02:14:09.225682    1271 [ld:open-rocks0] PartitionedRocksDBStore.cpp:897] open() Shard[0] dirty ranges: [A:{{[2021-09-17 02:10:10.092,2021-09-17 02:10:20.092]}}]
I0917 02:14:09.233748    1271 [ld:open-rocks0] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.000s. Read 6 records, 450 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:09.246239    1272 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000038.log.trash as trash -- OK
I0917 02:14:09.261362    1274 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N1:1/db/shard1/000038.log.trash
I0917 02:14:09.361639    1272 [ld:open-rocks1] PartitionedRocksDBStore.cpp:891] open() Partition s1:1000000 is under-replicated: Start:2021-09-17 02:10:15.088, Min:2021-09-17 02:10:10.088, Max: 2021-09-17 02:10:20.088
I0917 02:14:09.369943    1272 [ld:open-rocks1] PartitionedRocksDBStore.cpp:897] open() Shard[1] dirty ranges: [A:{{[2021-09-17 02:10:10.088,2021-09-17 02:10:20.088]}}]
I0917 02:14:09.374797    1267 [rocks-high-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000043.log.trash as trash -- OK
I0917 02:14:09.381184    1271 [ld:open-rocks0] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N1:1/db/shard0 in 712 ms
I0917 02:14:09.381397    1273 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N1:1/db/shard0/000043.log.trash
I0917 02:14:09.389242    1272 [ld:open-rocks1] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.001s. Read 8 records, 1160 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:09.453046    1656 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 1ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:14:09.459873    1268 [rocks-high-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000044.log.trash as trash -- OK
I0917 02:14:09.462849    1272 [ld:open-rocks1] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N1:1/db/shard1 in 793 ms
I0917 02:14:09.463326    1274 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N1:1/db/shard1/000044.log.trash
I0917 02:14:09.470411     761 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:691] printDiskShardMapping() Disk -> Shard mapping: /data/store/N1:1/db/shard0 -> [0,1]
I0917 02:14:09.471418     761 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:285] init() Initialized sharded RocksDB instance at /data/store/N1:1/db with 2 shards
E0917 02:14:09.476420    1751 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState1"!
E0917 02:14:09.478524    1750 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState0"!
I0917 02:14:09.481304     761 [logdeviced-main] Server.cpp:1173] initLogStorageStateMap() Populating log storage state map successful.
E0917 02:14:09.497273     761 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:09.497999     761 [logdeviced-main] RecordCacheMonitorThread.cpp:27] RecordCacheMonitorThread() Record cache monitor thread started.
I0917 02:14:09.503388     761 [logdeviced-main] ClusterState.cpp:356] resizeClusterState() Cluster state size updated from 0 to 5
I0917 02:14:09.505945    1771 [ld:cache-evict] RecordCacheMonitorThread.cpp:44] threadMain() Record cache eviction thread started. Size limit is set to 4294967296 bytes.
E0917 02:14:09.511246     761 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:09.520869     761 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:09.540153     761 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:09.559523     761 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:09.562797     761 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:09.564512     761 [logdeviced-main] Processor.cpp:247] init() Initialized 5 workers of type GENERAL
E0917 02:14:09.566937     761 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:09.568650     761 [logdeviced-main] Processor.cpp:247] init() Initialized 1 workers of type FAILURE_DETECTOR
E0917 02:14:09.571064     761 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:09.578260     761 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:09.581457     761 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:09.587316     761 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:09.592713     761 [logdeviced-main] Processor.cpp:247] init() Initialized 4 workers of type BACKGROUND
I0917 02:14:09.595852     761 [logdeviced-main] FailureDetector.cpp:139] FailureDetector() Failure Detector created with instance id: 1631844849595
I0917 02:14:09.596714     761 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N0 changed from UNKNOWN to DEAD
I0917 02:14:09.598814     761 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from HEALTHY to UNHEALTHY
I0917 02:14:09.599636     761 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N1 changed from UNKNOWN to DEAD
I0917 02:14:09.601640     761 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from HEALTHY to UNHEALTHY
I0917 02:14:09.610675     761 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N2 changed from UNKNOWN to DEAD
I0917 02:14:09.633950     761 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from HEALTHY to UNHEALTHY
I0917 02:14:09.638854     761 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N3 changed from UNKNOWN to DEAD
I0917 02:14:09.642774     761 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from HEALTHY to UNHEALTHY
I0917 02:14:09.645289     761 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N4 changed from UNKNOWN to DEAD
I0917 02:14:09.647451     761 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from HEALTHY to UNHEALTHY
W0917 02:14:09.661963    1782 [ld:srv:WG4] Worker.cpp:1322] processRequest() Request queued for 66 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967300), p :HI_PRI
W0917 02:14:09.685573    1779 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 89 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967298), p :HI_PRI
W0917 02:14:09.694217    1773 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 97 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967296), p :HI_PRI
I0917 02:14:09.698822     761 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
W0917 02:14:09.701182    1773 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 103 msec: NODE_STATE_UPDATED (id: 4294967301), p :LO_PRI
I0917 02:14:09.701325    1788 [ld:srv:WB2] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
W0917 02:14:09.702882    1773 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 104 msec: NODE_STATE_UPDATED (id: 4294967306), p :LO_PRI
I0917 02:14:09.704679    1788 [ld:srv:WB2] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 4ms
W0917 02:14:09.707093    1773 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 108 msec: NODE_STATE_UPDATED (id: 4294967307), p :LO_PRI
W0917 02:14:09.712358    1773 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 111 msec: NODE_STATE_UPDATED (id: 4294967311), p :LO_PRI
W0917 02:14:09.713720    1773 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 112 msec: NODE_STATE_UPDATED (id: 4294967316), p :LO_PRI
W0917 02:14:09.714464    1773 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 112 msec: NODE_STATE_UPDATED (id: 4294967317), p :LO_PRI
W0917 02:14:09.715354    1773 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 81 msec: NODE_STATE_UPDATED (id: 4294967321), p :LO_PRI
I0917 02:14:09.718216    1788 [ld:srv:WB2] NodesConfigurationManager.cpp:507] onProcessingFinished() Updated local nodes config to version 5...
I0917 02:14:09.719381    1758 [ld:s0:default:1] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:09.720085    1758 [ld:s0:default:1] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 0, totaling 0 bytes.
I0917 02:14:09.724099    1767 [ld:s1:default:1] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:09.725316    1767 [ld:s1:default:1] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 1, totaling 0 bytes.
I0917 02:14:09.726963     761 [logdeviced-main] Server.cpp:1319] initSequencers() Initializing FileEpochStore
I0917 02:14:09.727782     761 [logdeviced-main] Server.cpp:1398] initSequencerPlacement() using SequencerOptions::LAZY
I0917 02:14:09.728471     761 [logdeviced-main] Server.cpp:1430] initRebuildingCoordinator() Initializing EventLog RSM and RebuildingCoordinator
I0917 02:14:09.729332     761 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387903)
I0917 02:14:09.731435     761 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387903, is_server:1)
I0917 02:14:09.732277     761 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:09.733240     761 [logdeviced-main] Server.cpp:1467] initRebuildingCoordinator() Starting RebuildingSupervisor
I0917 02:14:09.734377     761 [logdeviced-main] Server.cpp:1480] initRebuildingCoordinator() Starting RebuildingCoordinator
I0917 02:14:09.734451    1782 [ld:srv:WG4] RebuildingSupervisor.cpp:62] init() Starting Rebuilding Supervisor
I0917 02:14:09.735853    1782 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N4 to execute in 1200s
I0917 02:14:09.737025    1782 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N3 to execute in 1200s
I0917 02:14:09.737962    1782 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N2 to execute in 1200s
I0917 02:14:09.737719     761 [logdeviced-main] LogStoreMonitor.cpp:190] start() Logstore monitoring thread started.
I0917 02:14:09.740645     761 [logdeviced-main] UnreleasedRecordDetector.cpp:106] start() Unreleased record detector thread started.
I0917 02:14:09.737805    1789 [ld:srv:WB3] RebuildingCoordinator.cpp:309] subscribeToEventLogIfNeeded() RebuildingCoordinator did not start yet because LogsConfig is not fully loaded yet
I0917 02:14:09.739584    1782 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N0 to execute in 1200s
W0917 02:14:09.744595    1782 [ld:srv:WG4] RebuildingSupervisor.cpp:705] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:14:09.741366     761 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387901)
I0917 02:14:09.745547    1782 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
W0917 02:14:09.747536    1782 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.013s, source: [Request: REBUILDING_SUPERVISOR]
I0917 02:14:09.746430     761 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387901, is_server:1)
I0917 02:14:09.756587     761 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:09.743622    1789 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [eventlog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:09.779058    1787 [ld:srv:WB1] LogsConfigManager.cpp:38] execute() Starting LogsConfigManager on Worker 1 in pool: BACKGROUND
I0917 02:14:09.802947    1787 [ld:srv:WB1] LogsConfigManager.cpp:165] start() Starting LogsConfig Manager RSM
I0917 02:14:09.799468    1789 [ld:srv:WB3] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.056s to write().
I0917 02:14:09.804081    1787 [ld:srv:WB1] LogsConfigManager.cpp:206] start() Starting LogsConfig Replicated State Machine
I0917 02:14:09.829761    1787 [ld:srv:WB1] ReplicatedStateMachine-inl.h:38] startFetchingSnapshot() [logsconfig] Using RSMSnapshotStore...
I0917 02:14:09.825006    1789 [ld:srv:WB3] EventLogStateMachine.cpp:146] gotInitialState() Got base rebuilding set: {}
I0917 02:14:09.834450    1787 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1294] initSnapshotFetchTimer() [logsconfig] Creating timer to fetch snapshots ...
W0917 02:14:09.840659    1787 [ld:srv:WB1] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.062s, source: [Request: START_LOGS_CONFIG_MANAGER]
I0917 02:14:09.838376    1789 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [eventlog] Retrieving tail lsn of delta log...
E0917 02:14:09.855237    1780 [ld:srv:WG3] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387903. All sequencer nodes are unavailable.
E0917 02:14:09.856007    1780 [ld:srv:WG3] SequencerRouter.cpp:56] operator()() Error during sequencer lookup for log 4611686018427387903 (NOSEQUENCER), reporting NOSEQUENCER.
E0917 02:14:09.857183    1780 [ld:srv:WG3] SequencerRouter.cpp:105] onFailure() Error during sequencer routing for log 4611686018427387903 (NOSEQUENCER), request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7fe525a9f028].
W0917 02:14:09.859385    1780 [ld:srv:WG3] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387903, rqid:17179869186, ctx:rsm, err(NOSEQUENCER)
W0917 02:14:09.860730    1780 [ld:srv:WG3] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387903 (rqid:17179869186, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
I0917 02:14:09.858701     761 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server LogDevice Admin API Service will listen on port 48349
I0917 02:14:09.868320     761 [logdeviced-main] Server.cpp:1540] createAndAttachMaintenanceManager() Not initializing MaintenanceManager since it is disabled in settings
I0917 02:14:09.870568     761 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: s2s-api
I0917 02:14:09.859539    1789 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [maintenancelog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:09.875679    1789 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [maintenancelog] Retrieving tail lsn of delta log...
I0917 02:14:09.872817     761 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server s2s-api will listen on port 48353
I0917 02:14:09.885872     761 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: c2s-api
E0917 02:14:09.878749    1789 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:17179869186) for log:4611686018427387903, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
E0917 02:14:09.880625    1782 [ld:srv:WG4] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387899. All sequencer nodes are unavailable.
I0917 02:14:09.890410     761 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server c2s-api will listen on port 48354
I0917 02:14:09.907268     761 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:09.913079    1246 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
W0917 02:14:09.901273    1782 [ld:srv:WG4] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387899, rqid:17179869188, ctx:rsm, err(NOSEQUENCER)
W0917 02:14:09.917958    1782 [ld:srv:WG4] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387899 (rqid:17179869188, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
E0917 02:14:09.924515    1789 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:17179869188) for log:4611686018427387899, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:14:16.501335    2577 [logdeviced-main] main.cpp:399] main() Command line arguments: --local-log-store-path /data/store/N1:1/db --num-shards 2 --server-id 1grbn0q9h4 --log-file /data/store/N1:1/log --name Node1 --config-path file:/data/store/logdevice.conf --client-thrift-api-port 41086 --gossip-port 41080 --server-thrift-api-port 41085 --test-mode true --server-to-server-port 41084 --admin-port 41081 --loglevel info --port 41078 --sequencers lazy 
I0917 02:14:16.502975    2577 [logdeviced-main] main.cpp:403] main() Plugins loaded: {"Thrift client factory plugin":"built-in","ZookeeperClient factory":"built-in","ConfigSource factory":["built-in"],"PermissionChecker factory":"built-in","Build Info":"built-in","Plugin provider":["Built-in plugin provider","Static plug-in loader","Dynamic plugin loader"]}
I0917 02:14:16.504945    2577 [logdeviced-main] main.cpp:405] main() server starting
I0917 02:14:16.506660    2577 [logdeviced-main] main.cpp:410] main() version 99.99.99
I0917 02:14:16.507994    2577 [logdeviced-main] main.cpp:418] main() asserts off (NDEBUG set)
I0917 02:14:16.511687    2577 [logdeviced-main] TextConfigUpdater.cpp:56] fetchFromSource() Requesting main config "/data/store/logdevice.conf" (source: file)
I0917 02:14:16.516849    2577 [logdeviced-main] TextConfigUpdater.cpp:116] onContents() Main config from file, hash = 99e4033bvf
I0917 02:14:17.287883    2577 [logdeviced-main] Server.cpp:185] operator()() Updating settings from config took 766ms
I0917 02:14:17.290101    2577 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 768ms, config update: 0ms, notifications: 0ms
I0917 02:14:17.292967    2577 [logdeviced-main] TextConfigUpdater.cpp:306] pushServerConfig() Updated config (version: 1 - hash: 99e4033bvf)
I0917 02:14:17.295047    2577 [logdeviced-main] TextConfigUpdater.cpp:397] pushLogsConfig() Ignoring changes in the 'logs' section in the config file because LogsConfigManager is ENABLED
I0917 02:14:17.297281    2577 [logdeviced-main] TextConfigUpdater.cpp:174] update() Config update result: ServerConfig=updated, ZK=skipped, LogsConfig=updated
I0917 02:14:17.299878    2577 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:14:17.310078    2577 [logdeviced-main] NodesConfigurationInit.cpp:233] operator()() Fetching initial nodes configuration (Attempt 1)...
I0917 02:14:17.317977    2586 [ld:file-ncs] NodesConfigurationInit.cpp:290] operator()() Got a NodesConfiguration of version: 5
I0917 02:14:17.322459    2586 [ld:file-ncs] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:17.326548    2577 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:17.328304    2577 [logdeviced-main] Server.cpp:510] init() My Node ID is N1:1
I0917 02:14:17.329737    2577 [logdeviced-main] Server.cpp:517] init() My version is 0
I0917 02:14:17.332524    2577 [logdeviced-main] NoopTraceLogger.cpp:22] NoopTraceLogger() NOOP TraceLogger is ON, no trace samples will be published.
I0917 02:14:17.338097    2577 [logdeviced-main] FileBasedVersionedConfigStore.cpp:46] stopAndJoin() FileBasedVersionedConfigStore threads stopped.
I0917 02:14:17.340630    2577 [logdeviced-main] main.cpp:144] set_fd_limit() Limit on number of file descriptors is 1048576
W0917 02:14:17.341955    2577 [logdeviced-main] main.cpp:192] drop_root() Running under root, but no --user command line option specified. Will keep running as root
I0917 02:14:17.346779    2577 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 41078
I0917 02:14:17.352357    2577 [logdeviced-main] Server.cpp:781] initListeners() Initializing a gossip listener.
I0917 02:14:17.356813    2577 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 41080
I0917 02:14:17.360801    2577 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 41084 (SSL)
I0917 02:14:17.363065    2577 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 41088 (SSL)
I0917 02:14:17.365837    2577 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 41087 (SSL)
I0917 02:14:17.396843    2577 [logdeviced-main] RocksDBLogStoreConfig.cpp:162] RocksDBLogStoreConfig() LD manages flushes and all memory budgets on the node. atomic_flush is set to true.
I0917 02:14:17.401805    2590 [io-stall:s0] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 0
I0917 02:14:17.418607    2591 [io-stall:s1] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 1
I0917 02:14:17.419385    2598 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:17.447138    2599 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:17.875278    2598 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000056.log.trash as trash -- OK
I0917 02:14:17.884585    2600 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N1:1/db/shard0/000056.log.trash
I0917 02:14:17.965116    2598 [ld:open-rocks0] PartitionedRocksDBStore.cpp:891] open() Partition s0:1000000 is under-replicated: Start:2021-09-17 02:10:15.092, Min:2021-09-17 02:10:05.092, Max: 2021-09-17 02:10:25.092
I0917 02:14:17.973450    2598 [ld:open-rocks0] PartitionedRocksDBStore.cpp:897] open() Shard[0] dirty ranges: [A:{{[2021-09-17 02:10:05.092,2021-09-17 02:10:25.092]}}]
I0917 02:14:17.991976    2598 [ld:open-rocks0] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.001s. Read 6 records, 450 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:18.045232    2599 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000057.log.trash as trash -- OK
I0917 02:14:18.062081    2601 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N1:1/db/shard1/000057.log.trash
I0917 02:14:18.114595    2597 [rocks-high-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000062.log.trash as trash -- OK
I0917 02:14:18.137406    2598 [ld:open-rocks0] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N1:1/db/shard0 in 708 ms
I0917 02:14:18.147769    2600 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N1:1/db/shard0/000062.log.trash
I0917 02:14:18.190346    2599 [ld:open-rocks1] PartitionedRocksDBStore.cpp:891] open() Partition s1:1000000 is under-replicated: Start:2021-09-17 02:10:15.088, Min:2021-09-17 02:10:05.088, Max: 2021-09-17 02:10:25.088
I0917 02:14:18.202618    2593 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000066.sst.trash as trash -- OK
I0917 02:14:18.205051    2599 [ld:open-rocks1] PartitionedRocksDBStore.cpp:897] open() Shard[1] dirty ranges: [A:{{[2021-09-17 02:10:05.088,2021-09-17 02:10:25.088]}}]
I0917 02:14:18.216819    2600 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N1:1/db/shard0/000066.sst.trash
I0917 02:14:18.221694    2743 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 1ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:14:18.239114    2593 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000060.sst.trash as trash -- OK
I0917 02:14:18.247864    2599 [ld:open-rocks1] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.001s. Read 8 records, 1160 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:18.272507    2593 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000057.sst.trash as trash -- OK
I0917 02:14:18.282462    2600 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N1:1/db/shard0/000060.sst.trash
I0917 02:14:18.306684    2593 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000055.sst.trash as trash -- OK
I0917 02:14:18.319812    2600 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 19after deleting file /data/store/N1:1/db/shard0/000057.sst.trash
I0917 02:14:18.337969    2593 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000049.sst.trash as trash -- OK
I0917 02:14:18.352019    2600 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 29after deleting file /data/store/N1:1/db/shard0/000055.sst.trash
I0917 02:14:18.370818    2593 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000047.sst.trash as trash -- OK
I0917 02:14:18.377306    2600 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 38after deleting file /data/store/N1:1/db/shard0/000049.sst.trash
I0917 02:14:18.410078    2593 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000041.sst.trash as trash -- OK
I0917 02:14:18.419936    2600 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N1:1/db/shard0/000047.sst.trash
I0917 02:14:18.441619    2593 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000038.sst.trash as trash -- OK
I0917 02:14:18.448553    2600 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 21after deleting file /data/store/N1:1/db/shard0/000041.sst.trash
I0917 02:14:18.461764    2593 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000036.sst.trash as trash -- OK
I0917 02:14:18.466615    2596 [rocks-high-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000063.log.trash as trash -- OK
I0917 02:14:18.467868    2600 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 30after deleting file /data/store/N1:1/db/shard0/000038.sst.trash
I0917 02:14:18.488412    2593 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000029.sst.trash as trash -- OK
I0917 02:14:18.490756    2599 [ld:open-rocks1] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N1:1/db/shard1 in 1036 ms
I0917 02:14:18.499048    2601 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N1:1/db/shard1/000063.log.trash
I0917 02:14:18.505315    2600 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 40after deleting file /data/store/N1:1/db/shard0/000036.sst.trash
I0917 02:14:18.521359    2577 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:691] printDiskShardMapping() Disk -> Shard mapping: /data/store/N1:1/db/shard0 -> [0,1]
I0917 02:14:18.523551    2577 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:285] init() Initialized sharded RocksDB instance at /data/store/N1:1/db with 2 shards
I0917 02:14:18.521537    2594 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000067.sst.trash as trash -- OK
I0917 02:14:18.523426    2600 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 53after deleting file /data/store/N1:1/db/shard0/000029.sst.trash
E0917 02:14:18.528923    2894 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState1"!
E0917 02:14:18.533255    2893 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState0"!
I0917 02:14:18.563697    2594 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000061.sst.trash as trash -- OK
I0917 02:14:18.571285    2601 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N1:1/db/shard1/000067.sst.trash
I0917 02:14:18.563923    2577 [logdeviced-main] Server.cpp:1173] initLogStorageStateMap() Populating log storage state map successful.
I0917 02:14:18.610585    2601 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 21after deleting file /data/store/N1:1/db/shard1/000061.sst.trash
E0917 02:14:18.617532    2577 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:18.620399    2577 [logdeviced-main] RecordCacheMonitorThread.cpp:27] RecordCacheMonitorThread() Record cache monitor thread started.
I0917 02:14:18.618495    2594 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000058.sst.trash as trash -- OK
I0917 02:14:18.625134    2912 [ld:cache-evict] RecordCacheMonitorThread.cpp:44] threadMain() Record cache eviction thread started. Size limit is set to 4294967296 bytes.
I0917 02:14:18.625606    2577 [logdeviced-main] ClusterState.cpp:356] resizeClusterState() Cluster state size updated from 0 to 5
I0917 02:14:18.653343    2594 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000056.sst.trash as trash -- OK
I0917 02:14:18.658371    2601 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N1:1/db/shard1/000058.sst.trash
E0917 02:14:18.663831    2577 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:18.682823    2577 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:18.683886    2594 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000050.sst.trash as trash -- OK
E0917 02:14:18.697900    2577 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:18.692427    2601 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 19after deleting file /data/store/N1:1/db/shard1/000056.sst.trash
I0917 02:14:18.715512    2594 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000048.sst.trash as trash -- OK
I0917 02:14:18.720379    2601 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 27after deleting file /data/store/N1:1/db/shard1/000050.sst.trash
E0917 02:14:18.722261    2577 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:18.730900    2601 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 38after deleting file /data/store/N1:1/db/shard1/000048.sst.trash
E0917 02:14:18.737670    2577 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:18.742329    2594 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000042.sst.trash as trash -- OK
I0917 02:14:18.745042    2577 [logdeviced-main] Processor.cpp:247] init() Initialized 5 workers of type GENERAL
E0917 02:14:18.759526    2577 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:18.762627    2594 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000039.sst.trash as trash -- OK
I0917 02:14:18.766371    2601 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N1:1/db/shard1/000042.sst.trash
I0917 02:14:18.768038    2577 [logdeviced-main] Processor.cpp:247] init() Initialized 1 workers of type FAILURE_DETECTOR
I0917 02:14:18.777353    2601 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 19after deleting file /data/store/N1:1/db/shard1/000039.sst.trash
E0917 02:14:18.784642    2577 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:18.786373    2594 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000037.sst.trash as trash -- OK
E0917 02:14:18.793854    2577 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:18.802590    2577 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:18.813086    2594 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000029.sst.trash as trash -- OK
I0917 02:14:18.830660    2601 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N1:1/db/shard1/000037.sst.trash
E0917 02:14:18.832400    2577 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:18.850874    2577 [logdeviced-main] Processor.cpp:247] init() Initialized 4 workers of type BACKGROUND
I0917 02:14:18.857731    2601 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 23after deleting file /data/store/N1:1/db/shard1/000029.sst.trash
I0917 02:14:18.861617    2577 [logdeviced-main] FailureDetector.cpp:139] FailureDetector() Failure Detector created with instance id: 1631844858861
I0917 02:14:18.864990    2577 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N0 changed from UNKNOWN to DEAD
I0917 02:14:18.878580    2577 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from HEALTHY to UNHEALTHY
I0917 02:14:18.887882    2577 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N1 changed from UNKNOWN to DEAD
I0917 02:14:18.891084    2577 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from HEALTHY to UNHEALTHY
I0917 02:14:18.895719    2577 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N2 changed from UNKNOWN to DEAD
I0917 02:14:18.898766    2577 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from HEALTHY to UNHEALTHY
I0917 02:14:18.901263    2577 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N3 changed from UNKNOWN to DEAD
I0917 02:14:18.904565    2577 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from HEALTHY to UNHEALTHY
I0917 02:14:18.915598    2577 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N4 changed from UNKNOWN to DEAD
I0917 02:14:18.918249    2577 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from HEALTHY to UNHEALTHY
W0917 02:14:18.929294    2935 [ld:srv:WG4] Worker.cpp:1322] processRequest() Request queued for 67 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967300), p :HI_PRI
W0917 02:14:18.970085    2923 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 109 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967296), p :HI_PRI
W0917 02:14:18.982070    2935 [ld:srv:WG4] Worker.cpp:1322] processRequest() Request queued for 103 msec: NODE_STATE_UPDATED (id: 4294967305), p :LO_PRI
W0917 02:14:18.992551    2925 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 114 msec: NODE_STATE_UPDATED (id: 4294967302), p :LO_PRI
W0917 02:14:19.000012    2925 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 121 msec: NODE_STATE_UPDATED (id: 4294967308), p :LO_PRI
W0917 02:14:19.003450    2925 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 112 msec: NODE_STATE_UPDATED (id: 4294967312), p :LO_PRI
W0917 02:14:19.011337    2925 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 120 msec: NODE_STATE_UPDATED (id: 4294967318), p :LO_PRI
W0917 02:14:19.027298    2925 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 128 msec: NODE_STATE_UPDATED (id: 4294967322), p :LO_PRI
W0917 02:14:19.034991    2925 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 136 msec: NODE_STATE_UPDATED (id: 4294967328), p :LO_PRI
W0917 02:14:19.042927    2925 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 138 msec: NODE_STATE_UPDATED (id: 4294967332), p :LO_PRI
I0917 02:14:19.031979    2577 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:14:19.056300    2958 [ld:srv:WB0] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:14:19.062725    2958 [ld:srv:WB0] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 7ms
W0917 02:14:19.070686    2958 [ld:srv:WB0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.016s, source: [Request: NODES_CONFIGURATION_MANAGER]
I0917 02:14:19.076205    2958 [ld:srv:WB0] NodesConfigurationManager.cpp:507] onProcessingFinished() Updated local nodes config to version 5...
W0917 02:14:19.089542    2958 [ld:srv:WB0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.013s, source: [Request: NODES_CONFIGURATION_MANAGER]
I0917 02:14:19.083546    2908 [ld:s1:default:0] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:19.093517    2908 [ld:s1:default:0] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 1, totaling 0 bytes.
I0917 02:14:19.084004    2901 [ld:s0:default:1] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:19.104788    2901 [ld:s0:default:1] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 0, totaling 0 bytes.
I0917 02:14:19.119617    2577 [logdeviced-main] Server.cpp:1319] initSequencers() Initializing FileEpochStore
I0917 02:14:19.123048    2577 [logdeviced-main] Server.cpp:1398] initSequencerPlacement() using SequencerOptions::LAZY
I0917 02:14:19.130080    2577 [logdeviced-main] Server.cpp:1430] initRebuildingCoordinator() Initializing EventLog RSM and RebuildingCoordinator
I0917 02:14:19.134487    2577 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387903)
I0917 02:14:19.140833    2577 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387903, is_server:1)
I0917 02:14:19.147926    2577 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:19.151707    2577 [logdeviced-main] Server.cpp:1467] initRebuildingCoordinator() Starting RebuildingSupervisor
I0917 02:14:19.155373    2577 [logdeviced-main] Server.cpp:1480] initRebuildingCoordinator() Starting RebuildingCoordinator
I0917 02:14:19.155582    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:62] init() Starting Rebuilding Supervisor
I0917 02:14:19.177300    2577 [logdeviced-main] LogStoreMonitor.cpp:190] start() Logstore monitoring thread started.
I0917 02:14:19.180887    2577 [logdeviced-main] UnreleasedRecordDetector.cpp:106] start() Unreleased record detector thread started.
I0917 02:14:19.182490    2577 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387901)
I0917 02:14:19.176803    2969 [ld:srv:WB3] RebuildingCoordinator.cpp:309] subscribeToEventLogIfNeeded() RebuildingCoordinator did not start yet because LogsConfig is not fully loaded yet
I0917 02:14:19.177416    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N4 to execute in 1200s
I0917 02:14:19.191549    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N3 to execute in 1200s
I0917 02:14:19.185547    2577 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387901, is_server:1)
I0917 02:14:19.197582    2577 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:19.188335    2969 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [eventlog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:19.225688    2969 [ld:srv:WB3] EventLogStateMachine.cpp:146] gotInitialState() Got base rebuilding set: {}
I0917 02:14:19.194184    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N2 to execute in 1200s
I0917 02:14:19.243741    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N0 to execute in 1200s
I0917 02:14:19.221679    2960 [ld:srv:WB1] LogsConfigManager.cpp:38] execute() Starting LogsConfigManager on Worker 1 in pool: BACKGROUND
I0917 02:14:19.228633    2969 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [eventlog] Retrieving tail lsn of delta log...
I0917 02:14:19.260818    2969 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [maintenancelog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
W0917 02:14:19.247425    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:705] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:14:19.272617    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:14:19.255721    2960 [ld:srv:WB1] LogsConfigManager.cpp:165] start() Starting LogsConfig Manager RSM
I0917 02:14:19.283126    2960 [ld:srv:WB1] LogsConfigManager.cpp:206] start() Starting LogsConfig Replicated State Machine
E0917 02:14:19.261538    2931 [ld:srv:WG3] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387903. All sequencer nodes are unavailable.
I0917 02:14:19.264095    2969 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [maintenancelog] Retrieving tail lsn of delta log...
I0917 02:14:19.349494    2969 [ld:srv:WB3] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.085s to write().
I0917 02:14:19.289331    2960 [ld:srv:WB1] ReplicatedStateMachine-inl.h:38] startFetchingSnapshot() [logsconfig] Using RSMSnapshotStore...
I0917 02:14:19.336902    2931 [ld:srv:WG3] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.075s to write().
E0917 02:14:19.373725    2931 [ld:srv:WG3] SequencerRouter.cpp:105] onFailure() Error during sequencer routing for log 4611686018427387903 (NOSEQUENCER), request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7f4ca85ab028].
E0917 02:14:19.358055    2935 [ld:srv:WG4] SequencerRouter.cpp:56] operator()() Error during sequencer lookup for log 4611686018427387899 (NOSEQUENCER), reporting NOSEQUENCER.
W0917 02:14:19.386951    2935 [ld:srv:WG4] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387899 (rqid:25769803779, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
I0917 02:14:19.365757    2960 [ld:srv:WB1] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.076s to write().
I0917 02:14:19.411568    2960 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1294] initSnapshotFetchTimer() [logsconfig] Creating timer to fetch snapshots ...
W0917 02:14:19.381419    2931 [ld:srv:WG3] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387903, rqid:25769803777, ctx:rsm, err(NOSEQUENCER)
W0917 02:14:19.426513    2931 [ld:srv:WG3] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387903 (rqid:25769803777, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
E0917 02:14:19.400945    2969 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:25769803779) for log:4611686018427387899, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
E0917 02:14:19.432426    2969 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:25769803777) for log:4611686018427387903, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:14:19.422761    2577 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server LogDevice Admin API Service will listen on port 41081
I0917 02:14:19.445501    2577 [logdeviced-main] Server.cpp:1540] createAndAttachMaintenanceManager() Not initializing MaintenanceManager since it is disabled in settings
I0917 02:14:19.451906    2743 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:14:19.451944    2577 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: s2s-api
I0917 02:14:19.454065    2743 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:14:19.457655    2577 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server s2s-api will listen on port 41085
I0917 02:14:19.466154    2577 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: c2s-api
I0917 02:14:19.473054    2577 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server c2s-api will listen on port 41086
I0917 02:14:19.475561    2577 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:19.480588    2587 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:19.487497    2577 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:19.515704    2588 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:19.518924    2577 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server s2s-api
I0917 02:14:19.520463    2951 [ld:srv:WF0] FailureDetector.cpp:228] startGetClusterState() Sending GET_CLUSTER_STATE to build initial FD cluster view
I0917 02:14:19.536867    2951 [ld:srv:WF0] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket N0:1(127.0.0.1:41091) hit error AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused)
I0917 02:14:19.542529    2951 [ld:srv:WF0] GetClusterStateRequest.cpp:252] onError() Retrieving the state of the cluster failed. sending another wave.
E0917 02:14:19.549288    2951 [ld:srv:WF0] GetClusterStateRequest.cpp:243] onError() Retrieving the state of the cluster failed. giving up.
E0917 02:14:19.551887    2951 [ld:srv:WF0] FailureDetector.cpp:243] operator()() Unable to refresh cluster state: FAILED: request failed
I0917 02:14:19.557621    2951 [ld:srv:WF0] FailureDetector.cpp:288] buildInitialState() Wait over
I0917 02:14:19.560907    2951 [ld:srv:WF0] FailureDetector.cpp:344] buildInitialState() Initializing DomainIsolationChecker
I0917 02:14:19.578570    2951 [ld:srv:WF0] FailureDetector.cpp:915] startSuspectTimer() Starting suspect state timer
I0917 02:14:19.581456    2951 [ld:srv:WF0] FailureDetector.cpp:1285] updateNodeState() N1 transitioned from DEAD to ALIVE, FD State:(gossip: 0, instance-id: 0, failover: 0, starting: 1)
I0917 02:14:19.583808    2951 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N1 changed from DEAD to STARTING
I0917 02:14:19.587695    2951 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting suspect-state-finished message.
I0917 02:14:19.592782    2951 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844858861 to node WF0:N4:1 (127.0.0.1:41047)
I0917 02:14:19.588238    2577 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server c2s-api
I0917 02:14:19.596752    2951 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844858861 to node WF0:N3:1 (127.0.0.1:41058)
I0917 02:14:19.616431    2951 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting bringup message.
I0917 02:14:19.628506    2951 [ld:srv:WF0] FailureDetector.cpp:937] startGossiping() Start Gossiping.
I0917 02:14:19.632721    2951 [ld:srv:WF0] FailureDetector.cpp:925] operator()() Suspect timeout expired
I0917 02:14:19.639236    2577 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server LogDevice Admin API Service
W0917 02:14:19.652353    2951 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() skipped at least 10 log entries
W0917 02:14:19.670427    2951 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.020s, source: [Message sent/received: GET_CLUSTER_STATE]
I0917 02:14:19.726317    2577 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:19.739881    2589 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:19.742860    2951 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N2:1 (127.0.0.1:41069): CONNFAILED: connection failed. Trying another node.
I0917 02:14:19.748912    2577 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:19.755875    2587 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:19.767567    2951 [ld:srv:WF0] ProtocolHandler.cpp:127] notifyErrorOnSocket() skipped at least 10 log entries
I0917 02:14:19.779505    2951 [ld:srv:WF0] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket N2:1(127.0.0.1:41069) hit error AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused)
I0917 02:14:19.773483    2577 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:19.784501    2587 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
W0917 02:14:19.792523    2951 [ld:srv:WF0] FailureDetector.cpp:1529] onGossipMessageSent() Could not send gossip to WF0:N4:1 (127.0.0.1:41047): CONNFAILED: connection failed. Consecutively failed to send 5 gossips.
W0917 02:14:19.803251    2951 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.011s, source: [Message sent/received: GOSSIP]
I0917 02:14:19.798540    2577 [logdeviced-main] main.cpp:464] main() Listeners initialized
I0917 02:14:20.190044    2951 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() skipped at least 10 log entries
I0917 02:14:20.198952    2951 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N3:1 (127.0.0.1:41058): CONNFAILED: connection failed. Trying another node.
W0917 02:14:20.204914    2951 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() skipped at least 1 log entries
W0917 02:14:20.230062    2951 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.015s, source: [Message sent/received: GOSSIP]
W0917 02:14:20.403275    2951 [ld:srv:WF0] FailureDetector.cpp:496] gossip() Unable to find a node to send a gossip message to
I0917 02:14:20.417274    2960 [ld:srv:WB1] ReplicatedStateMachine-inl.h:130] getSnapshot() [logsconfig] Fetching snapshot with ver:e0n1, (waiting_for_snapshot_:LSN_INVALID, version_:e0n1). sync_state_:0
I0917 02:14:20.438643    2925 [ld:srv:WG1] GET_SEQ_STATE_Message.cpp:238] getSequencer() Sequencer for log:4611686018427387900 is absent, state=UNAVAILABLE, cur_epoch=0, attempting to activate it upon receiving GSS (rqid:42949672961, ctx:sync-sequencer, min_epoch:none) from WG1:C1 (127.0.0.1:41054)
I0917 02:14:20.452775    2923 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:238] getSequencer() Sequencer for log:4611686018427387903 is absent, state=UNAVAILABLE, cur_epoch=0, attempting to activate it upon receiving GSS (rqid:25769803781, ctx:rsm, min_epoch:none) from WG0:C3 (127.0.0.1:41058)
I0917 02:14:20.546479    2935 [ld:srv:WG4] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387899, rqid:25769803780, ctx:rsm) from WG4:C2 (127.0.0.1:41056), but its data log sequencer's state is ACTIVATING
W0917 02:14:20.559784    2935 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.121s, source: [Message sent/received: GET_SEQ_STATE]
I0917 02:14:20.570848    2935 [ld:srv:WG4] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 4611686018427387899 epoch 6.
I0917 02:14:20.577130    2935 [ld:srv:WG4] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 4611686018427387899: {[E:1 (at 2021-09-17 02:14:20.454) since:1 (at 2021-09-17 02:10:15.170) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S1,N1:S1,N2:S1,N3:S1,N4:S1} W:[]], Until:6}.
I0917 02:14:20.574025    2925 [ld:srv:WG1] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387900, rqid:42949672961, ctx:sync-sequencer) from WG1:C1 (127.0.0.1:41054), but its data log sequencer's state is ACTIVATING
I0917 02:14:20.579913    2935 [ld:srv:WG4] AllSequencers.cpp:527] onEpochMetaDataFromEpochStore() Activated a sequencer for log 4611686018427387899 (reason: GET_SEQ_STATE) with epoch 6, metadata: [E:6 (at 2021-09-17 02:14:20.454) since:1 (at 2021-09-17 02:10:15.170) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S1,N1:S1,N2:S1,N3:S1,N4:S1} W:[]]. Activation Result: RECOVERY.
I0917 02:14:20.581261    2926 [ld:srv:WG2] PeriodicReleases.cpp:416] execute() Start broadcasting releases for log 4611686018427387899.
I0917 02:14:20.603817    2926 [ld:srv:WG2] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 13835058055282163707 epoch 6.
I0917 02:14:20.582046    2923 [ld:srv:WG0] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 4611686018427387903 epoch 6.
I0917 02:14:20.590495    2925 [ld:srv:WG1] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 4611686018427387900 epoch 6.
I0917 02:14:20.620864    2925 [ld:srv:WG1] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 4611686018427387900: {[E:1 (at 2021-09-17 02:14:20.467) since:1 (at 2021-09-17 02:10:15.391) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S0,N1:S0,N2:S0,N3:S0,N4:S0} W:[]], Until:6}.
I0917 02:14:20.600644    2935 [ld:srv:WG4] MetaDataLogTrimmer.cpp:115] schedulePeriodicTrimming() Will run periodic trimming every ~7200000 s for 4611686018427387899
I0917 02:14:20.607835    2926 [ld:srv:WG2] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 13835058055282163707: {[E:1 (at -inf) since:1 (at -inf) R:[node: 3] V:2 flags: params:{target:0 seed:0 signature:0} N:{N0:S1,N1:S1,N2:S1,N3:S1,N4:S1} W:[]], Until:6}.
I0917 02:14:20.639624    2926 [ld:srv:WG2] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 13835058055282163707 with next_epoch 6
I0917 02:14:20.612183    2923 [ld:srv:WG0] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 4611686018427387903: {[E:1 (at 2021-09-17 02:14:20.500) since:1 (at 2021-09-17 02:10:15.661) R:[node: 3] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S1,N1:S1,N2:S1,N3:S1,N4:S1} W:[]], Until:6}.
I0917 02:14:20.649802    2923 [ld:srv:WG0] AllSequencers.cpp:527] onEpochMetaDataFromEpochStore() Activated a sequencer for log 4611686018427387903 (reason: GET_SEQ_STATE) with epoch 6, metadata: [E:6 (at 2021-09-17 02:14:20.500) since:1 (at 2021-09-17 02:10:15.661) R:[node: 3] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S1,N1:S1,N2:S1,N3:S1,N4:S1} W:[]]. Activation Result: RECOVERY.
I0917 02:14:20.628438    2925 [ld:srv:WG1] AllSequencers.cpp:527] onEpochMetaDataFromEpochStore() Activated a sequencer for log 4611686018427387900 (reason: GET_SEQ_STATE) with epoch 6, metadata: [E:6 (at 2021-09-17 02:14:20.467) since:1 (at 2021-09-17 02:10:15.391) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S0,N1:S0,N2:S0,N3:S0,N4:S0} W:[]]. Activation Result: RECOVERY.
I0917 02:14:20.629285    2931 [ld:srv:WG3] PeriodicReleases.cpp:416] execute() Start broadcasting releases for log 4611686018427387900.
I0917 02:14:20.633402    2935 [ld:srv:WG4] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 4611686018427387899 with next_epoch 6
I0917 02:14:20.668371    2925 [ld:srv:WG1] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 13835058055282163711 epoch 6.
I0917 02:14:20.683463    2925 [ld:srv:WG1] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 13835058055282163711: {[E:1 (at -inf) since:1 (at -inf) R:[node: 3] V:2 flags: params:{target:0 seed:0 signature:0} N:{N0:S1,N1:S1,N2:S1,N3:S1,N4:S1} W:[]], Until:6}.
I0917 02:14:20.671479    2931 [ld:srv:WG3] PeriodicReleases.cpp:416] execute() Start broadcasting releases for log 4611686018427387903.
W0917 02:14:20.700390    2925 [ld:srv:WG1] Worker.cpp:1000] onStoppedRunning() skipped at least 10 log entries
W0917 02:14:20.720896    2925 [ld:srv:WG1] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.032s, source: [Request: START_METADATA_LOG_RECOVERY]
I0917 02:14:20.704966    2935 [ld:srv:WG4] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 13835058055282163708 epoch 6.
I0917 02:14:20.725006    2925 [ld:srv:WG1] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 13835058055282163711 with next_epoch 6
I0917 02:14:20.747068    2926 [ld:srv:WG2] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [2, 5] of log 13835058055282163707
W0917 02:14:20.725423    2923 [ld:srv:WG0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.061s, source: [Request: GET_TRIM_POINT]
I0917 02:14:20.766391    2923 [ld:srv:WG0] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 4611686018427387900 with next_epoch 6
I0917 02:14:20.726517    2931 [ld:srv:WG3] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 4611686018427387903 with next_epoch 6
I0917 02:14:20.732220    2935 [ld:srv:WG4] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 13835058055282163708: {[E:1 (at -inf) since:1 (at -inf) R:[node: 3] V:2 flags: params:{target:0 seed:0 signature:0} N:{N0:S0,N1:S0,N2:S0,N3:S0,N4:S0} W:[]], Until:6}.
I0917 02:14:20.802813    2935 [ld:srv:WG4] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [2, 5] of log 4611686018427387899
I0917 02:14:20.803843    2923 [ld:srv:WG0] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [2, 5] of log 4611686018427387900
I0917 02:14:20.825883    2935 [ld:srv:WG4] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 13835058055282163708 with next_epoch 6
I0917 02:14:20.831579    2925 [ld:srv:WG1] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [4, 5] of log 13835058055282163711
I0917 02:14:20.825968    2951 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() skipped at least 8 log entries
I0917 02:14:20.852611    2951 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N3:1 (127.0.0.1:41058): CONNFAILED: connection failed. Trying another node.
I0917 02:14:20.827018    2931 [ld:srv:WG3] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [4, 5] of log 4611686018427387903
I0917 02:14:20.879949    2931 [ld:srv:WG3] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.053s to write().
I0917 02:14:20.968877    2935 [ld:srv:WG4] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [2, 5] of log 13835058055282163708
I0917 02:14:21.097368    2951 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N0:1 with instance id:1631844859887, sent_time:1631844861023ms
I0917 02:14:21.109432    2951 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from DEAD to STARTING
I0917 02:14:21.115694    2951 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N0 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844859887, failover: 0, starting: 1)
I0917 02:14:21.124773    2951 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N0:1 with instance id:1631844859887, sent_time:1631844861036ms
I0917 02:14:21.118370    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N0
I0917 02:14:21.158854    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=3, #adjusted cluster size=5, threshold=35%, actual=60%
I0917 02:14:21.153383    2951 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N0
I0917 02:14:21.500731    2951 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N4:1 with instance id:1631844860532, sent_time:1631844861479ms
I0917 02:14:21.504086    2951 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from DEAD to STARTING
I0917 02:14:21.508735    2951 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N4 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844860532, failover: 0, starting: 1)
W0917 02:14:21.511842    2951 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() skipped at least 17 log entries
I0917 02:14:21.508830    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N4
W0917 02:14:21.514817    2951 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.011s, source: [Message sent/received: GOSSIP]
I0917 02:14:21.522569    2951 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N4:1 with instance id:1631844860532, sent_time:1631844861486ms
I0917 02:14:21.523734    2951 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N4
I0917 02:14:21.673071    2931 [ld:srv:WG3] EpochRecovery.cpp:1502] onDigestMayHaveBecomeComplete() Completing an authoritative partial digest for epoch 4 of log 4611686018427387903 because grace period with timeout of 100ms expired. State: {s:N3:S1 m:N0:S1,N1:S1,N2:S1,N4:S1 DIGEST}
I0917 02:14:21.673320    2925 [ld:srv:WG1] EpochRecovery.cpp:566] startMutations() Log 13835058055282163711 epoch 4 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 0, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_INCOMPLETE, mutation set: {N0:S1, N1:S1, N2:S1, N4:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163711 N:e1n1 T:0 AOM:{246:0} F:16], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:13835058055282163711 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {s:N3:S1 m:N0:S1,N1:S1,N2:S1,N4:S1 MUTATION}.
I0917 02:14:21.675071    2931 [ld:srv:WG3] EpochRecovery.cpp:566] startMutations() Log 4611686018427387903 epoch 4 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_INCOMPLETE, mutation set: {N0:S1, N1:S1, N2:S1, N4:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387903 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387903 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {s:N3:S1 m:N0:S1,N1:S1,N2:S1,N4:S1 MUTATION}.
I0917 02:14:21.688278    2931 [ld:srv:WG3] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:13835058055282163707, rqid:30064771090, ctx:start-message) from WG3:C5 (127.0.0.1:41090), but its data log sequencer's state is Recovery Incomplete
W0917 02:14:21.680337    2935 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.012s, source: [Message sent/received: START]
I0917 02:14:21.813675    2923 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387899, rqid:34359738369, ctx:start-message) from WG0:C12 (127.0.0.1:41238), but its data log sequencer's state is Recovery Incomplete
I0917 02:14:21.818487    2925 [ld:srv:WG1] GET_SEQ_STATE_Message.cpp:831] shouldRedirectOrFail() Returning status=REDIRECTED to [WG1:C1 (127.0.0.1:41054)] for log:4611686018427387900. Redirect target is Node N0:1
I0917 02:14:21.823079    2923 [ld:srv:WG0] SequencerRouter.cpp:149] onRedirected() Got redirected from N1:1 to N0:1 for log:4611686018427387900, status:REDIRECTED, request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7f4ca8daa028]
I0917 02:14:21.837924    2935 [ld:srv:WG4] EpochRecovery.cpp:1502] onDigestMayHaveBecomeComplete() Completing an authoritative partial digest for epoch 2 of log 4611686018427387899 because grace period with timeout of 100ms expired. State: {s:N3:S1 m:N0:S1,N1:S1,N2:S1,N4:S1 DIGEST}
I0917 02:14:21.860438    2935 [ld:srv:WG4] EpochRecovery.cpp:566] startMutations() Log 4611686018427387899 epoch 2 final digest before mutation: consensus LNG 0, start esn: 1, 1 entries, first esn: 1, last esn: 1, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_INCOMPLETE, mutation set: {N0:S1, N1:S1, N2:S1, N4:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {s:N3:S1 m:N0:S1,N1:S1,N2:S1,N4:S1 MUTATION}.
I0917 02:14:21.866055    2935 [ld:srv:WG4] EpochRecovery.cpp:1502] onDigestMayHaveBecomeComplete() Completing an authoritative partial digest for epoch 2 of log 13835058055282163708 because grace period with timeout of 100ms expired. State: {s:N3:S0 m:N0:S0,N1:S0,N2:S0,N4:S0 DIGEST}
I0917 02:14:21.868910    2935 [ld:srv:WG4] EpochRecovery.cpp:566] startMutations() Log 13835058055282163708 epoch 2 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 0, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_INCOMPLETE, mutation set: {N0:S0, N1:S0, N2:S0, N4:S0}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163708 N:e1n1 T:0 AOM:{246:0} F:16], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:13835058055282163708 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {s:N3:S0 m:N0:S0,N1:S0,N2:S0,N4:S0 MUTATION}.
I0917 02:14:21.849700    2923 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:831] shouldRedirectOrFail() Returning status=REDIRECTED to [WG0:C3 (127.0.0.1:41058)] for log:4611686018427387903. Redirect target is Node N0:1
I0917 02:14:21.859291    2931 [ld:srv:WG3] Mutator.cpp:400] finalize() Mutator 4611686018427387903e4n1 completed (OK). Trace: W1{N1:S1,N0:S1,N4:S1};X:N1:S1:K;X:N0:S1:K;X:N4:S1:K;Y1:N4:S1:K;Y1:N1:S1:K;Y1:N0:S1:K;done:can_replicate:OK;
I0917 02:14:21.909431    2951 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N2:1 with instance id:1631844860573, sent_time:1631844861829ms
I0917 02:14:21.911098    2951 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from DEAD to STARTING
I0917 02:14:21.913452    2951 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N2 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844860573, failover: 0, starting: 1)
I0917 02:14:21.915294    2951 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N2
I0917 02:14:21.882314    2935 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163708 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:21.904033    2923 [ld:srv:WG0] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.054s to write().
I0917 02:14:21.927596    2931 [ld:srv:WG3] SequencerRouter.cpp:149] onRedirected() Got redirected from N1:1 to N0:1 for log:4611686018427387903, status:REDIRECTED, request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7f4ca85ab568]
I0917 02:14:21.921071    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N2
W0917 02:14:21.954860    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:734] adjustRebuildingThrottle() Exiting throttling mode: #draining=0, #rebuilding=0, #triggers=1, #adjusted cluster size=5, threshold=35%, actual=20%
I0917 02:14:21.956803    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:751] adjustRebuildingThrottle() Not triggering new rebuildings until 2021-09-17 02:34:21.956: It's too soon after exiting throttling mode
I0917 02:14:21.930684    2908 [ld:s1:default:0] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 4611686018427387903 epoch 2: cache not found but cannot declare no data. head epoch : 4, last_nonauthoritative_epoch: 1.
I0917 02:14:21.954553    2923 [ld:srv:WG0] LogRecoveryRequest.cpp:1468] complete() Log recovery for log 4611686018427387900 failed with error code PREEMPTED, next_epoch:6
W0917 02:14:21.969854    2923 [ld:srv:WG0] Worker.cpp:1000] onStoppedRunning() skipped at least 10 log entries
I0917 02:14:21.958555    2931 [ld:srv:WG3] RecoveryNode.cpp:401] onDisconnect() Lost connection to N4:S1 while waiting for reply in state CLEANING during recovery of epoch 4 of log 4611686018427387903: CONNFAILED: connection failed
I0917 02:14:21.973834    2969 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [maintenancelog] Tail lsn of delta log is e6n0
W0917 02:14:21.982976    2923 [ld:srv:WG0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.015s, source: [Message sent/received: SEALED]
I0917 02:14:21.998070    2923 [ld:srv:WG0] CheckSealRequest.cpp:128] onSent() Sending a check-seal message to N4:S1 failed with err:CONNFAILED (log:4611686018427387899, rqid:55834574862, gss-rqid:34359738370)
I0917 02:14:21.987596    2935 [ld:srv:WG4] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [1, 1] for log 13835058055282163708.
I0917 02:14:22.007258    2935 [ld:srv:WG4] Mutator.cpp:400] finalize() Mutator 4611686018427387899e2n1 completed (OK). Trace: W1{N2:S1,N1:S1};X:N2:S1:K;X:N1:S1:K;Y1:N2:S1:K;Y1:N1:S1:K;done:can_replicate:OK;
W0917 02:14:21.999444    2969 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.026s, source: [Request: WORKER_CALLBACK_HELPER]
I0917 02:14:22.001584    2923 [ld:srv:WG0] CheckSealRequest.cpp:128] onSent() Sending a check-seal message to N4:S1 failed with err:CONNFAILED (log:4611686018427387899, rqid:55834574863, gss-rqid:55834574848)
I0917 02:14:22.027131    2931 [ld:srv:WG3] LogRecoveryRequest.cpp:1468] complete() Log recovery for log 4611686018427387903 failed with error code PREEMPTED, next_epoch:6
I0917 02:14:22.037166    2931 [ld:srv:WG3] CLEANED_Message.cpp:82] onReceived() Got a stale CLEANED message for log 4611686018427387903 epoch 4 id 13 from WG3:N0:1 (127.0.0.1:41089). No epoch recovery machine is active for log. Ignoring.
I0917 02:14:22.032706    2935 [ld:srv:WG4] RecoveryNode.cpp:378] onMessageSent() Failed to send a CLEAN message to N4:S1 during recovery of epoch 2 of log 4611686018427387899: CONNFAILED: connection failed
I0917 02:14:22.067894    2935 [ld:srv:WG4] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387899, rqid:30064771092, ctx:store-message) from WG4:C2 (127.0.0.1:41056), but its data log sequencer's state is Recovery Incomplete
I0917 02:14:22.078287    2925 [ld:srv:WG1] RecoveryNode.cpp:378] onMessageSent() Failed to send a CLEAN message to N4:S1 during recovery of epoch 4 of log 13835058055282163711: CONNFAILED: connection failed
I0917 02:14:22.081755    2926 [ld:srv:WG2] EpochRecovery.cpp:1502] onDigestMayHaveBecomeComplete() Completing an authoritative partial digest for epoch 2 of log 13835058055282163707 because grace period with timeout of 100ms expired. State: {s:N3:S1,N4:S1 m:N0:S1,N1:S1,N2:S1 DIGEST}
I0917 02:14:22.087816    2935 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:22.093000    2926 [ld:srv:WG2] EpochRecovery.cpp:566] startMutations() Log 13835058055282163707 epoch 2 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 0, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_INCOMPLETE, mutation set: {N0:S1, N1:S1, N2:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163707 N:e1n1 T:0 AOM:{246:0} F:16], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:13835058055282163707 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {s:N3:S1,N4:S1 m:N0:S1,N1:S1,N2:S1 MUTATION}.
I0917 02:14:22.095703    2951 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() skipped at least 4 log entries
I0917 02:14:22.106319    2951 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N3:1 (127.0.0.1:41058): CONNFAILED: connection failed. Trying another node.
I0917 02:14:22.110016    2931 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163707 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:22.100197    2935 [ld:srv:WG4] LogRecoveryRequest.cpp:1468] complete() Log recovery for log 13835058055282163708 failed with error code PREEMPTED, next_epoch:6
W0917 02:14:22.139459    2935 [ld:srv:WG4] MetaDataLogWriter.cpp:451] onWriteMetaDataRecordDone() WriteMetaDataRecord state machine (epoch 6) finished with status PREEMPTED: log writer was preempted by another one for data log 4611686018427387900
W0917 02:14:22.143777    2935 [ld:srv:WG4] MetaDataLogWriter.cpp:529] onWriteMetaDataRecordDone() WriteMetaDataRecord state machine (epoch 6) finished with status PREEMPTED for data log 4611686018427387900, sequencer state: PREEMPTED.
I0917 02:14:22.155490    2935 [ld:srv:WG4] CLEANED_Message.cpp:82] onReceived() Got a stale CLEANED message for log 13835058055282163708 epoch 2 id 17 from WG4:N2:1 (127.0.0.1:41067). No epoch recovery machine is active for log. Ignoring.
I0917 02:14:22.173494    2923 [ld:srv:WG0] CheckSealRequest.cpp:235] onTimeout() Timed out on replies for log:4611686018427387899 for CheckSealRequest(rqid:55834574862, gss-rqid:34359738370), expected_from:[N1:S1 N4:S1 ], recvd_from:[N1:S1 N4:S1 ], replies_successful=1
I0917 02:14:22.180350    2923 [ld:srv:WG0] CheckSealRequest.cpp:235] onTimeout() Timed out on replies for log:4611686018427387899 for CheckSealRequest(rqid:55834574863, gss-rqid:55834574848), expected_from:[N1:S1 N4:S1 ], recvd_from:[N1:S1 N4:S1 ], replies_successful=1
I0917 02:14:22.211042    2935 [ld:srv:WG4] RecoveryNode.cpp:378] onMessageSent() Failed to send a CLEAN message to N4:S1 during recovery of epoch 2 of log 4611686018427387899: CONNFAILED: connection failed
I0917 02:14:22.245804    2969 [ld:srv:WB3] ClientReadStream.cpp:650] sendStart() Cannot send START message to N3:S1 for log 4611686018427387899: DISABLED: server is marked down
I0917 02:14:22.299622    2925 [ld:srv:WG1] RecoveryNode.cpp:378] onMessageSent() Failed to send a CLEAN message to N4:S1 during recovery of epoch 4 of log 13835058055282163711: CONNFAILED: connection failed
I0917 02:14:22.436693    2935 [ld:srv:WG4] RecoveryNode.cpp:378] onMessageSent() Failed to send a CLEAN message to N4:S1 during recovery of epoch 2 of log 4611686018427387899: CONNFAILED: connection failed
I0917 02:14:22.480018    2926 [ld:srv:WG2] EpochRecovery.cpp:1502] onDigestMayHaveBecomeComplete() Completing an authoritative partial digest for epoch 3 of log 13835058055282163707 because grace period with timeout of 100ms expired. State: {s:N3:S1,N4:S1 m:N0:S1,N1:S1,N2:S1 DIGEST}
I0917 02:14:22.482858    2926 [ld:srv:WG2] EpochRecovery.cpp:566] startMutations() Log 13835058055282163707 epoch 3 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 0, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_INCOMPLETE, mutation set: {N0:S1, N1:S1, N2:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163707 N:e1n1 T:0 AOM:{246:0} F:16], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:13835058055282163707 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {s:N3:S1,N4:S1 m:N0:S1,N1:S1,N2:S1 MUTATION}.
I0917 02:14:22.494646    2931 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163707 has already been cleaned. No purge needed. last clean epoch: 2, purge to: 2.
I0917 02:14:22.607510    2935 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163708 has already been cleaned. No purge needed. last clean epoch: 2, purge to: 2.
I0917 02:14:22.705613    2925 [ld:srv:WG1] RecoveryNode.cpp:378] onMessageSent() Failed to send a CLEAN message to N4:S1 during recovery of epoch 4 of log 13835058055282163711: CONNFAILED: connection failed
W0917 02:14:22.724905    2926 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() skipped at least 15 log entries
W0917 02:14:22.726478    2926 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.018s, source: [Message sent/received: CLEANED]
I0917 02:14:22.838757    2926 [ld:srv:WG2] EpochRecovery.cpp:1502] onDigestMayHaveBecomeComplete() Completing an authoritative partial digest for epoch 4 of log 13835058055282163707 because grace period with timeout of 100ms expired. State: {s:N3:S1,N4:S1 m:N0:S1,N1:S1,N2:S1 DIGEST}
I0917 02:14:22.840937    2926 [ld:srv:WG2] EpochRecovery.cpp:566] startMutations() Log 13835058055282163707 epoch 4 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 0, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_INCOMPLETE, mutation set: {N0:S1, N1:S1, N2:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163707 N:e1n1 T:0 AOM:{246:0} F:16], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:13835058055282163707 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {s:N3:S1,N4:S1 m:N0:S1,N1:S1,N2:S1 MUTATION}.
I0917 02:14:22.844614    2931 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163707 has already been cleaned. No purge needed. last clean epoch: 3, purge to: 3.
I0917 02:14:22.845103    2935 [ld:srv:WG4] ProtocolHandler.cpp:127] notifyErrorOnSocket() skipped at least 100 log entries
I0917 02:14:22.850458    2935 [ld:srv:WG4] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket N4:1(127.0.0.1:41045) hit error AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused)
I0917 02:14:22.852364    2935 [ld:srv:WG4] RecoveryNode.cpp:378] onMessageSent() Failed to send a CLEAN message to N4:S1 during recovery of epoch 2 of log 4611686018427387899: CONNFAILED: connection failed
I0917 02:14:22.953976    2935 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163708 has already been cleaned. No purge needed. last clean epoch: 3, purge to: 3.
I0917 02:14:23.062870    2935 [ld:srv:WG4] PurgeUncleanEpochs.cpp:592] complete() skipped at least 5 log entries
I0917 02:14:23.063485    2923 [ld:srv:WG0] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 4611686018427387903 shard 1 epochs [2,3] purge_to 3 got at least one reply with E::EMPTY, for the epoch 2.
I0917 02:14:23.064708    2935 [ld:srv:WG4] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [3, 3] for log 13835058055282163708.
I0917 02:14:23.067044    2923 [ld:srv:WG0] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 4611686018427387903 shard 1 epochs [2,3] purge_to 3 got at least one reply with E::EMPTY, for the epoch 3.
W0917 02:14:23.073814    2923 [ld:srv:WG0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.010s, source: [Message sent/received: GET_EPOCH_RECOVERY_METADATA_REPLY]
I0917 02:14:23.078354    2923 [ld:srv:WG0] PurgeUncleanEpochs.cpp:401] onGetEpochRecoveryMetadataComplete() Nothing to purge. Epoch is empty locally and EpochRecoveryMetadata consensus is also EMPTY for log: 4611686018427387903,epoch:3
I0917 02:14:23.144430    2923 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:238] getSequencer() Sequencer for log:4611686018427387898 is absent, state=UNAVAILABLE, cur_epoch=0, attempting to activate it upon receiving GSS (rqid:21474836484, ctx:rsm, min_epoch:none) from WG0:C19 (127.0.0.1:41568)
I0917 02:14:23.167341    2923 [ld:srv:WG0] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 4611686018427387898 epoch 6.
I0917 02:14:23.169470    2923 [ld:srv:WG0] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 4611686018427387898: {[E:1 (at 2021-09-17 02:14:23.154) since:1 (at 2021-09-17 02:10:14.514) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S0,N1:S0,N2:S0,N3:S0,N4:S0} W:[]], Until:6}.
I0917 02:14:23.171149    2931 [ld:srv:WG3] PeriodicReleases.cpp:416] execute() Start broadcasting releases for log 4611686018427387898.
I0917 02:14:23.171149    2923 [ld:srv:WG0] AllSequencers.cpp:527] onEpochMetaDataFromEpochStore() Activated a sequencer for log 4611686018427387898 (reason: GET_SEQ_STATE) with epoch 6, metadata: [E:6 (at 2021-09-17 02:14:23.154) since:1 (at 2021-09-17 02:10:14.514) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S0,N1:S0,N2:S0,N3:S0,N4:S0} W:[]]. Activation Result: RECOVERY.
I0917 02:14:23.178361    2925 [ld:srv:WG1] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 13835058055282163706 epoch 6.
I0917 02:14:23.180477    2951 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() skipped at least 1 log entries
I0917 02:14:23.180702    2923 [ld:srv:WG0] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 4611686018427387898 with next_epoch 6
I0917 02:14:23.180926    2925 [ld:srv:WG1] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 13835058055282163706: {[E:1 (at -inf) since:1 (at -inf) R:[node: 3] V:2 flags: params:{target:0 seed:0 signature:0} N:{N0:S0,N1:S0,N2:S0,N3:S0,N4:S0} W:[]], Until:6}.
I0917 02:14:23.184960    2951 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N3:1 (127.0.0.1:41058): CONNFAILED: connection failed. Trying another node.
I0917 02:14:23.194781    2925 [ld:srv:WG1] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 13835058055282163706 with next_epoch 6
I0917 02:14:23.201787    2926 [ld:srv:WG2] EpochRecovery.cpp:1502] onDigestMayHaveBecomeComplete() Completing an authoritative partial digest for epoch 5 of log 13835058055282163707 because grace period with timeout of 100ms expired. State: {s:N3:S1,N4:S1 m:N0:S1,N1:S1,N2:S1 DIGEST}
I0917 02:14:23.217737    2926 [ld:srv:WG2] EpochRecovery.cpp:566] startMutations() Log 13835058055282163707 epoch 5 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 0, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_INCOMPLETE, mutation set: {N0:S1, N1:S1, N2:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163707 N:e1n1 T:0 AOM:{246:0} F:16], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:13835058055282163707 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {s:N3:S1,N4:S1 m:N0:S1,N1:S1,N2:S1 MUTATION}.
I0917 02:14:23.218114    2923 [ld:srv:WG0] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [2, 5] of log 4611686018427387898
I0917 02:14:23.226633    2931 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163707 has already been cleaned. No purge needed. last clean epoch: 4, purge to: 4.
I0917 02:14:23.256886    2931 [ld:srv:WG3] CLEANED_Message.cpp:82] onReceived() Got a stale CLEANED message for log 4611686018427387903 epoch 4 id 13 from WG3:N1:1 (127.0.0.1:41078). No epoch recovery machine is active for log. Ignoring.
I0917 02:14:23.228991    2925 [ld:srv:WG1] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [2, 5] of log 13835058055282163706
I0917 02:14:23.279551    2925 [ld:srv:WG1] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.050s to write().
W0917 02:14:23.276314    2931 [ld:srv:WG3] Worker.cpp:1000] onStoppedRunning() skipped at least 10 log entries
W0917 02:14:23.287317    2931 [ld:srv:WG3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.019s, source: [Message sent/received: CLEANED]
I0917 02:14:23.400453    2935 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163708 has already been cleaned. No purge needed. last clean epoch: 4, purge to: 4.
I0917 02:14:23.499657    2935 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387903 has already been cleaned. No purge needed. last clean epoch: 4, purge to: 4.
I0917 02:14:23.503268    2925 [ld:srv:WG1] EpochRecovery.cpp:1502] onDigestMayHaveBecomeComplete() Completing an authoritative partial digest for epoch 2 of log 13835058055282163706 because grace period with timeout of 100ms expired. State: {s:N3:S0,N4:S0 m:N0:S0,N1:S0,N2:S0 DIGEST}
I0917 02:14:23.504695    2925 [ld:srv:WG1] EpochRecovery.cpp:566] startMutations() Log 13835058055282163706 epoch 2 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 0, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_INCOMPLETE, mutation set: {N0:S0, N1:S0, N2:S0}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163706 N:e1n1 T:0 AOM:{246:0} F:16], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:13835058055282163706 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {s:N3:S0,N4:S0 m:N0:S0,N1:S0,N2:S0 MUTATION}.
W0917 02:14:23.507620    2926 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.027s, source: [Message sent/received: CLEANED]
I0917 02:14:23.514458    2925 [ld:srv:WG1] RecoveryNode.cpp:378] onMessageSent() Failed to send a CLEAN message to N4:S1 during recovery of epoch 4 of log 13835058055282163711: CONNFAILED: connection failed
I0917 02:14:23.526050    2926 [ld:srv:WG2] LogRecoveryRequest.cpp:1463] complete() Log recovery completed for log 13835058055282163707, next_epoch:6
I0917 02:14:23.658561    2935 [ld:srv:WG4] RecoveryNode.cpp:378] onMessageSent() Failed to send a CLEAN message to N4:S1 during recovery of epoch 2 of log 4611686018427387899: CONNFAILED: connection failed
W0917 02:14:23.743783    2925 [ld:srv:WG1] Worker.cpp:1000] onStoppedRunning() skipped at least 1 log entries
W0917 02:14:23.752645    2925 [ld:srv:WG1] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.015s, source: [Message sent/received: CLEANED]
I0917 02:14:23.867409    2925 [ld:srv:WG1] EpochRecovery.cpp:1502] onDigestMayHaveBecomeComplete() Completing an authoritative partial digest for epoch 3 of log 13835058055282163706 because grace period with timeout of 100ms expired. State: {s:N3:S0,N4:S0 m:N0:S0,N1:S0,N2:S0 DIGEST}
I0917 02:14:23.869740    2925 [ld:srv:WG1] EpochRecovery.cpp:566] startMutations() Log 13835058055282163706 epoch 3 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 0, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_INCOMPLETE, mutation set: {N0:S0, N1:S0, N2:S0}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163706 N:e1n1 T:0 AOM:{246:0} F:16], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:13835058055282163706 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {s:N3:S0,N4:S0 m:N0:S0,N1:S0,N2:S0 MUTATION}.
W0917 02:14:23.877687    2925 [ld:srv:WG1] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.011s, source: [Message sent/received: GAP]
I0917 02:14:24.242302    2951 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() skipped at least 1 log entries
I0917 02:14:24.244388    2951 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N3:1 (127.0.0.1:41058): CONNFAILED: connection failed. Trying another node.
I0917 02:14:24.289271    2925 [ld:srv:WG1] EpochRecovery.cpp:1502] onDigestMayHaveBecomeComplete() Completing an authoritative partial digest for epoch 4 of log 13835058055282163706 because grace period with timeout of 100ms expired. State: {s:N3:S0,N4:S0 m:N0:S0,N1:S0,N2:S0 DIGEST}
I0917 02:14:24.292910    2925 [ld:srv:WG1] EpochRecovery.cpp:566] startMutations() Log 13835058055282163706 epoch 4 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 0, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_INCOMPLETE, mutation set: {N0:S0, N1:S0, N2:S0}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163706 N:e1n1 T:0 AOM:{246:0} F:16], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:13835058055282163706 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {s:N3:S0,N4:S0 m:N0:S0,N1:S0,N2:S0 MUTATION}.
I0917 02:14:24.363552    2931 [ld:srv:WG3] GET_SEQ_STATE_Message.cpp:831] shouldRedirectOrFail() Returning status=REDIRECTED to [WG3:C20 (127.0.0.1:41748)] for log:13835058055282163711. Redirect target is Node N0:1
I0917 02:14:24.368967    2926 [ld:srv:WG2] GET_SEQ_STATE_Message.cpp:831] shouldRedirectOrFail() Returning status=REDIRECTED to [WG2:C16 (127.0.0.1:41294)] for log:13835058055282163711. Redirect target is Node N0:1
I0917 02:14:24.409916    2926 [ld:srv:WG2] PurgeUncleanEpochs.cpp:592] complete() skipped at least 8 log entries
I0917 02:14:24.411681    2926 [ld:srv:WG2] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [3, 3] for log 13835058055282163706.
I0917 02:14:24.667736    2925 [ld:srv:WG1] EpochRecovery.cpp:566] startMutations() Log 13835058055282163706 epoch 5 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 0, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_INCOMPLETE, mutation set: {N0:S0, N1:S0, N2:S0}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163706 N:e1n1 T:0 AOM:{246:0} F:16], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:13835058055282163706 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {s:N3:S0,N4:S0 m:N0:S0,N1:S0,N2:S0 MUTATION}.
W0917 02:14:24.765767    2923 [ld:srv:WG0] Worker.cpp:1000] onStoppedRunning() skipped at least 3 log entries
W0917 02:14:24.779091    2923 [ld:srv:WG0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.010s, source: [None]
W0917 02:14:24.924318    2925 [ld:srv:WG1] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.030s, source: [Message sent/received: CLEANED]
I0917 02:14:24.932596    2925 [ld:srv:WG1] LogRecoveryRequest.cpp:1463] complete() Log recovery completed for log 13835058055282163706, next_epoch:6
I0917 02:14:25.131949    2925 [ld:srv:WG1] RecoveryNode.cpp:378] onMessageSent() Failed to send a CLEAN message to N4:S1 during recovery of epoch 4 of log 13835058055282163711: CONNFAILED: connection failed
I0917 02:14:25.179267    2951 [ld:srv:WF0] FailureDetector.cpp:1285] updateNodeState() N4 transitioned from ALIVE to DEAD, FD State:(gossip: 31, instance-id: 1631844860532, failover: 0, starting: 1)
I0917 02:14:25.181455    2951 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from STARTING to DEAD
I0917 02:14:25.187740    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N4 to execute in 1200s
W0917 02:14:25.189539    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:705] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=2, #adjusted cluster size=5, threshold=35%, actual=40%
I0917 02:14:25.191738    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() skipped at least 1 log entries
I0917 02:14:25.194314    2935 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=2, #adjusted cluster size=5, threshold=35%, actual=40%
I0917 02:14:25.200979    2935 [ld:srv:WG4] GET_SEQ_STATE_Message.cpp:567] continueExecution() skipped at least 10 log entries
I0917 02:14:25.202865    2935 [ld:srv:WG4] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387899, rqid:30064771092, ctx:store-message) from WG4:C2 (127.0.0.1:41056), but its data log sequencer's state is Recovery Incomplete
E0917 02:14:25.250914    2926 [ld:srv:WG2] WeightedCopySetSelector.cpp:1241] augment() Failed to select 3 nodes for rebuilding for log 13835058055282163711 because too many whole NODEs are unavailable. Copyset: []. Useful existing copies: 0. Nodeset: {N0:S1,N1:S1,N2:S1,N3:S1,N4:S1}. Unavailable nodes: {N3:S1,N1:S1,N4:S1}. Secondary replication: 3. NODE weights: [0.000(2.000-2.000), 2.000, 2.000, 0.000(2.000-2.000), 0.000(2.000-2.000)]
E0917 02:14:25.253040    2926 [ld:srv:WG2] NodeSetAccessor.cpp:224] pickWaveFromCopySet() Failed to pick a copyset for log 13835058055282163711, given exisiting nodes .
I0917 02:14:25.261420    2935 [ld:srv:WG4] RecoveryNode.cpp:201] transition() Failed to send CLEAN message to N4:S1 for epoch 2 of log 4611686018427387899: DISABLED: server is marked down
I0917 02:14:25.372013    2925 [ld:srv:WG1] GetSeqStateRequest.cpp:531] onReplyTimeout() Timed out waiting for GET_SEQ_STATE_REPLY for GetSeqStateRequest (rqid:30064771105, ctx:start-message) for log:13835058055282163711 from node N0:1
I0917 02:14:25.373650    2925 [ld:srv:WG1] SequencerRouter.cpp:321] onDeadNode() Node N0:1 unavailable for log:13835058055282163711, status=TIMEDOUT. request[type:GET_SEQ_STATE_REQ_TYPE, handler_:0x7f4cb1ffd0a8]
I0917 02:14:25.375869    2926 [ld:srv:WG2] GET_SEQ_STATE_Message.cpp:831] shouldRedirectOrFail() Returning status=REDIRECTED to [WG2:C6 (127.0.0.1:41114)] for log:13835058055282163711. Redirect target is Node N0:1
I0917 02:14:25.381065    2925 [ld:srv:WG1] SequencerRouter.cpp:149] onRedirected() Got redirected from N1:1 to N0:1 for log:13835058055282163711, status:REDIRECTED, request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7f4cb1ffd0a8]
I0917 02:14:25.455180    2969 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [eventlog] Tail lsn of delta log is e7n0
I0917 02:14:25.458005    2969 [ld:srv:WB3] ClientReadStream.cpp:650] sendStart() skipped at least 1 log entries
I0917 02:14:25.459768    2969 [ld:srv:WB3] ClientReadStream.cpp:650] sendStart() Cannot send START message to N3:S1 for log 13835058055282163711: DISABLED: server is marked down
I0917 02:14:25.500075    2969 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 2 is not available. Highest epoch known is 1.
W0917 02:14:25.502397    2969 [ld:srv:WB3] ClientReadStream.cpp:2476] updateCurrentMetaData() Existing epoch metadata has changed for log 4611686018427387903 on epoch 1, check metadata log!
I0917 02:14:25.523839    2969 [ld:srv:WB3] ClientReadStream.cpp:650] sendStart() skipped at least 10 log entries
I0917 02:14:25.526595    2969 [ld:srv:WB3] ClientReadStream.cpp:650] sendStart() Cannot send START message to N4:S1 for log 4611686018427387903: DISABLED: server is marked down
I0917 02:14:25.545922    2969 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [eventlog] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:14:25.547851    2969 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (1)
I0917 02:14:25.912166    2951 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N4:1 (127.0.0.1:41047): CONNFAILED: connection failed. Trying another node.
I0917 02:14:26.172536    2925 [ld:srv:WG1] RecoveryNode.cpp:401] onDisconnect() Lost connection to N2:S1 while waiting for reply in state CLEANING during recovery of epoch 4 of log 13835058055282163711: PEER_CLOSED: connection closed by peer
I0917 02:14:30.253838    4396 [logdeviced-main] main.cpp:399] main() Command line arguments: --local-log-store-path /data/store/N1:1/db --num-shards 2 --server-id y0g4eldim6 --log-file /data/store/N1:1/log --name Node1 --config-path file:/data/store/logdevice.conf --client-thrift-api-port 48449 --gossip-port 48443 --server-thrift-api-port 48448 --test-mode true --server-to-server-port 48447 --admin-port 48444 --loglevel info --port 48441 --sequencers lazy 
I0917 02:14:30.254886    4396 [logdeviced-main] main.cpp:403] main() Plugins loaded: {"Thrift client factory plugin":"built-in","ZookeeperClient factory":"built-in","ConfigSource factory":["built-in"],"PermissionChecker factory":"built-in","Build Info":"built-in","Plugin provider":["Built-in plugin provider","Static plug-in loader","Dynamic plugin loader"]}
I0917 02:14:30.255804    4396 [logdeviced-main] main.cpp:405] main() server starting
I0917 02:14:30.256754    4396 [logdeviced-main] main.cpp:410] main() version 99.99.99
I0917 02:14:30.257678    4396 [logdeviced-main] main.cpp:418] main() asserts off (NDEBUG set)
I0917 02:14:30.259170    4396 [logdeviced-main] TextConfigUpdater.cpp:56] fetchFromSource() Requesting main config "/data/store/logdevice.conf" (source: file)
I0917 02:14:30.261410    4396 [logdeviced-main] TextConfigUpdater.cpp:116] onContents() Main config from file, hash = ndhqu97h59
I0917 02:14:30.499768    4396 [logdeviced-main] Server.cpp:185] operator()() Updating settings from config took 237ms
I0917 02:14:30.500927    4396 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 238ms, config update: 0ms, notifications: 0ms
I0917 02:14:30.501923    4396 [logdeviced-main] TextConfigUpdater.cpp:306] pushServerConfig() Updated config (version: 1 - hash: ndhqu97h59)
I0917 02:14:30.502809    4396 [logdeviced-main] TextConfigUpdater.cpp:397] pushLogsConfig() Ignoring changes in the 'logs' section in the config file because LogsConfigManager is ENABLED
I0917 02:14:30.504589    4396 [logdeviced-main] TextConfigUpdater.cpp:174] update() Config update result: ServerConfig=updated, ZK=skipped, LogsConfig=updated
I0917 02:14:30.505520    4396 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:14:30.509252    4396 [logdeviced-main] NodesConfigurationInit.cpp:233] operator()() Fetching initial nodes configuration (Attempt 1)...
I0917 02:14:30.513102    4405 [ld:file-ncs] NodesConfigurationInit.cpp:290] operator()() Got a NodesConfiguration of version: 5
I0917 02:14:30.513915    4405 [ld:file-ncs] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:30.514799    4396 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:30.515971    4396 [logdeviced-main] Server.cpp:510] init() My Node ID is N1:1
I0917 02:14:30.516682    4396 [logdeviced-main] Server.cpp:517] init() My version is 0
I0917 02:14:30.517270    4396 [logdeviced-main] NoopTraceLogger.cpp:22] NoopTraceLogger() NOOP TraceLogger is ON, no trace samples will be published.
I0917 02:14:30.518835    4396 [logdeviced-main] FileBasedVersionedConfigStore.cpp:46] stopAndJoin() FileBasedVersionedConfigStore threads stopped.
I0917 02:14:30.519848    4396 [logdeviced-main] main.cpp:144] set_fd_limit() Limit on number of file descriptors is 1048576
W0917 02:14:30.520412    4396 [logdeviced-main] main.cpp:192] drop_root() Running under root, but no --user command line option specified. Will keep running as root
I0917 02:14:30.530388    4396 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48441
I0917 02:14:30.531612    4396 [logdeviced-main] Server.cpp:781] initListeners() Initializing a gossip listener.
I0917 02:14:30.539625    4396 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48443
I0917 02:14:30.541709    4396 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48447 (SSL)
I0917 02:14:30.542782    4396 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48451 (SSL)
I0917 02:14:30.543632    4396 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48450 (SSL)
I0917 02:14:30.554641    4396 [logdeviced-main] RocksDBLogStoreConfig.cpp:162] RocksDBLogStoreConfig() LD manages flushes and all memory budgets on the node. atomic_flush is set to true.
I0917 02:14:30.555643    4409 [io-stall:s0] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 0
I0917 02:14:30.564806    4410 [io-stall:s1] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 1
I0917 02:14:30.567113    4419 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:30.567799    4418 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:30.852208    4418 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000076.log.trash as trash -- OK
I0917 02:14:30.859039    4421 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N1:1/db/shard0/000076.log.trash
I0917 02:14:30.925306    4418 [ld:open-rocks0] PartitionedRocksDBStore.cpp:891] open() Partition s0:1000000 is under-replicated: Start:2021-09-17 02:10:15.092, Min:2021-09-17 02:10:00.092, Max: 2021-09-17 02:10:30.092
I0917 02:14:30.926827    4418 [ld:open-rocks0] PartitionedRocksDBStore.cpp:897] open() Shard[0] dirty ranges: [A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}]
I0917 02:14:30.940726    4418 [ld:open-rocks0] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.001s. Read 6 records, 450 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:31.014978    4416 [rocks-high-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard0/000082.log.trash as trash -- OK
I0917 02:14:31.033254    4419 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000078.log.trash as trash -- OK
I0917 02:14:31.034296    4418 [ld:open-rocks0] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N1:1/db/shard0 in 465 ms
I0917 02:14:31.042903    4420 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N1:1/db/shard1/000078.log.trash
I0917 02:14:31.049648    4421 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N1:1/db/shard0/000082.log.trash
I0917 02:14:31.084742    4419 [ld:open-rocks1] PartitionedRocksDBStore.cpp:891] open() Partition s1:1000000 is under-replicated: Start:2021-09-17 02:10:15.088, Min:2021-09-17 02:10:00.088, Max: 2021-09-17 02:10:30.088
I0917 02:14:31.086947    4419 [ld:open-rocks1] PartitionedRocksDBStore.cpp:897] open() Shard[1] dirty ranges: [A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}]
I0917 02:14:31.095019    4419 [ld:open-rocks1] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.001s. Read 13 records, 1453 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:31.146393    4701 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:14:31.170923    4415 [rocks-high-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N1:1/db/shard1/000084.log.trash as trash -- OK
I0917 02:14:31.181067    4419 [ld:open-rocks1] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N1:1/db/shard1 in 611 ms
I0917 02:14:31.181514    4420 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N1:1/db/shard1/000084.log.trash
I0917 02:14:31.198997    4396 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:691] printDiskShardMapping() Disk -> Shard mapping: /data/store/N1:1/db/shard0 -> [0,1]
I0917 02:14:31.205448    4396 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:285] init() Initialized sharded RocksDB instance at /data/store/N1:1/db with 2 shards
E0917 02:14:31.209968    4888 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState0"!
E0917 02:14:31.211268    4889 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState1"!
I0917 02:14:31.235345    4396 [logdeviced-main] Server.cpp:1173] initLogStorageStateMap() Populating log storage state map successful.
E0917 02:14:31.266378    4396 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:31.267860    4396 [logdeviced-main] RecordCacheMonitorThread.cpp:27] RecordCacheMonitorThread() Record cache monitor thread started.
I0917 02:14:31.272757    4396 [logdeviced-main] ClusterState.cpp:356] resizeClusterState() Cluster state size updated from 0 to 5
I0917 02:14:31.273186    4941 [ld:cache-evict] RecordCacheMonitorThread.cpp:44] threadMain() Record cache eviction thread started. Size limit is set to 4294967296 bytes.
E0917 02:14:31.284141    4396 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.301653    4396 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.312756    4396 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.325692    4396 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.338595    4396 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:31.351519    4396 [logdeviced-main] Processor.cpp:247] init() Initialized 5 workers of type GENERAL
E0917 02:14:31.356690    4396 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:31.360897    4396 [logdeviced-main] Processor.cpp:247] init() Initialized 1 workers of type FAILURE_DETECTOR
E0917 02:14:31.367451    4396 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.382636    4396 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.391018    4396 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.396018    4396 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:31.398421    4396 [logdeviced-main] Processor.cpp:247] init() Initialized 4 workers of type BACKGROUND
I0917 02:14:31.402690    4396 [logdeviced-main] FailureDetector.cpp:139] FailureDetector() Failure Detector created with instance id: 1631844871402
I0917 02:14:31.406356    4396 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N0 changed from UNKNOWN to DEAD
I0917 02:14:31.407695    4396 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from HEALTHY to UNHEALTHY
I0917 02:14:31.410411    4396 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N1 changed from UNKNOWN to DEAD
I0917 02:14:31.415340    4396 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from HEALTHY to UNHEALTHY
I0917 02:14:31.417317    4396 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N2 changed from UNKNOWN to DEAD
I0917 02:14:31.423753    4396 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from HEALTHY to UNHEALTHY
I0917 02:14:31.425769    4396 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N3 changed from UNKNOWN to DEAD
I0917 02:14:31.428151    4396 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from HEALTHY to UNHEALTHY
I0917 02:14:31.434192    4396 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N4 changed from UNKNOWN to DEAD
I0917 02:14:31.437444    4396 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from HEALTHY to UNHEALTHY
W0917 02:14:31.441594    4988 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 39 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967297), p :HI_PRI
W0917 02:14:31.445245    5046 [ld:srv:WG4] Worker.cpp:1322] processRequest() Request queued for 42 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967300), p :HI_PRI
W0917 02:14:31.451757    4977 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 44 msec: NODE_STATE_UPDATED (id: 4294967301), p :LO_PRI
W0917 02:14:31.453716    4977 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 46 msec: NODE_STATE_UPDATED (id: 4294967306), p :LO_PRI
I0917 02:14:31.451957    4396 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
W0917 02:14:31.456011    4977 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 48 msec: NODE_STATE_UPDATED (id: 4294967307), p :LO_PRI
W0917 02:14:31.467505    4977 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 52 msec: NODE_STATE_UPDATED (id: 4294967311), p :LO_PRI
I0917 02:14:31.463505    5071 [ld:srv:WB2] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:14:31.475333    5071 [ld:srv:WB2] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 13ms
W0917 02:14:31.472366    4977 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 57 msec: NODE_STATE_UPDATED (id: 4294967316), p :LO_PRI
W0917 02:14:31.483120    5071 [ld:srv:WB2] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.021s, source: [Request: NODES_CONFIGURATION_MANAGER]
W0917 02:14:31.483962    4977 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 68 msec: NODE_STATE_UPDATED (id: 4294967317), p :LO_PRI
W0917 02:14:31.486394    4977 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 63 msec: NODE_STATE_UPDATED (id: 4294967321), p :LO_PRI
W0917 02:14:31.489834    4977 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 66 msec: NODE_STATE_UPDATED (id: 4294967326), p :LO_PRI
I0917 02:14:31.492365    5071 [ld:srv:WB2] NodesConfigurationManager.cpp:507] onProcessingFinished() Updated local nodes config to version 5...
I0917 02:14:31.493628    4908 [ld:s0:default:0] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:31.496199    4908 [ld:s0:default:0] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 0, totaling 0 bytes.
I0917 02:14:31.493695    4934 [ld:s1:default:0] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:31.499966    4934 [ld:s1:default:0] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 1, totaling 0 bytes.
I0917 02:14:31.502479    4396 [logdeviced-main] Server.cpp:1319] initSequencers() Initializing FileEpochStore
I0917 02:14:31.505832    4396 [logdeviced-main] Server.cpp:1398] initSequencerPlacement() using SequencerOptions::LAZY
I0917 02:14:31.508768    4396 [logdeviced-main] Server.cpp:1430] initRebuildingCoordinator() Initializing EventLog RSM and RebuildingCoordinator
I0917 02:14:31.509890    4396 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387903)
I0917 02:14:31.511091    4396 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387903, is_server:1)
I0917 02:14:31.512114    4396 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:31.513818    4396 [logdeviced-main] Server.cpp:1467] initRebuildingCoordinator() Starting RebuildingSupervisor
I0917 02:14:31.514983    4396 [logdeviced-main] Server.cpp:1480] initRebuildingCoordinator() Starting RebuildingCoordinator
I0917 02:14:31.515102    5046 [ld:srv:WG4] RebuildingSupervisor.cpp:62] init() Starting Rebuilding Supervisor
I0917 02:14:31.517563    5046 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N4 to execute in 1200s
I0917 02:14:31.519144    5046 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N3 to execute in 1200s
I0917 02:14:31.519954    4396 [logdeviced-main] LogStoreMonitor.cpp:190] start() Logstore monitoring thread started.
I0917 02:14:31.519865    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:309] subscribeToEventLogIfNeeded() RebuildingCoordinator did not start yet because LogsConfig is not fully loaded yet
I0917 02:14:31.519982    5046 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N2 to execute in 1200s
I0917 02:14:31.528205    5046 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N0 to execute in 1200s
I0917 02:14:31.521491    4396 [logdeviced-main] UnreleasedRecordDetector.cpp:106] start() Unreleased record detector thread started.
I0917 02:14:31.535884    4396 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387901)
I0917 02:14:31.526533    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [eventlog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:31.545148    5076 [ld:srv:WB3] EventLogStateMachine.cpp:146] gotInitialState() Got base rebuilding set: {}
W0917 02:14:31.531563    5046 [ld:srv:WG4] RebuildingSupervisor.cpp:705] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:14:31.540975    4396 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387901, is_server:1)
I0917 02:14:31.559897    4396 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:31.561581    5069 [ld:srv:WB1] LogsConfigManager.cpp:38] execute() Starting LogsConfigManager on Worker 1 in pool: BACKGROUND
I0917 02:14:31.548630    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [eventlog] Retrieving tail lsn of delta log...
W0917 02:14:31.570548    5076 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.044s, source: [Request: START_EVENT_LOG_READER]
I0917 02:14:31.556128    5046 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:14:31.564099    5069 [ld:srv:WB1] LogsConfigManager.cpp:165] start() Starting LogsConfig Manager RSM
E0917 02:14:31.570643    5030 [ld:srv:WG3] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387903. All sequencer nodes are unavailable.
E0917 02:14:31.583903    5030 [ld:srv:WG3] SequencerRouter.cpp:56] operator()() Error during sequencer lookup for log 4611686018427387903 (NOSEQUENCER), reporting NOSEQUENCER.
I0917 02:14:31.576269    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [maintenancelog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:31.591937    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [maintenancelog] Retrieving tail lsn of delta log...
E0917 02:14:31.593345    5046 [ld:srv:WG4] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387899. All sequencer nodes are unavailable.
I0917 02:14:31.580739    5069 [ld:srv:WB1] LogsConfigManager.cpp:206] start() Starting LogsConfig Replicated State Machine
E0917 02:14:31.589988    5030 [ld:srv:WG3] SequencerRouter.cpp:105] onFailure() Error during sequencer routing for log 4611686018427387903 (NOSEQUENCER), request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7fa1dcdab028].
W0917 02:14:31.595089    5046 [ld:srv:WG4] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387899, rqid:30064771075, ctx:rsm, err(NOSEQUENCER)
E0917 02:14:31.613403    5076 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:30064771075) for log:4611686018427387899, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:14:31.602193    5069 [ld:srv:WB1] ReplicatedStateMachine-inl.h:38] startFetchingSnapshot() [logsconfig] Using RSMSnapshotStore...
W0917 02:14:31.611113    5030 [ld:srv:WG3] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387903 (rqid:30064771073, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
I0917 02:14:31.622328    5069 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1294] initSnapshotFetchTimer() [logsconfig] Creating timer to fetch snapshots ...
E0917 02:14:31.625183    5076 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:30064771073) for log:4611686018427387903, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:14:31.631224    4396 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server LogDevice Admin API Service will listen on port 48444
I0917 02:14:31.634795    4396 [logdeviced-main] Server.cpp:1540] createAndAttachMaintenanceManager() Not initializing MaintenanceManager since it is disabled in settings
I0917 02:14:31.638529    4396 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: s2s-api
I0917 02:14:31.641073    4396 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server s2s-api will listen on port 48448
I0917 02:14:31.642270    4396 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: c2s-api
I0917 02:14:31.643719    4396 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server c2s-api will listen on port 48449
I0917 02:14:31.644881    4396 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:31.647955    4406 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:31.663983    4396 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:31.666998    4407 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:31.676190    4396 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server s2s-api
I0917 02:14:31.676267    5063 [ld:srv:WF0] FailureDetector.cpp:228] startGetClusterState() Sending GET_CLUSTER_STATE to build initial FD cluster view
I0917 02:14:31.692729    5063 [ld:srv:WF0] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket N4:1(127.0.0.1:48410) hit error AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused)
I0917 02:14:31.696926    5063 [ld:srv:WF0] FailureDetector.cpp:267] operator()() Cluster state received with 5 dead nodes (N0,N1,N2,N3,N4) and 0 boycotted nodes ()
I0917 02:14:31.698835    5063 [ld:srv:WF0] FailureDetector.cpp:288] buildInitialState() Wait over (cluster state received)
I0917 02:14:31.700217    5063 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N0 transitioned to DEAD
I0917 02:14:31.701240    5063 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from DEAD to STARTING
I0917 02:14:31.703011    5046 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N2
I0917 02:14:31.703198    5063 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N2 transitioned to ALIVE
I0917 02:14:31.706502    5063 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N3 transitioned to DEAD
I0917 02:14:31.707604    5063 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N4 transitioned to DEAD
I0917 02:14:31.708254    4396 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server c2s-api
I0917 02:14:31.708833    5063 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N0 transitioned to UNHEALTHY (status)
I0917 02:14:31.714203    5063 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N2 transitioned to UNHEALTHY (status)
I0917 02:14:31.715480    5063 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N3 transitioned to UNHEALTHY (status)
I0917 02:14:31.717830    5063 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N4 transitioned to UNHEALTHY (status)
I0917 02:14:31.719302    5063 [ld:srv:WF0] FailureDetector.cpp:344] buildInitialState() Initializing DomainIsolationChecker
I0917 02:14:31.720315    5063 [ld:srv:WF0] FailureDetector.cpp:915] startSuspectTimer() Starting suspect state timer
I0917 02:14:31.721123    5063 [ld:srv:WF0] FailureDetector.cpp:1285] updateNodeState() N1 transitioned from DEAD to ALIVE, FD State:(gossip: 0, instance-id: 0, failover: 0, starting: 1)
I0917 02:14:31.724344    5063 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N1 changed from DEAD to STARTING
I0917 02:14:31.726873    5063 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting suspect-state-finished message.
I0917 02:14:31.727815    5063 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844871402 to node WF0:N4:1 (127.0.0.1:48410)
I0917 02:14:31.730364    5063 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844871402 to node WF0:N3:1 (UNKNOWN)
I0917 02:14:31.733610    5063 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting bringup message.
I0917 02:14:31.736710    4396 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server LogDevice Admin API Service
I0917 02:14:31.738282    5063 [ld:srv:WF0] FailureDetector.cpp:937] startGossiping() Start Gossiping.
I0917 02:14:31.741350    5063 [ld:srv:WF0] FailureDetector.cpp:925] operator()() Suspect timeout expired
I0917 02:14:31.758624    4396 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:31.761961    4408 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:31.763499    4396 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:31.764632    4406 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:31.766536    4396 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:31.767858    4406 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:31.769829    4396 [logdeviced-main] main.cpp:464] main() Listeners initialized
I0917 02:14:31.844195    5063 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from UNHEALTHY to UNDEFINED
I0917 02:14:31.882378    5063 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N0:1 with instance id:1631844871595, sent_time:1631844871840ms
I0917 02:14:31.884051    5063 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from DEAD to STARTING
I0917 02:14:31.885479    5046 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N0
I0917 02:14:31.885845    5063 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N0 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844871595, failover: 0, starting: 1)
I0917 02:14:31.891687    5063 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N0:1 with instance id:1631844871595, sent_time:1631844871844ms
I0917 02:14:31.892994    5063 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N0
I0917 02:14:31.955568    5063 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from UNDEFINED to HEALTHY
I0917 02:14:31.959817    5063 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N4:1 (127.0.0.1:48410): CONNFAILED: connection failed. Trying another node.
I0917 02:14:31.965858    5063 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from UNHEALTHY to UNDEFINED
I0917 02:14:31.966644    5063 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from UNHEALTHY to HEALTHY
I0917 02:14:32.015092    5063 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N4:1 with instance id:1631844871814, sent_time:1631844872010ms
I0917 02:14:32.016312    5063 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from DEAD to STARTING
I0917 02:14:32.018212    5046 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N4
W0917 02:14:32.020143    5046 [ld:srv:WG4] RebuildingSupervisor.cpp:734] adjustRebuildingThrottle() Exiting throttling mode: #draining=0, #rebuilding=0, #triggers=1, #adjusted cluster size=5, threshold=35%, actual=20%
I0917 02:14:32.024127    5046 [ld:srv:WG4] RebuildingSupervisor.cpp:751] adjustRebuildingThrottle() Not triggering new rebuildings until 2021-09-17 02:34:32.023: It's too soon after exiting throttling mode
I0917 02:14:32.018865    5063 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N4 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844871814, failover: 0, starting: 1)
I0917 02:14:32.027416    5063 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N4:1 with instance id:1631844871814, sent_time:1631844872011ms
I0917 02:14:32.028626    5063 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N4
I0917 02:14:32.089937    5063 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N3:1 with instance id:1631844871925, sent_time:1631844872083ms
I0917 02:14:32.092339    5063 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N3 changed from DEAD to STARTING
I0917 02:14:32.093792    5063 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N3 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844871925, failover: 0, starting: 1)
I0917 02:14:32.093891    5046 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N3
I0917 02:14:32.094937    5063 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N3
I0917 02:14:32.171350    5063 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from UNHEALTHY to UNDEFINED
I0917 02:14:32.303148    4825 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:14:32.304244    4825 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:14:32.506953    4988 [ld:srv:WG1] GET_SEQ_STATE_Message.cpp:238] getSequencer() Sequencer for log:4611686018427387899 is absent, state=UNAVAILABLE, cur_epoch=0, attempting to activate it upon receiving GSS (rqid:30064771076, ctx:rsm, min_epoch:none) from WG1:C5 (127.0.0.1:43676)
I0917 02:14:32.516937    4988 [ld:srv:WG1] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387899, rqid:30064771076, ctx:rsm) from WG1:C5 (127.0.0.1:43676), but its data log sequencer's state is ACTIVATING
W0917 02:14:32.518294    4988 [ld:srv:WG1] Worker.cpp:1000] onStoppedRunning() skipped at least 8 log entries
W0917 02:14:32.519152    4988 [ld:srv:WG1] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.011s, source: [Message sent/received: GET_SEQ_STATE]
I0917 02:14:32.520108    4988 [ld:srv:WG1] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 4611686018427387899 epoch 8.
I0917 02:14:32.521494    4988 [ld:srv:WG1] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 4611686018427387899: {[E:1 (at 2021-09-17 02:14:32.511) since:1 (at 2021-09-17 02:10:15.170) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S1,N1:S1,N2:S1,N3:S1,N4:S1} W:[]], Until:8}.
I0917 02:14:32.522635    4988 [ld:srv:WG1] AllSequencers.cpp:527] onEpochMetaDataFromEpochStore() Activated a sequencer for log 4611686018427387899 (reason: GET_SEQ_STATE) with epoch 8, metadata: [E:8 (at 2021-09-17 02:14:32.511) since:1 (at 2021-09-17 02:10:15.170) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S1,N1:S1,N2:S1,N3:S1,N4:S1} W:[]]. Activation Result: RECOVERY.
I0917 02:14:32.522757    4995 [ld:srv:WG2] PeriodicReleases.cpp:416] execute() Start broadcasting releases for log 4611686018427387899.
I0917 02:14:32.525383    4995 [ld:srv:WG2] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 13835058055282163707 epoch 8.
I0917 02:14:32.525468    4988 [ld:srv:WG1] MetaDataLogTrimmer.cpp:115] schedulePeriodicTrimming() Will run periodic trimming every ~7200000 s for 4611686018427387899
I0917 02:14:32.527176    4995 [ld:srv:WG2] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 13835058055282163707: {[E:1 (at -inf) since:1 (at -inf) R:[node: 3] V:2 flags: params:{target:0 seed:0 signature:0} N:{N0:S1,N1:S1,N2:S1,N3:S1,N4:S1} W:[]], Until:8}.
I0917 02:14:32.528710    4995 [ld:srv:WG2] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 13835058055282163707 with next_epoch 8
W0917 02:14:32.533322    5046 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.011s, source: [Request: GET_TRIM_POINT]
I0917 02:14:32.534957    5046 [ld:srv:WG4] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 4611686018427387899 with next_epoch 8
I0917 02:14:32.541819    5046 [ld:srv:WG4] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [2, 7] of log 4611686018427387899
I0917 02:14:32.549819    4995 [ld:srv:WG2] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [6, 7] of log 13835058055282163707
I0917 02:14:32.555769    4935 [ld:s1:default:1] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 4611686018427387899 epoch 2: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 2.
I0917 02:14:32.623769    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [maintenancelog] Tail lsn of delta log is e8n0
I0917 02:14:32.630983    5069 [ld:srv:WB1] ReplicatedStateMachine-inl.h:130] getSnapshot() [logsconfig] Fetching snapshot with ver:e0n1, (waiting_for_snapshot_:LSN_INVALID, version_:e0n1). sync_state_:0
I0917 02:14:32.664458    4995 [ld:srv:WG2] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:13835058055282163707, rqid:25769803792, ctx:start-message) from WG2:C17 (127.0.0.1:43774), but its data log sequencer's state is Recovery Incomplete
I0917 02:14:32.672019    4995 [ld:srv:WG2] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387899, rqid:68719476737, ctx:start-message) from WG2:C18 (127.0.0.1:43788), but its data log sequencer's state is Recovery Incomplete
I0917 02:14:32.676183    4988 [ld:srv:WG1] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387899, rqid:38654705666, ctx:start-message) from WG1:C5 (127.0.0.1:43676), but its data log sequencer's state is Recovery Incomplete
I0917 02:14:32.686181    4995 [ld:srv:WG2] EpochRecovery.cpp:566] startMutations() Log 13835058055282163707 epoch 6 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 0, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S1, N1:S1, N2:S1, N3:S1, N4:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163707 N:e1n1 T:0 AOM:{246:0} F:16], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:13835058055282163707 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {m:N0:S1,N1:S1,N2:S1,N3:S1,N4:S1 MUTATION}.
I0917 02:14:32.687324    4977 [ld:srv:WG0] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 4611686018427387899 epoch 2: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 2.
I0917 02:14:32.690154    5063 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() skipped at least 2 log entries
I0917 02:14:32.693276    5063 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from UNDEFINED to HEALTHY
I0917 02:14:32.690576    4977 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:13835058055282163707, rqid:68719476736, ctx:start-message) from WG0:C15 (127.0.0.1:43770), but its data log sequencer's state is Recovery Incomplete
I0917 02:14:32.697979    5063 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from UNDEFINED to HEALTHY
I0917 02:14:32.735514    5030 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387903 has already been cleaned. No purge needed. last clean epoch: 6, purge to: 6.
I0917 02:14:32.735768    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [eventlog] Tail lsn of delta log is e9n0
I0917 02:14:32.755563    5046 [ld:srv:WG4] EpochRecovery.cpp:566] startMutations() Log 4611686018427387899 epoch 2 final digest before mutation: consensus LNG 0, start esn: 1, 1 entries, first esn: 1, last esn: 1, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S1, N1:S1, N2:S1, N3:S1, N4:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {m:N0:S1,N1:S1,N2:S1,N3:S1,N4:S1 MUTATION}.
I0917 02:14:32.764447    5046 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163707 shard 1 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 2.
I0917 02:14:32.767800    5046 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163707 shard 1 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 3.
I0917 02:14:32.773636    5046 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163707 shard 1 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 4.
I0917 02:14:32.774554    5046 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163707 shard 1 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 5.
I0917 02:14:32.778223    5046 [ld:srv:WG4] PurgeUncleanEpochs.cpp:401] onGetEpochRecoveryMetadataComplete() Nothing to purge. Epoch is empty locally and EpochRecoveryMetadata consensus is also EMPTY for log: 13835058055282163707,epoch:5
I0917 02:14:32.823987    4995 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387900 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:32.844387    5046 [ld:srv:WG4] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [1, 5] for log 13835058055282163707.
I0917 02:14:32.877487    5046 [ld:srv:WG4] EpochRecovery.cpp:566] startMutations() Log 4611686018427387899 epoch 3 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S1, N1:S1, N2:S1, N3:S1, N4:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {m:N0:S1,N1:S1,N2:S1,N3:S1,N4:S1 MUTATION}.
I0917 02:14:32.890109    5046 [ld:srv:WG4] Mutator.cpp:400] finalize() Mutator 4611686018427387899e3n1 completed (OK). Trace: W1{N2:S1,N1:S1};X:N2:S1:K;X:N1:S1:K;Y1:N1:S1:K;Y1:N2:S1:K;done:can_replicate:OK;
I0917 02:14:32.894041    4977 [ld:srv:WG0] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 2, purge to: 2.
I0917 02:14:32.989840    4995 [ld:srv:WG2] EpochRecovery.cpp:566] startMutations() Log 13835058055282163707 epoch 7 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 0, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S1, N1:S1, N2:S1, N3:S1, N4:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163707 N:e1n1 T:0 AOM:{246:0} F:16], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:13835058055282163707 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {m:N0:S1,N1:S1,N2:S1,N3:S1,N4:S1 MUTATION}.
I0917 02:14:32.992539    5046 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163707 has already been cleaned. No purge needed. last clean epoch: 6, purge to: 6.
I0917 02:14:33.005660    5030 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387903 has already been cleaned. No purge needed. last clean epoch: 7, purge to: 7.
I0917 02:14:33.069680    5030 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163708 has already been cleaned. No purge needed. last clean epoch: 7, purge to: 7.
I0917 02:14:33.083154    4995 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387900 has already been cleaned. No purge needed. last clean epoch: 2, purge to: 2.
I0917 02:14:33.088267    5046 [ld:srv:WG4] EpochRecovery.cpp:566] startMutations() Log 4611686018427387899 epoch 4 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S1, N1:S1, N2:S1, N3:S1, N4:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {m:N0:S1,N1:S1,N2:S1,N3:S1,N4:S1 MUTATION}.
I0917 02:14:33.093178    5046 [ld:srv:WG4] Mutator.cpp:400] finalize() Mutator 4611686018427387899e4n1 completed (OK). Trace: W1{N2:S1,N1:S1};X:N2:S1:K;X:N1:S1:K;Y1:N2:S1:K;Y1:N1:S1:K;done:can_replicate:OK;
I0917 02:14:33.096887    4977 [ld:srv:WG0] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 3, purge to: 3.
W0917 02:14:33.195308    4995 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() skipped at least 10 log entries
W0917 02:14:33.197006    4995 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.023s, source: [Message sent/received: CLEANED]
I0917 02:14:33.214296    4995 [ld:srv:WG2] LogRecoveryRequest.cpp:1463] complete() Log recovery completed for log 13835058055282163707, next_epoch:8
I0917 02:14:33.216280    5076 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 2 is not available. Highest epoch known is 1.
W0917 02:14:33.225477    4995 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.011s, source: [Request: COMPLETION]
I0917 02:14:33.229693    5076 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 3 is not available. Highest epoch known is 1.
I0917 02:14:33.267524    4995 [ld:srv:WG2] GetEpochRecoveryMetadataRequest.cpp:172] checkAllFullyAuthoritativeNodesResponded() GetEpochRecoveryMetadataRequest for log 13835058055282163711 shard 1 epochs [2,3] purge_to 3 received reply from all fully authoritative nodes in thenodeset but still unable to make a decision. It is likely that some epoch has been recovered by non-authoritative recovery.
I0917 02:14:33.269924    4995 [ld:srv:WG2] GetEpochRecoveryMetadataRequest.cpp:199] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163711 shard 1 epochs [2,3] purge_to 3 - All nodes responded but there is no valid response for epoch:2
I0917 02:14:33.272334    4995 [ld:srv:WG2] GetEpochRecoveryMetadataRequest.cpp:199] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163711 shard 1 epochs [2,3] purge_to 3 - All nodes responded but there is no valid response for epoch:3
I0917 02:14:33.275697    4995 [ld:srv:WG2] PurgeUncleanEpochs.cpp:387] onGetEpochRecoveryMetadataComplete() GetEpochRecoveryMetadataRequest for log 13835058055282163711 did not get a valid response for epoch 3. Skipping purging for this epoch
I0917 02:14:33.276365    4995 [ld:srv:WG2] PurgeUncleanEpochs.cpp:387] onGetEpochRecoveryMetadataComplete() GetEpochRecoveryMetadataRequest for log 13835058055282163711 did not get a valid response for epoch 2. Skipping purging for this epoch
I0917 02:14:33.277492    5076 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 8 is not available. Highest epoch known is 1.
W0917 02:14:33.281227    5076 [ld:srv:WB3] ClientReadStream.cpp:2476] updateCurrentMetaData() Existing epoch metadata has changed for log 4611686018427387903 on epoch 1, check metadata log!
I0917 02:14:33.286271    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [eventlog] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:14:33.288300    5076 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (1)
I0917 02:14:33.320475    5046 [ld:srv:WG4] EpochRecovery.cpp:566] startMutations() Log 4611686018427387899 epoch 5 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S1, N1:S1, N2:S1, N3:S1, N4:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {m:N0:S1,N1:S1,N2:S1,N3:S1,N4:S1 MUTATION}.
I0917 02:14:33.364925    5046 [ld:srv:WG4] Mutator.cpp:400] finalize() Mutator 4611686018427387899e5n1 completed (OK). Trace: W1{N1:S1,N4:S1};X:N1:S1:K;X:N4:S1:K;Y1:N1:S1:K;Y1:N4:S1:K;done:can_replicate:OK;
I0917 02:14:33.367334    4977 [ld:srv:WG0] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 4, purge to: 4.
I0917 02:14:33.383422    4995 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387900 has already been cleaned. No purge needed. last clean epoch: 3, purge to: 3.
I0917 02:14:33.492489    4995 [ld:srv:WG2] PurgeUncleanEpochs.cpp:592] complete() skipped at least 10 log entries
I0917 02:14:33.494795    4995 [ld:srv:WG2] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [3, 3] for log 4611686018427387900.
I0917 02:14:33.585433    4988 [ld:srv:WG1] GET_SEQ_STATE_Message.cpp:238] getSequencer() Sequencer for log:4611686018427387898 is absent, state=UNAVAILABLE, cur_epoch=0, attempting to activate it upon receiving GSS (rqid:17179869188, ctx:rsm, min_epoch:none) from WG1:C31 (127.0.0.1:43930)
W0917 02:14:33.600298    5046 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() skipped at least 3 log entries
W0917 02:14:33.606362    5046 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.033s, source: [Message sent/received: CLEANED]
W0917 02:14:33.615911    4988 [ld:srv:WG1] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.027s, source: [Message sent/received: GET_SEQ_STATE]
I0917 02:14:33.616024    5046 [ld:srv:WG4] EpochRecovery.cpp:566] startMutations() Log 4611686018427387899 epoch 6 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S1, N1:S1, N2:S1, N3:S1, N4:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {m:N0:S1,N1:S1,N2:S1,N3:S1,N4:S1 MUTATION}.
I0917 02:14:33.619361    4988 [ld:srv:WG1] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 4611686018427387898 epoch 8.
I0917 02:14:33.620627    4988 [ld:srv:WG1] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 4611686018427387898: {[E:1 (at 2021-09-17 02:14:33.589) since:1 (at 2021-09-17 02:10:14.514) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S0,N1:S0,N2:S0,N3:S0,N4:S0} W:[]], Until:8}.
I0917 02:14:33.622452    5046 [ld:srv:WG4] PeriodicReleases.cpp:416] execute() Start broadcasting releases for log 4611686018427387898.
I0917 02:14:33.624821    5046 [ld:srv:WG4] Mutator.cpp:400] finalize() Mutator 4611686018427387899e6n1 completed (OK). Trace: W1{N4:S1,N3:S1};X:N4:S1:K;X:N3:S1:K;Y1:N4:S1:K;Y1:N3:S1:K;done:can_replicate:OK;
I0917 02:14:33.623160    4988 [ld:srv:WG1] AllSequencers.cpp:527] onEpochMetaDataFromEpochStore() Activated a sequencer for log 4611686018427387898 (reason: GET_SEQ_STATE) with epoch 8, metadata: [E:8 (at 2021-09-17 02:14:33.589) since:1 (at 2021-09-17 02:10:14.514) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S0,N1:S0,N2:S0,N3:S0,N4:S0} W:[]]. Activation Result: RECOVERY.
I0917 02:14:33.635552    4977 [ld:srv:WG0] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 4611686018427387898 with next_epoch 8
I0917 02:14:33.636342    4988 [ld:srv:WG1] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 13835058055282163706 epoch 8.
I0917 02:14:33.643702    4977 [ld:srv:WG0] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [2, 7] of log 4611686018427387898
I0917 02:14:33.645767    4988 [ld:srv:WG1] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 13835058055282163706: {[E:1 (at -inf) since:1 (at -inf) R:[node: 3] V:2 flags: params:{target:0 seed:0 signature:0} N:{N0:S0,N1:S0,N2:S0,N3:S0,N4:S0} W:[]], Until:8}.
I0917 02:14:33.655041    4988 [ld:srv:WG1] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 13835058055282163706 with next_epoch 8
I0917 02:14:33.660299    4988 [ld:srv:WG1] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [6, 7] of log 13835058055282163706
I0917 02:14:33.712875    4977 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:567] continueExecution() skipped at least 10 log entries
I0917 02:14:33.713993    4977 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:13835058055282163707, rqid:68719476736, ctx:start-message) from WG0:C15 (127.0.0.1:43770), but its data log sequencer's state is Recovery Incomplete
I0917 02:14:33.720868    4977 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387899, rqid:38654705668, ctx:start-message) from WG0:C6 (127.0.0.1:43682), but its data log sequencer's state is Recovery Incomplete
I0917 02:14:33.736027    5046 [ld:srv:WG4] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387899, rqid:68719476737, ctx:start-message) from WG4:C20 (127.0.0.1:43790), but its data log sequencer's state is Recovery Incomplete
I0917 02:14:33.744044    5046 [ld:srv:WG4] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:13835058055282163707, rqid:38654705665, ctx:start-message) from WG4:C7 (127.0.0.1:43696), but its data log sequencer's state is Recovery Incomplete
I0917 02:14:33.752515    4977 [ld:srv:WG0] EpochRecovery.cpp:566] startMutations() Log 4611686018427387898 epoch 2 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S0, N1:S0, N2:S0, N3:S0, N4:S0}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387898 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387898 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {m:N0:S0,N1:S0,N2:S0,N3:S0,N4:S0 MUTATION}.
I0917 02:14:33.753391    4988 [ld:srv:WG1] EpochRecovery.cpp:566] startMutations() Log 13835058055282163706 epoch 6 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 0, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S0, N1:S0, N2:S0, N3:S0, N4:S0}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163706 N:e1n1 T:0 AOM:{246:0} F:16], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:13835058055282163706 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {m:N0:S0,N1:S0,N2:S0,N3:S0,N4:S0 MUTATION}.
I0917 02:14:33.755144    4995 [ld:srv:WG2] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387898, rqid:30064771107, ctx:store-message) from WG2:C10 (127.0.0.1:43712), but its data log sequencer's state is Recovery Incomplete
I0917 02:14:33.761631    4977 [ld:srv:WG0] Mutator.cpp:400] finalize() Mutator 4611686018427387898e2n1 completed (OK). Trace: W1{N0:S0,N3:S0};X:N0:S0:K;X:N3:S0:K;Y1:N0:S0:K;Y1:N3:S0:K;done:can_replicate:OK;
I0917 02:14:33.834460    5046 [ld:srv:WG4] EpochRecovery.cpp:566] startMutations() Log 4611686018427387899 epoch 7 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S1, N1:S1, N2:S1, N3:S1, N4:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {m:N0:S1,N1:S1,N2:S1,N3:S1,N4:S1 MUTATION}.
I0917 02:14:33.846962    5046 [ld:srv:WG4] PurgeUncleanEpochs.cpp:592] complete() skipped at least 3 log entries
I0917 02:14:33.847833    5046 [ld:srv:WG4] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [1, 1] for log 4611686018427387898.
I0917 02:14:33.849931    5046 [ld:srv:WG4] Mutator.cpp:400] finalize() Mutator 4611686018427387899e7n1 completed (OK). Trace: W1{N0:S1,N4:S1};X:N0:S1:K;X:N4:S1:K;Y1:N4:S1:K;Y1:N0:S1:K;done:can_replicate:OK;
I0917 02:14:33.967087    4977 [ld:srv:WG0] EpochRecovery.cpp:566] startMutations() Log 4611686018427387898 epoch 3 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S0, N1:S0, N2:S0, N3:S0, N4:S0}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387898 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387898 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {m:N0:S0,N1:S0,N2:S0,N3:S0,N4:S0 MUTATION}.
I0917 02:14:33.977089    4977 [ld:srv:WG0] Mutator.cpp:400] finalize() Mutator 4611686018427387898e3n1 completed (OK). Trace: W1{N1:S0,N2:S0};X:N1:S0:K;X:N2:S0:K;Y1:N2:S0:K;Y1:N1:S0:K;done:can_replicate:OK;
I0917 02:14:34.088391    5046 [ld:srv:WG4] LogRecoveryRequest.cpp:1463] complete() Log recovery completed for log 4611686018427387899, next_epoch:8
I0917 02:14:34.096561    5076 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387899 epoch 2 is not available. Highest epoch known is 1.
I0917 02:14:34.134242    5076 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387899 epoch 8 is not available. Highest epoch known is 1.
W0917 02:14:34.138464    5076 [ld:srv:WB3] ClientReadStream.cpp:2476] updateCurrentMetaData() Existing epoch metadata has changed for log 4611686018427387899 on epoch 1, check metadata log!
I0917 02:14:34.139496    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [maintenancelog] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:14:34.141048    5076 [ld:srv:WB3] ClusterMaintenanceStateMachine.cpp:112] onUpdate() [maintenancelog] Published new ClusterMaintenanceState version (1)
I0917 02:14:34.202677    4977 [ld:srv:WG0] EpochRecovery.cpp:566] startMutations() Log 4611686018427387898 epoch 4 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S0, N1:S0, N2:S0, N3:S0, N4:S0}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387898 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387898 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {m:N0:S0,N1:S0,N2:S0,N3:S0,N4:S0 MUTATION}.
I0917 02:14:34.209683    4977 [ld:srv:WG0] Mutator.cpp:400] finalize() Mutator 4611686018427387898e4n1 completed (OK). Trace: W1{N1:S0,N3:S0};X:N1:S0:K;X:N3:S0:K;Y1:N1:S0:K;Y1:N3:S0:K;done:can_replicate:OK;
I0917 02:14:34.406481    4977 [ld:srv:WG0] EpochRecovery.cpp:566] startMutations() Log 4611686018427387898 epoch 5 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S0, N1:S0, N2:S0, N3:S0, N4:S0}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387898 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387898 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {m:N0:S0,N1:S0,N2:S0,N3:S0,N4:S0 MUTATION}.
I0917 02:14:34.413291    4977 [ld:srv:WG0] Mutator.cpp:400] finalize() Mutator 4611686018427387898e5n1 completed (OK). Trace: W1{N1:S0,N3:S0};X:N1:S0:K;X:N3:S0:K;Y1:N1:S0:K;Y1:N3:S0:K;done:can_replicate:OK;
I0917 02:14:34.482071    4988 [ld:srv:WG1] EpochRecovery.cpp:566] startMutations() Log 13835058055282163706 epoch 7 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 0, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S0, N1:S0, N2:S0, N3:S0, N4:S0}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163706 N:e1n1 T:0 AOM:{246:0} F:16], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:13835058055282163706 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {m:N0:S0,N1:S0,N2:S0,N3:S0,N4:S0 MUTATION}.
I0917 02:14:34.590008    4995 [ld:srv:WG2] PurgeUncleanEpochs.cpp:592] complete() skipped at least 10 log entries
I0917 02:14:34.590956    4995 [ld:srv:WG2] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [6, 6] for log 13835058055282163706.
W0917 02:14:34.608946    4977 [ld:srv:WG0] Worker.cpp:1000] onStoppedRunning() skipped at least 7 log entries
W0917 02:14:34.610037    4977 [ld:srv:WG0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.018s, source: [Message sent/received: CLEANED]
I0917 02:14:34.618624    4977 [ld:srv:WG0] EpochRecovery.cpp:566] startMutations() Log 4611686018427387898 epoch 6 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S0, N1:S0, N2:S0, N3:S0, N4:S0}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387898 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387898 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {m:N0:S0,N1:S0,N2:S0,N3:S0,N4:S0 MUTATION}.
I0917 02:14:34.627669    4977 [ld:srv:WG0] Mutator.cpp:400] finalize() Mutator 4611686018427387898e6n1 completed (OK). Trace: W1{N4:S0,N3:S0};X:N4:S0:K;X:N3:S0:K;Y1:N4:S0:K;Y1:N3:S0:K;done:can_replicate:OK;
I0917 02:14:34.631450    4935 [ld:s1:default:1] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 4611686018427387901 epoch 2: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 2.
I0917 02:14:34.703391    4988 [ld:srv:WG1] LogRecoveryRequest.cpp:1463] complete() Log recovery completed for log 13835058055282163706, next_epoch:8
I0917 02:14:34.804904    4977 [ld:srv:WG0] EpochRecovery.cpp:566] startMutations() Log 4611686018427387898 epoch 7 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_COMPLETE, mutation set: {N0:S0, N1:S0, N2:S0, N3:S0, N4:S0}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387898 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387898 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {m:N0:S0,N1:S0,N2:S0,N3:S0,N4:S0 MUTATION}.
W0917 02:14:34.815106    4977 [ld:srv:WG0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.010s, source: [Message sent/received: GAP]
I0917 02:14:34.823023    4977 [ld:srv:WG0] Mutator.cpp:400] finalize() Mutator 4611686018427387898e7n1 completed (OK). Trace: W1{N4:S0,N2:S0};X:N4:S0:K;X:N2:S0:K;Y1:N2:S0:K;Y1:N4:S0:K;done:can_replicate:OK;
I0917 02:14:34.927349    5046 [ld:srv:WG4] PurgeUncleanEpochs.cpp:592] complete() skipped at least 3 log entries
I0917 02:14:34.928733    5046 [ld:srv:WG4] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [6, 6] for log 4611686018427387898.
I0917 02:14:35.043274    4977 [ld:srv:WG0] LogRecoveryRequest.cpp:1463] complete() Log recovery completed for log 4611686018427387898, next_epoch:8
I0917 02:14:35.660859    5069 [ld:srv:WB1] LogBasedRSMSnapshotStore.cpp:298] onGotLastReleased() Returning EMPTY for log:4611686018427387900, last_released_real_lsn:LSN_INVALID
I0917 02:14:35.661533    5069 [ld:srv:WB1] ReplicatedStateMachine-inl.h:83] operator()() [logsconfig] getSnapshot()'s callback. st:EMPTY, snapshot blob size:0, attrs:(base_ver:LSN_INVALID, ts:0)
I0917 02:14:35.662330    5069 [ld:srv:WB1] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [logsconfig] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:35.663277    5069 [ld:srv:WB1] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [logsconfig] Retrieving tail lsn of delta log...
I0917 02:14:35.678995    5069 [ld:srv:WB1] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [logsconfig] Tail lsn of delta log is e6n0
W0917 02:14:35.713762    4988 [ld:srv:WG1] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:52 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.714653    4988 [ld:srv:WG1] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:72 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.717394    4988 [ld:srv:WG1] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:90 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.732370    5030 [ld:srv:WG3] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:22 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.733362    5030 [ld:srv:WG3] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:64 (status=NOTFOUND), replying with E::NOSEQUENCER.
I0917 02:14:35.749886    5069 [ld:srv:WB1] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387901 epoch 2 is not available. Highest epoch known is 1.
W0917 02:14:35.751170    5069 [ld:srv:WB1] ClientReadStream.cpp:2476] updateCurrentMetaData() Existing epoch metadata has changed for log 4611686018427387901 on epoch 1, check metadata log!
I0917 02:14:35.752731    5069 [ld:srv:WB1] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [logsconfig] Applied delta record with lsn=e2n1 ts=2021-09-17 02:10:19.558
I0917 02:14:35.754300    5069 [ld:srv:WB1] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [logsconfig] Applied delta record with lsn=e2n2 ts=2021-09-17 02:11:11.944
I0917 02:14:35.779508    5076 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.754, e9n1: SHARD_NEEDS_REBUILD(nodeIdx=2, shardIdx=1, source=N2, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:35.781040    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n1 ts=2021-09-17 02:14:35.754
I0917 02:14:35.782737    5076 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705665)
I0917 02:14:35.823519    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n1 ts=2021-09-17 02:14:35.812 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:35.830990    5076 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.823, e9n2: SHARD_NEEDS_REBUILD(nodeIdx=2, shardIdx=0, source=N2, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:35.838945    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n2 ts=2021-09-17 02:14:35.823
I0917 02:14:35.840515    5076 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705666)
W0917 02:14:35.841575    5076 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.011s, source: [Message sent/received: RECORD]
I0917 02:14:35.846067    5069 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [logsconfig] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:14:35.847906    5069 [ld:srv:WB1] LogsConfigManager.cpp:193] operator()() Received update from LogsConfigStateMachine, version 8589934594
I0917 02:14:35.850863    5069 [ld:srv:WB1] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:14:35.851926    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n2 ts=2021-09-17 02:14:35.840 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:35.852163    5069 [ld:srv:WB1] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 1ms
I0917 02:14:35.853367    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1740] publishDirtyShards() Publishing dirty shards.
I0917 02:14:35.858439    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 1, reason=Node came back with data intact
I0917 02:14:35.854407    5069 [ld:srv:WB1] LogsConfigManager.cpp:331] updateLogsConfig() Published new LogsConfig (fully loaded? yes) version (8589934594) from LogsConfigManager
I0917 02:14:35.864795    5076 [ld:srv:WB3] EventLogWriter.cpp:86] writeEvent() (Queue size: 0) Enqueueing event SHARD_NEEDS_REBUILD(nodeIdx=1, shardIdx=1, source=N1, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}]
I0917 02:14:35.869812    5076 [ld:srv:WB3] EventLogWriter.cpp:50] writeNextEventInQueue() (Queue size: 1) Writing event SHARD_NEEDS_REBUILD(nodeIdx=1, shardIdx=1, source=N1, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}]
W0917 02:14:35.868249    5069 [ld:srv:WB1] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.022s, source: [Message sent/received: GAP]
I0917 02:14:35.870732    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 0, reason=Node came back with data intact
I0917 02:14:35.873437    5076 [ld:srv:WB3] EventLogWriter.cpp:86] writeEvent() (Queue size: 1) Enqueueing event SHARD_NEEDS_REBUILD(nodeIdx=1, shardIdx=0, source=N1, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}]
I0917 02:14:35.875311    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 0 after 1ms
I0917 02:14:35.876231    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 1 after 1ms
I0917 02:14:35.879323    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:2064] subscribeToEventLog() Subscribed to EventLog
I0917 02:14:35.881264    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n3 ts=2021-09-17 02:14:35.869 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:35.896590    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 0 and rebuilding set N2:S0[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:35.898444    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 1 and rebuilding set N2:S1[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:35.905205    5046 [ld:srv:WG4] Appender.cpp:1099] onTimeout() Appender 4611686018427387899e8n4 hit a STORE timeout(10ms), wave 1, recipient set: {N0:S1: STORED, N3:S1: OUTSTANDING}
I0917 02:14:35.905319    5063 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N1 changed from STARTING to FULLY_STARTED
I0917 02:14:35.914713    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [eventlog] Successfully wrote delta with lsn e9n3
I0917 02:14:35.915691    5076 [ld:srv:WB3] EventLogWriter.cpp:67] operator()() Wrote record with lsn e9n3
I0917 02:14:35.917048    5076 [ld:srv:WB3] EventLogWriter.cpp:50] writeNextEventInQueue() (Queue size: 1) Writing event SHARD_NEEDS_REBUILD(nodeIdx=1, shardIdx=0, source=N1, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}]
I0917 02:14:35.920523    5076 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.881, e9n3: SHARD_NEEDS_REBUILD(nodeIdx=1, shardIdx=1, source=N1, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}]
I0917 02:14:35.921500    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n3 ts=2021-09-17 02:14:35.881
I0917 02:14:35.922809    5076 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705667)
I0917 02:14:35.924958    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 1 after 1ms
I0917 02:14:35.928547    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 1, reason=Shard came back with data intact
I0917 02:14:35.929869    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 1 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:35.930921    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}]
I0917 02:14:35.932178    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}]
I0917 02:14:35.933236    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1883] abortForMyShard() Dirty ranges for my shard 1 successfully published
I0917 02:14:35.935461    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:472] noteRangesPublished() Noting dirty ranges published for shard 1
I0917 02:14:35.937874    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 1 and rebuilding set N1:S1[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}],N2:S1[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:35.940547    4995 [ld:srv:WG2] Appender.cpp:1099] onTimeout() Appender 4611686018427387899e8n6 hit a STORE timeout(10ms), wave 1, recipient set: {N0:S1: OUTSTANDING, N4:S1: OUTSTANDING}
I0917 02:14:35.941806    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n4
I0917 02:14:35.955026    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n4 ts=2021-09-17 02:14:35.881 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:35.959360    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n5 ts=2021-09-17 02:14:35.892 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:35.962279    5076 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.929, e9n4: SHARD_NEEDS_REBUILD(nodeIdx=1, shardIdx=0, source=N1, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}]
I0917 02:14:35.965711    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n4 ts=2021-09-17 02:14:35.929
I0917 02:14:35.967217    5076 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705668)
I0917 02:14:35.971224    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 0 after 1ms
I0917 02:14:35.975746    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [eventlog] Successfully wrote delta with lsn e9n4
I0917 02:14:35.979027    5076 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n4
I0917 02:14:35.984481    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 0, reason=Shard came back with data intact
I0917 02:14:35.988482    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 0 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:35.991435    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}]
I0917 02:14:35.992805    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}]
I0917 02:14:35.995229    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1883] abortForMyShard() Dirty ranges for my shard 0 successfully published
I0917 02:14:35.997008    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:472] noteRangesPublished() Noting dirty ranges published for shard 0
I0917 02:14:35.998407    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 0 and rebuilding set N1:S0[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}],N2:S0[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:35.999300    5076 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.933, e9n5: SHARD_NEEDS_REBUILD(nodeIdx=0, shardIdx=1, source=N0, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:09:59.858,2021-09-17 02:10:29.858]}}]
I0917 02:14:36.004011    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n5 ts=2021-09-17 02:14:35.933
I0917 02:14:36.005858    5076 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705669)
I0917 02:14:36.007104    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 1 after 1ms
I0917 02:14:36.009106    5076 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.965, e9n6: SHARD_NEEDS_REBUILD(nodeIdx=0, shardIdx=0, source=N0, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:09:59.859,2021-09-17 02:10:29.859]}}]
I0917 02:14:36.010998    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n6 ts=2021-09-17 02:14:35.965
I0917 02:14:36.013887    5076 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705670)
I0917 02:14:36.016547    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 0 after 1ms
I0917 02:14:36.015469    4995 [ld:srv:WG2] PurgeUncleanEpochs.cpp:592] complete() skipped at least 6 log entries
I0917 02:14:36.017805    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n6 ts=2021-09-17 02:14:35.928 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.021131    5076 [ld:srv:WB3] EventLogWriter.cpp:67] operator()() Wrote record with lsn e9n4
I0917 02:14:36.019314    4995 [ld:srv:WG2] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [1, 1] for log 13835058055282163710.
I0917 02:14:36.034997    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 1, reason=Shard came back with data intact
I0917 02:14:36.037552    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 1 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.038381    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}]
I0917 02:14:36.039164    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}]
I0917 02:14:36.039733    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 1. Converting abort into no-op.
I0917 02:14:36.040691    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 1 and rebuilding set N0:S1[A:{{[2021-09-17 02:09:59.858,2021-09-17 02:10:29.858]}}],N1:S1[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}],N2:S1[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:36.042589    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 0, reason=Shard came back with data intact
I0917 02:14:36.043639    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 0 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.044476    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}]
I0917 02:14:36.049139    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}]
I0917 02:14:36.050540    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 0. Converting abort into no-op.
I0917 02:14:36.051702    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 0 and rebuilding set N0:S0[A:{{[2021-09-17 02:09:59.859,2021-09-17 02:10:29.859]}}],N1:S0[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}],N2:S0[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:36.056851    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n7 ts=2021-09-17 02:14:35.952 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.057929    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n8 ts=2021-09-17 02:14:36.040 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.058798    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n8
I0917 02:14:36.060761    5076 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n8
I0917 02:14:36.066962    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n9 ts=2021-09-17 02:14:36.059 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.073266    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n10 ts=2021-09-17 02:14:36.063 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.075994    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n10
I0917 02:14:36.077326    5076 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n10
I0917 02:14:36.089071    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n11 ts=2021-09-17 02:14:36.068 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.104335    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n12 ts=2021-09-17 02:14:36.080 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.113809    5076 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:36.083, e9n7: SHARD_NEEDS_REBUILD(nodeIdx=4, shardIdx=1, source=N4, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
I0917 02:14:36.117032    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n7 ts=2021-09-17 02:14:36.083
I0917 02:14:36.115893    5063 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from STARTING to FULLY_STARTED
I0917 02:14:36.117622    5076 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705671)
I0917 02:14:36.124423    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 1 after 1ms
I0917 02:14:36.124134    5063 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from STARTING to FULLY_STARTED
W0917 02:14:36.127997    5063 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() skipped at least 10 log entries
W0917 02:14:36.128978    5063 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.012s, source: [Message sent/received: GOSSIP]
I0917 02:14:36.125494    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n12
W0917 02:14:36.136691    5076 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.011s, source: [Request: WORKER_CALLBACK_HELPER]
I0917 02:14:36.138870    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 1, reason=Shard came back with data intact
I0917 02:14:36.141772    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 1 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.145302    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}]
I0917 02:14:36.146332    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}]
I0917 02:14:36.147513    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 1. Converting abort into no-op.
I0917 02:14:36.148557    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 1 and rebuilding set N0:S1[A:{{[2021-09-17 02:09:59.858,2021-09-17 02:10:29.858]}}],N1:S1[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}],N2:S1[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}],N4:S1[A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
I0917 02:14:36.150001    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n13 ts=2021-09-17 02:14:36.084 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.151189    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n14 ts=2021-09-17 02:14:36.092 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.152674    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n15 ts=2021-09-17 02:14:36.094 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.159758    5076 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n12
I0917 02:14:36.165685    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n16 ts=2021-09-17 02:14:36.144 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.173007    5076 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:36.125, e9n8: SHARD_NEEDS_REBUILD(nodeIdx=4, shardIdx=0, source=N4, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
I0917 02:14:36.176376    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n8 ts=2021-09-17 02:14:36.125
I0917 02:14:36.178869    5076 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705672)
I0917 02:14:36.184682    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 0 after 1ms
I0917 02:14:36.187528    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 0, reason=Shard came back with data intact
I0917 02:14:36.189922    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 0 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.198548    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}]
I0917 02:14:36.202911    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}]
I0917 02:14:36.206527    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 0. Converting abort into no-op.
I0917 02:14:36.214320    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 0 and rebuilding set N0:S0[A:{{[2021-09-17 02:09:59.859,2021-09-17 02:10:29.859]}}],N1:S0[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}],N2:S0[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}],N4:S0[A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
I0917 02:14:36.215911    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n17
I0917 02:14:36.217760    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n17 ts=2021-09-17 02:14:36.171 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.220119    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n18 ts=2021-09-17 02:14:36.182 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.221303    5076 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n17
I0917 02:14:36.228793    5063 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from STARTING to FULLY_STARTED
I0917 02:14:36.239472    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n19 ts=2021-09-17 02:14:36.225 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.252086    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n19
I0917 02:14:36.264798    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n20 ts=2021-09-17 02:14:36.230 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.266847    5076 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n19
I0917 02:14:36.270934    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n21 ts=2021-09-17 02:14:36.237 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.281032    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n22 ts=2021-09-17 02:14:36.271 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.282100    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n22
I0917 02:14:36.283428    5076 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n22
I0917 02:14:36.284716    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n23 ts=2021-09-17 02:14:36.276 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.309430    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n24
I0917 02:14:36.312173    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n24 ts=2021-09-17 02:14:36.285 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.314730    5076 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:36.286, e9n9: SHARD_NEEDS_REBUILD(nodeIdx=3, shardIdx=1, source=N3, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:09:59.669,2021-09-17 02:10:29.669]}}]
I0917 02:14:36.316798    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n9 ts=2021-09-17 02:14:36.286
I0917 02:14:36.315702    5030 [ld:srv:WG3] Appender.cpp:1099] onTimeout() skipped at least 10 log entries
I0917 02:14:36.317641    5076 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705673)
I0917 02:14:36.319169    5030 [ld:srv:WG3] Appender.cpp:1099] onTimeout() Appender 4611686018427387899e8n27 hit a STORE timeout(10ms), wave 1, recipient set: {N3:S1: STORED, N1:S1: OUTSTANDING}
I0917 02:14:36.323095    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 1 after 1ms
I0917 02:14:36.328721    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n25 ts=2021-09-17 02:14:36.285 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.330186    5076 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n24
I0917 02:14:36.335655    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 1, reason=Shard came back with data intact
I0917 02:14:36.339254    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 1 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.341982    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}]
I0917 02:14:36.343357    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}]
I0917 02:14:36.344802    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 1. Converting abort into no-op.
I0917 02:14:36.346297    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 1 and rebuilding set N0:S1[A:{{[2021-09-17 02:09:59.858,2021-09-17 02:10:29.858]}}],N1:S1[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}],N2:S1[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}],N3:S1[A:{{[2021-09-17 02:09:59.669,2021-09-17 02:10:29.669]}}],N4:S1[A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
I0917 02:14:36.348272    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n26 ts=2021-09-17 02:14:36.291 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.349880    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n27 ts=2021-09-17 02:14:36.304 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.351799    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n28 ts=2021-09-17 02:14:36.342 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.364445    5076 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:36.350, e9n10: SHARD_NEEDS_REBUILD(nodeIdx=3, shardIdx=0, source=N3, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:09:59.666,2021-09-17 02:10:29.666]}}]
I0917 02:14:36.368207    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n10 ts=2021-09-17 02:14:36.350
I0917 02:14:36.370292    5076 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705674)
I0917 02:14:36.373649    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 0 after 1ms
I0917 02:14:36.375091    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n29 ts=2021-09-17 02:14:36.353 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.378484    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n30 ts=2021-09-17 02:14:36.358 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.375135    5030 [ld:srv:WG3] Appender.cpp:1099] onTimeout() Appender 4611686018427387899e8n31 hit a STORE timeout(10ms), wave 1, recipient set: {N3:S1: STORED, N2:S1: OUTSTANDING}
I0917 02:14:36.379725    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n30
I0917 02:14:36.388993    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 0, reason=Shard came back with data intact
I0917 02:14:36.389933    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 0 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.397410    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}]
I0917 02:14:36.401183    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}]
I0917 02:14:36.405982    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 0. Converting abort into no-op.
I0917 02:14:36.407736    5076 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 0 and rebuilding set N0:S0[A:{{[2021-09-17 02:09:59.859,2021-09-17 02:10:29.859]}}],N1:S0[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}],N2:S0[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}],N3:S0[A:{{[2021-09-17 02:09:59.666,2021-09-17 02:10:29.666]}}],N4:S0[A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
I0917 02:14:36.409374    5076 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n30
I0917 02:14:36.411385    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n31 ts=2021-09-17 02:14:36.362 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.412656    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n32 ts=2021-09-17 02:14:36.375 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.428077    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n33 ts=2021-09-17 02:14:36.412 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.432649    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n34 ts=2021-09-17 02:14:36.412 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.435365    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n35 ts=2021-09-17 02:14:36.417 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.440819    5063 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N3 changed from STARTING to FULLY_STARTED
I0917 02:14:36.442141    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n33
I0917 02:14:36.448165    5076 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n33
I0917 02:14:36.455172    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n36 ts=2021-09-17 02:14:36.429 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.458265    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n37 ts=2021-09-17 02:14:36.433 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.469129    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n38 ts=2021-09-17 02:14:36.453 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.483001    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n39 ts=2021-09-17 02:14:36.463 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.505445    5076 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n40 ts=2021-09-17 02:14:36.496 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.507588    5069 [ld:srv:WB1] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [logsconfig] Could not apply delta record with lsn=e6n1 ts=2021-09-17 02:14:36.493 on base with version e2n2: EXISTS, Adding LogGroup with the path "/test_logs" which already exists in the tree!
I0917 02:14:36.519286    4995 [ld:srv:WG2] Connection.cpp:724] close() Closing socket C38(127.0.0.1:43986). Reason: PEER_CLOSED: connection closed by peer
I0917 02:14:36.521528    4988 [ld:srv:WG1] Connection.cpp:724] close() Closing socket C23(127.0.0.1:43808). Reason: PEER_CLOSED: connection closed by peer
I0917 02:14:36.555877    4995 [ld:srv:WG2] Connection.cpp:724] close() Closing socket C44(127.0.0.1:44062). Reason: PEER_CLOSED: connection closed by peer
I0917 02:14:36.557182    5046 [ld:srv:WG4] Connection.cpp:724] close() Closing socket C37(127.0.0.1:43976). Reason: PEER_CLOSED: connection closed by peer
I0917 02:14:36.557803    4988 [ld:srv:WG1] ProtocolHandler.cpp:127] notifyErrorOnSocket() skipped at least 10 log entries
I0917 02:14:36.562799    4988 [ld:srv:WG1] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket N4:1(127.0.0.1:48408) hit error AsyncSocketException: Socket read end of file., type = End of file
