I0917 02:10:17.000108     312 [logdeviced-main] main.cpp:399] main() Command line arguments: --local-log-store-path /data/store/N4:1/db --num-shards 2 --server-id dajb3r7v2z --log-file /data/store/N4:1/log --name Node4 --config-path file:/data/store/logdevice.conf --client-thrift-api-port 39327 --gossip-port 39321 --server-thrift-api-port 39326 --test-mode true --server-to-server-port 39325 --admin-port 39322 --loglevel info --port 39319 --sequencers lazy 
I0917 02:10:17.001301     312 [logdeviced-main] main.cpp:403] main() Plugins loaded: {"Thrift client factory plugin":"built-in","ZookeeperClient factory":"built-in","ConfigSource factory":["built-in"],"PermissionChecker factory":"built-in","Build Info":"built-in","Plugin provider":["Built-in plugin provider","Static plug-in loader","Dynamic plugin loader"]}
I0917 02:10:17.002383     312 [logdeviced-main] main.cpp:405] main() server starting
I0917 02:10:17.003569     312 [logdeviced-main] main.cpp:410] main() version 99.99.99
I0917 02:10:17.004533     312 [logdeviced-main] main.cpp:418] main() asserts off (NDEBUG set)
I0917 02:10:17.006954     312 [logdeviced-main] TextConfigUpdater.cpp:56] fetchFromSource() Requesting main config "/data/store/logdevice.conf" (source: file)
I0917 02:10:17.009067     312 [logdeviced-main] TextConfigUpdater.cpp:116] onContents() Main config from file, hash = 9egjnxotid
I0917 02:10:17.180537     312 [logdeviced-main] Server.cpp:185] operator()() Updating settings from config took 170ms
I0917 02:10:17.181573     312 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 171ms, config update: 0ms, notifications: 0ms
I0917 02:10:17.182605     312 [logdeviced-main] TextConfigUpdater.cpp:306] pushServerConfig() Updated config (version: 1 - hash: 9egjnxotid)
I0917 02:10:17.183371     312 [logdeviced-main] TextConfigUpdater.cpp:397] pushLogsConfig() Ignoring changes in the 'logs' section in the config file because LogsConfigManager is ENABLED
I0917 02:10:17.184130     312 [logdeviced-main] TextConfigUpdater.cpp:174] update() Config update result: ServerConfig=updated, ZK=skipped, LogsConfig=updated
I0917 02:10:17.184980     312 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:10:17.191228     312 [logdeviced-main] NodesConfigurationInit.cpp:233] operator()() Fetching initial nodes configuration (Attempt 1)...
I0917 02:10:17.195992     320 [ld:file-ncs] NodesConfigurationInit.cpp:290] operator()() Got a NodesConfiguration of version: 5
I0917 02:10:17.196731     320 [ld:file-ncs] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:10:17.198262     312 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:10:17.199231     312 [logdeviced-main] Server.cpp:510] init() My Node ID is N4:1
I0917 02:10:17.200058     312 [logdeviced-main] Server.cpp:517] init() My version is 0
I0917 02:10:17.200765     312 [logdeviced-main] NoopTraceLogger.cpp:22] NoopTraceLogger() NOOP TraceLogger is ON, no trace samples will be published.
I0917 02:10:17.202855     312 [logdeviced-main] FileBasedVersionedConfigStore.cpp:46] stopAndJoin() FileBasedVersionedConfigStore threads stopped.
I0917 02:10:17.203853     312 [logdeviced-main] main.cpp:144] set_fd_limit() Limit on number of file descriptors is 1048576
W0917 02:10:17.207644     312 [logdeviced-main] main.cpp:192] drop_root() Running under root, but no --user command line option specified. Will keep running as root
I0917 02:10:17.209100     312 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 39319
I0917 02:10:17.210799     312 [logdeviced-main] Server.cpp:781] initListeners() Initializing a gossip listener.
I0917 02:10:17.212033     312 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 39321
I0917 02:10:17.214785     312 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 39325 (SSL)
I0917 02:10:17.215548     312 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 39329 (SSL)
I0917 02:10:17.216151     312 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 39328 (SSL)
I0917 02:10:17.234783     312 [logdeviced-main] RocksDBLogStoreConfig.cpp:162] RocksDBLogStoreConfig() LD manages flushes and all memory budgets on the node. atomic_flush is set to true.
I0917 02:10:17.236038     338 [io-stall:s0] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 0
I0917 02:10:17.240882     339 [io-stall:s1] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 1
I0917 02:10:17.244967     362 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:10:17.245585     361 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:10:17.506993     362 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000015.log.trash as trash -- OK
I0917 02:10:17.507730     361 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard0/000013.log.trash as trash -- OK
I0917 02:10:17.514205     363 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N4:1/db/shard1/000015.log.trash
I0917 02:10:17.522795     364 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N4:1/db/shard0/000013.log.trash
I0917 02:10:17.568434     361 [ld:open-rocks0] PartitionedRocksDBStore.cpp:897] open() Shard[0] dirty ranges: []
I0917 02:10:17.570249     362 [ld:open-rocks1] PartitionedRocksDBStore.cpp:897] open() Shard[1] dirty ranges: []
I0917 02:10:17.574183     361 [ld:open-rocks0] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.000s. Read 0 records, 0 bytes. Wrote 0 records, 0 bytes.
I0917 02:10:17.580228     362 [ld:open-rocks1] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.000s. Read 2 records, 214 bytes. Wrote 0 records, 0 bytes.
I0917 02:10:17.646483     345 [rocks-high-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000021.log.trash as trash -- OK
I0917 02:10:17.648606     346 [rocks-high-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard0/000018.log.trash as trash -- OK
I0917 02:10:17.652867     362 [ld:open-rocks1] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N4:1/db/shard1 in 406 ms
I0917 02:10:17.657254     363 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N4:1/db/shard1/000021.log.trash
I0917 02:10:17.660809     364 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N4:1/db/shard0/000018.log.trash
I0917 02:10:17.661940     361 [ld:open-rocks0] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N4:1/db/shard0 in 414 ms
I0917 02:10:17.681002     312 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:691] printDiskShardMapping() Disk -> Shard mapping: /data/store/N4:1/db/shard0 -> [0,1]
I0917 02:10:17.683753     312 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:285] init() Initialized sharded RocksDB instance at /data/store/N4:1/db with 2 shards
E0917 02:10:17.685850    1068 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState0"!
E0917 02:10:17.686265    1069 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState1"!
I0917 02:10:17.697481     312 [logdeviced-main] Server.cpp:1173] initLogStorageStateMap() Populating log storage state map successful.
E0917 02:10:17.704954     312 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:10:17.707516     312 [logdeviced-main] RecordCacheMonitorThread.cpp:27] RecordCacheMonitorThread() Record cache monitor thread started.
I0917 02:10:17.709777     312 [logdeviced-main] ClusterState.cpp:356] resizeClusterState() Cluster state size updated from 0 to 5
I0917 02:10:17.708485    1087 [ld:cache-evict] RecordCacheMonitorThread.cpp:44] threadMain() Record cache eviction thread started. Size limit is set to 4294967296 bytes.
E0917 02:10:17.716758     312 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.721376     312 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.725044     312 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.728893     312 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.746103     312 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:10:17.750177     312 [logdeviced-main] Processor.cpp:247] init() Initialized 5 workers of type GENERAL
E0917 02:10:17.754788     312 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:10:17.757782     312 [logdeviced-main] Processor.cpp:247] init() Initialized 1 workers of type FAILURE_DETECTOR
E0917 02:10:17.762666     312 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.766125     312 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.768821     312 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.771852     312 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:10:17.774631     312 [logdeviced-main] Processor.cpp:247] init() Initialized 4 workers of type BACKGROUND
I0917 02:10:17.777222     312 [logdeviced-main] FailureDetector.cpp:139] FailureDetector() Failure Detector created with instance id: 1631844617777
I0917 02:10:17.783136     312 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N0 changed from UNKNOWN to DEAD
I0917 02:10:17.785683     312 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from HEALTHY to UNHEALTHY
I0917 02:10:17.786985     312 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N1 changed from UNKNOWN to DEAD
I0917 02:10:17.786420    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:10:17.788219     312 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from HEALTHY to UNHEALTHY
I0917 02:10:17.791406     312 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N2 changed from UNKNOWN to DEAD
I0917 02:10:17.792824     312 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from HEALTHY to UNHEALTHY
I0917 02:10:17.795214     312 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N3 changed from UNKNOWN to DEAD
I0917 02:10:17.800794     312 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from HEALTHY to UNHEALTHY
I0917 02:10:17.802807     312 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N4 changed from UNKNOWN to DEAD
I0917 02:10:17.807980     312 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from HEALTHY to UNHEALTHY
W0917 02:10:17.811803    1134 [ld:srv:WG4] Worker.cpp:1322] processRequest() Request queued for 34 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967300), p :HI_PRI
W0917 02:10:17.814734    1123 [ld:srv:WG3] Worker.cpp:1322] processRequest() Request queued for 37 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967299), p :HI_PRI
W0917 02:10:17.821118    1123 [ld:srv:WG3] Worker.cpp:1322] processRequest() Request queued for 35 msec: NODE_STATE_UPDATED (id: 4294967304), p :LO_PRI
W0917 02:10:17.825594    1123 [ld:srv:WG3] Worker.cpp:1322] processRequest() Request queued for 39 msec: NODE_STATE_UPDATED (id: 4294967310), p :LO_PRI
I0917 02:10:17.832814     312 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
W0917 02:10:17.832881    1123 [ld:srv:WG3] Worker.cpp:1322] processRequest() Request queued for 44 msec: NODE_STATE_UPDATED (id: 4294967314), p :LO_PRI
W0917 02:10:17.834888    1123 [ld:srv:WG3] Worker.cpp:1322] processRequest() Request queued for 46 msec: NODE_STATE_UPDATED (id: 4294967320), p :LO_PRI
W0917 02:10:17.838654    1123 [ld:srv:WG3] Worker.cpp:1322] processRequest() Request queued for 45 msec: NODE_STATE_UPDATED (id: 4294967324), p :LO_PRI
I0917 02:10:17.836194    1191 [ld:srv:WB1] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
W0917 02:10:17.848200    1123 [ld:srv:WG3] Worker.cpp:1322] processRequest() Request queued for 55 msec: NODE_STATE_UPDATED (id: 4294967330), p :LO_PRI
I0917 02:10:17.850528    1191 [ld:srv:WB1] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 14ms
W0917 02:10:17.851641    1123 [ld:srv:WG3] Worker.cpp:1322] processRequest() Request queued for 51 msec: NODE_STATE_UPDATED (id: 4294967334), p :LO_PRI
W0917 02:10:17.855008    1123 [ld:srv:WG3] Worker.cpp:1322] processRequest() Request queued for 54 msec: NODE_STATE_UPDATED (id: 4294967340), p :LO_PRI
W0917 02:10:17.854287    1191 [ld:srv:WB1] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.020s, source: [Request: NODES_CONFIGURATION_MANAGER]
I0917 02:10:17.861155    1191 [ld:srv:WB1] NodesConfigurationManager.cpp:507] onProcessingFinished() Updated local nodes config to version 5...
I0917 02:10:17.865061    1084 [ld:s1:default:1] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:10:17.866362    1084 [ld:s1:default:1] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 1, totaling 0 bytes.
I0917 02:10:17.867155    1075 [ld:s0:default:0] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:10:17.868645    1075 [ld:s0:default:0] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 0, totaling 0 bytes.
I0917 02:10:17.871175     312 [logdeviced-main] Server.cpp:1319] initSequencers() Initializing FileEpochStore
I0917 02:10:17.873022     312 [logdeviced-main] Server.cpp:1398] initSequencerPlacement() using SequencerOptions::LAZY
I0917 02:10:17.875011     312 [logdeviced-main] Server.cpp:1430] initRebuildingCoordinator() Initializing EventLog RSM and RebuildingCoordinator
I0917 02:10:17.875787     312 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387903)
I0917 02:10:17.877116     312 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387903, is_server:1)
I0917 02:10:17.879679     312 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:10:17.881068     312 [logdeviced-main] Server.cpp:1467] initRebuildingCoordinator() Starting RebuildingSupervisor
I0917 02:10:17.884830     312 [logdeviced-main] Server.cpp:1480] initRebuildingCoordinator() Starting RebuildingCoordinator
I0917 02:10:17.884979    1134 [ld:srv:WG4] RebuildingSupervisor.cpp:62] init() Starting Rebuilding Supervisor
I0917 02:10:17.887819    1134 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N3 to execute in 1200s
I0917 02:10:17.890717    1134 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N2 to execute in 1200s
I0917 02:10:17.892386    1134 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N1 to execute in 1200s
I0917 02:10:17.891812     312 [logdeviced-main] LogStoreMonitor.cpp:190] start() Logstore monitoring thread started.
I0917 02:10:17.891760    1199 [ld:srv:WB3] RebuildingCoordinator.cpp:309] subscribeToEventLogIfNeeded() RebuildingCoordinator did not start yet because LogsConfig is not fully loaded yet
I0917 02:10:17.893462    1134 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N0 to execute in 1200s
W0917 02:10:17.897896    1134 [ld:srv:WG4] RebuildingSupervisor.cpp:705] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:10:17.894997     312 [logdeviced-main] UnreleasedRecordDetector.cpp:106] start() Unreleased record detector thread started.
I0917 02:10:17.900887     312 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387901)
I0917 02:10:17.896594    1199 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [eventlog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:10:17.910620    1199 [ld:srv:WB3] EventLogStateMachine.cpp:146] gotInitialState() Got base rebuilding set: {}
I0917 02:10:17.899016    1134 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
W0917 02:10:17.914107    1134 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.029s, source: [Request: REBUILDING_SUPERVISOR]
I0917 02:10:17.907915     312 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387901, is_server:1)
I0917 02:10:17.916221     312 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:10:17.913041    1199 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [eventlog] Retrieving tail lsn of delta log...
I0917 02:10:17.920782    1199 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [maintenancelog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:10:17.917336    1191 [ld:srv:WB1] LogsConfigManager.cpp:38] execute() Starting LogsConfigManager on Worker 1 in pool: BACKGROUND
I0917 02:10:17.922978    1191 [ld:srv:WB1] LogsConfigManager.cpp:165] start() Starting LogsConfig Manager RSM
E0917 02:10:17.920886    1123 [ld:srv:WG3] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387903. All sequencer nodes are unavailable.
I0917 02:10:17.922331    1199 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [maintenancelog] Retrieving tail lsn of delta log...
I0917 02:10:17.923810    1191 [ld:srv:WB1] LogsConfigManager.cpp:206] start() Starting LogsConfig Replicated State Machine
I0917 02:10:17.927794    1191 [ld:srv:WB1] ReplicatedStateMachine-inl.h:38] startFetchingSnapshot() [logsconfig] Using RSMSnapshotStore...
E0917 02:10:17.924930    1123 [ld:srv:WG3] SequencerRouter.cpp:56] operator()() Error during sequencer lookup for log 4611686018427387903 (NOSEQUENCER), reporting NOSEQUENCER.
E0917 02:10:17.931635    1123 [ld:srv:WG3] SequencerRouter.cpp:105] onFailure() Error during sequencer routing for log 4611686018427387903 (NOSEQUENCER), request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7efee5fa3028].
E0917 02:10:17.926367    1134 [ld:srv:WG4] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387899. All sequencer nodes are unavailable.
W0917 02:10:17.933539    1134 [ld:srv:WG4] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387899 (rqid:25769803779, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
I0917 02:10:17.929140    1191 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1294] initSnapshotFetchTimer() [logsconfig] Creating timer to fetch snapshots ...
W0917 02:10:17.932968    1123 [ld:srv:WG3] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387903, rqid:25769803777, ctx:rsm, err(NOSEQUENCER)
W0917 02:10:17.936487    1123 [ld:srv:WG3] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387903 (rqid:25769803777, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
E0917 02:10:17.934649    1199 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:25769803779) for log:4611686018427387899, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
E0917 02:10:17.940389    1199 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:25769803777) for log:4611686018427387903, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:10:17.937193     312 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server LogDevice Admin API Service will listen on port 39322
I0917 02:10:17.942315     312 [logdeviced-main] Server.cpp:1540] createAndAttachMaintenanceManager() Not initializing MaintenanceManager since it is disabled in settings
I0917 02:10:17.943805     312 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: s2s-api
I0917 02:10:17.944834     312 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server s2s-api will listen on port 39326
I0917 02:10:17.946832     312 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: c2s-api
I0917 02:10:17.948492     312 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server c2s-api will listen on port 39327
I0917 02:10:17.949549     312 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:10:17.950923     325 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:10:17.955173     312 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:10:17.958148     328 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:10:17.959869     312 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server s2s-api
I0917 02:10:17.959970    1172 [ld:srv:WF0] FailureDetector.cpp:228] startGetClusterState() Sending GET_CLUSTER_STATE to build initial FD cluster view
I0917 02:10:17.962962    1172 [ld:srv:WF0] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket N2:1(127.0.0.1:39343) hit error AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused)
W0917 02:10:17.968710    1172 [ld:srv:WF0] GetClusterStateRequest.cpp:289] onReply() Could not retrieve the state of the cluster from WF0:N1:1 (127.0.0.1:39354): NOTREADY: operation cannot be processed at this time
I0917 02:10:17.972030    1172 [ld:srv:WF0] GetClusterStateRequest.cpp:252] onError() Retrieving the state of the cluster failed. sending another wave.
I0917 02:10:17.973717    1172 [ld:srv:WF0] GET_CLUSTER_STATE_Message.cpp:49] onReceived() Failure detector is not ready
E0917 02:10:17.975749    1172 [ld:srv:WF0] GetClusterStateRequest.cpp:243] onError() Retrieving the state of the cluster failed. giving up.
E0917 02:10:17.977391    1172 [ld:srv:WF0] FailureDetector.cpp:243] operator()() Unable to refresh cluster state: FAILED: request failed
I0917 02:10:17.978662    1172 [ld:srv:WF0] FailureDetector.cpp:288] buildInitialState() Wait over
I0917 02:10:17.979578    1172 [ld:srv:WF0] FailureDetector.cpp:344] buildInitialState() Initializing DomainIsolationChecker
I0917 02:10:17.978807     312 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server c2s-api
I0917 02:10:17.980877    1172 [ld:srv:WF0] FailureDetector.cpp:915] startSuspectTimer() Starting suspect state timer
I0917 02:10:17.983709    1172 [ld:srv:WF0] FailureDetector.cpp:1285] updateNodeState() N4 transitioned from DEAD to ALIVE, FD State:(gossip: 0, instance-id: 0, failover: 0, starting: 1)
I0917 02:10:17.987024    1172 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from DEAD to STARTING
I0917 02:10:17.989932    1172 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting suspect-state-finished message.
I0917 02:10:17.991071    1172 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844617777 to node WF0:N3:1 (127.0.0.1:39332)
I0917 02:10:17.991367     312 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server LogDevice Admin API Service
I0917 02:10:17.992757    1172 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844617777 to node WF0:N2:1 (127.0.0.1:39343)
I0917 02:10:17.995033    1172 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting bringup message.
I0917 02:10:17.996204    1172 [ld:srv:WF0] FailureDetector.cpp:937] startGossiping() Start Gossiping.
I0917 02:10:17.997615    1172 [ld:srv:WF0] FailureDetector.cpp:925] operator()() Suspect timeout expired
I0917 02:10:18.009630    1172 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N1:1 with instance id:1631844617782, sent_time:1631844617998ms
I0917 02:10:18.010782    1172 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N1 changed from DEAD to STARTING
I0917 02:10:18.012525    1134 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N1
I0917 02:10:18.012552    1172 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N1 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844617782, failover: 0, starting: 1)
I0917 02:10:18.014934    1172 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N1:1 with instance id:1631844617782, sent_time:1631844618004ms
I0917 02:10:18.015634    1172 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N1
I0917 02:10:18.016087     312 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:10:18.018239     331 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:10:18.019858     312 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:10:18.020780     325 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:10:18.022629     312 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:10:18.024176     325 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:10:18.026225     312 [logdeviced-main] main.cpp:464] main() Listeners initialized
I0917 02:10:18.040102    1172 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N2:1 with instance id:1631844617789, sent_time:1631844618027ms
I0917 02:10:18.041169    1172 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from DEAD to STARTING
I0917 02:10:18.045080    1172 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N2 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844617789, failover: 0, starting: 1)
I0917 02:10:18.046755    1172 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N2:1 with instance id:1631844617789, sent_time:1631844618035ms
I0917 02:10:18.045038    1134 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N2
I0917 02:10:18.047660    1172 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N2
I0917 02:10:18.053315    1172 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N3:1 with instance id:1631844617866, sent_time:1631844618042ms
I0917 02:10:18.054172    1172 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N3 changed from DEAD to STARTING
I0917 02:10:18.055494    1134 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N3
W0917 02:10:18.056667    1134 [ld:srv:WG4] RebuildingSupervisor.cpp:734] adjustRebuildingThrottle() Exiting throttling mode: #draining=0, #rebuilding=0, #triggers=1, #adjusted cluster size=5, threshold=35%, actual=20%
I0917 02:10:18.055522    1172 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N3 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844617866, failover: 0, starting: 1)
I0917 02:10:18.082005    1134 [ld:srv:WG4] RebuildingSupervisor.cpp:751] adjustRebuildingThrottle() Not triggering new rebuildings until 2021-09-17 02:30:18.081: It's too soon after exiting throttling mode
I0917 02:10:18.084476    1172 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N3
I0917 02:10:18.099148    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from UNHEALTHY to UNDEFINED
I0917 02:10:18.161960    1172 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from DEAD to STARTING
I0917 02:10:18.166530    1134 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N0
I0917 02:10:18.166591    1172 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N0 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844617844, failover: 0, starting: 1)
I0917 02:10:18.168630    1172 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N0
I0917 02:10:18.413362    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from UNDEFINED to HEALTHY
I0917 02:10:18.520909    1076 [ld:s0:default:1] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 4611686018427387900 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:18.523507    1075 [ld:s0:default:0] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 13835058055282163708 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:18.525439    1134 [ld:srv:WG4] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG4:C8 (127.0.0.1:65356)
I0917 02:10:18.618206    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from UNHEALTHY to HEALTHY
I0917 02:10:18.618962    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from UNHEALTHY to HEALTHY
I0917 02:10:18.620173    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from UNHEALTHY to HEALTHY
I0917 02:10:18.626028    1134 [ld:srv:WG4] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 13835058055282163708 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:18.647060    1096 [ld:srv:WG1] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387900 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:18.746539    1134 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163708 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:18.750440    1096 [ld:srv:WG1] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [0, 0] for log 4611686018427387900.
I0917 02:10:18.936029    1191 [ld:srv:WB1] ReplicatedStateMachine-inl.h:130] getSnapshot() [logsconfig] Fetching snapshot with ver:e0n1, (waiting_for_snapshot_:LSN_INVALID, version_:e0n1). sync_state_:0
I0917 02:10:18.939959    1191 [ld:srv:WB1] LogBasedRSMSnapshotStore.cpp:298] onGotLastReleased() Returning EMPTY for log:4611686018427387900, last_released_real_lsn:LSN_INVALID
I0917 02:10:18.940784    1191 [ld:srv:WB1] ReplicatedStateMachine-inl.h:83] operator()() [logsconfig] getSnapshot()'s callback. st:EMPTY, snapshot blob size:0, attrs:(base_ver:LSN_INVALID, ts:0)
I0917 02:10:18.941684    1191 [ld:srv:WB1] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [logsconfig] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:10:18.943382    1191 [ld:srv:WB1] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [logsconfig] Retrieving tail lsn of delta log...
I0917 02:10:18.988015    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:10:18.989214    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:10:19.093213    1092 [ld:srv:WG0] RecordCache.cpp:257] getEpochRecordCache() skipped at least 10 log entries
I0917 02:10:19.096791    1092 [ld:srv:WG0] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 13835058055282163709 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:19.100397    1092 [ld:srv:WG0] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 13835058055282163711 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:19.107477    1096 [ld:srv:WG1] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 4611686018427387899 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:19.114109    1096 [ld:srv:WG1] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.125474    1096 [ld:srv:WG1] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387901 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.135568    1123 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387903 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.222912    1092 [ld:srv:WG0] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163711 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.435871    1172 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from STARTING to FULLY_STARTED
I0917 02:10:19.573567    1111 [ld:srv:WG2] Connection.cpp:724] close() Closing socket C23(127.0.0.1:55034). Reason: PEER_CLOSED: connection closed by peer
I0917 02:10:19.640019    1172 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from STARTING to FULLY_STARTED
I0917 02:10:19.641645    1172 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N3 changed from STARTING to FULLY_STARTED
I0917 02:10:19.675806    1096 [ld:srv:WG1] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387898 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.774895    1092 [ld:srv:WG0] PurgeUncleanEpochs.cpp:592] complete() skipped at least 4 log entries
I0917 02:10:19.775482    1092 [ld:srv:WG0] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [0, 0] for log 4611686018427387902.
I0917 02:10:19.776204    1111 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163706 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.777735    1096 [ld:srv:WG1] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163710 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.951894    1199 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [maintenancelog] Tail lsn of delta log is e2n0
I0917 02:10:19.952703    1191 [ld:srv:WB1] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [logsconfig] Tail lsn of delta log is e2n1
I0917 02:10:19.966158    1199 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387899 epoch 2 is not available. Highest epoch known is 1.
I0917 02:10:19.967037    1199 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [maintenancelog] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:10:19.967855    1199 [ld:srv:WB3] ClusterMaintenanceStateMachine.cpp:112] onUpdate() [maintenancelog] Published new ClusterMaintenanceState version (1)
I0917 02:10:19.968317    1191 [ld:srv:WB1] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387901 epoch 2 is not available. Highest epoch known is 1.
I0917 02:10:19.969474    1191 [ld:srv:WB1] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [logsconfig] Applied delta record with lsn=e2n1 ts=2021-09-17 02:10:19.558
I0917 02:10:19.969956    1191 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [logsconfig] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:10:19.970787    1191 [ld:srv:WB1] LogsConfigManager.cpp:193] operator()() Received update from LogsConfigStateMachine, version 8589934593
I0917 02:10:19.971684    1199 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [eventlog] Tail lsn of delta log is e2n0
I0917 02:10:19.971847    1191 [ld:srv:WB1] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:10:19.973632    1191 [ld:srv:WB1] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 1ms
I0917 02:10:19.974287    1191 [ld:srv:WB1] LogsConfigManager.cpp:331] updateLogsConfig() Published new LogsConfig (fully loaded? yes) version (8589934593) from LogsConfigManager
I0917 02:10:19.974033    1199 [ld:srv:WB3] RebuildingCoordinator.cpp:2064] subscribeToEventLog() Subscribed to EventLog
I0917 02:10:19.986838    1199 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 2 is not available. Highest epoch known is 1.
I0917 02:10:19.988117    1199 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [eventlog] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:10:19.989188    1199 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (1)
I0917 02:10:19.989994    1199 [ld:srv:WB3] RebuildingCoordinator.cpp:1740] publishDirtyShards() Publishing dirty shards.
I0917 02:10:20.048861    1172 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from STARTING to FULLY_STARTED
I0917 02:10:20.253494    1172 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N1 changed from STARTING to FULLY_STARTED
I0917 02:10:27.805050    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 87 log entries
I0917 02:10:27.806194    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.004MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.002MB, [unpartitioned A:0.001MB]
I0917 02:10:29.007736    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:10:29.008684    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.004MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.002MB, [unpartitioned A:0.001MB]
I0917 02:10:29.989825    1199 [ld:srv:WB3] ShardAuthoritativeStatusMap.cpp:165] broadcastToAllWorkers() Posting shard status update to workers: , version=e0n1
I0917 02:10:37.823984    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 74 log entries
I0917 02:10:37.825966    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.004MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.002MB, [unpartitioned A:0.001MB]
I0917 02:10:39.026486    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:10:39.027339    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.004MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.002MB, [unpartitioned A:0.001MB]
I0917 02:10:47.616853     345 [rocks-high-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard0/000021.log.trash as trash -- OK
I0917 02:10:47.617998     346 [rocks-high-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000024.log.trash as trash -- OK
I0917 02:10:47.620974     364 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N4:1/db/shard0/000021.log.trash
I0917 02:10:47.623301     363 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N4:1/db/shard1/000024.log.trash
I0917 02:10:47.656631     342 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000027.sst.trash as trash -- OK
I0917 02:10:47.658244     341 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard0/000024.sst.trash as trash -- OK
I0917 02:10:47.665030     342 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000025.sst.trash as trash -- OK
I0917 02:10:47.666991     364 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 12after deleting file /data/store/N4:1/db/shard0/000024.sst.trash
I0917 02:10:47.668794     363 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 12after deleting file /data/store/N4:1/db/shard1/000027.sst.trash
I0917 02:10:47.674269     341 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard0/000022.sst.trash as trash -- OK
I0917 02:10:47.677298     363 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 23after deleting file /data/store/N4:1/db/shard1/000025.sst.trash
I0917 02:10:47.681232     364 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N4:1/db/shard0/000022.sst.trash
I0917 02:10:47.681588     342 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000019.sst.trash as trash -- OK
I0917 02:10:47.689008     341 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard0/000016.sst.trash as trash -- OK
I0917 02:10:47.695623     363 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N4:1/db/shard1/000019.sst.trash
I0917 02:10:47.697098     364 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N4:1/db/shard0/000016.sst.trash
I0917 02:10:47.698807     342 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000016.sst.trash as trash -- OK
I0917 02:10:47.701118     341 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard0/000014.sst.trash as trash -- OK
I0917 02:10:47.702764     363 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N4:1/db/shard1/000016.sst.trash
I0917 02:10:47.706642     364 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N4:1/db/shard0/000014.sst.trash
I0917 02:10:47.709929     342 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000014.sst.trash as trash -- OK
I0917 02:10:47.715755     363 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N4:1/db/shard1/000014.sst.trash
I0917 02:10:47.845231    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 74 log entries
I0917 02:10:47.846065    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:10:49.047531    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:10:49.048465    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:10:57.864918    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 72 log entries
I0917 02:10:57.866515    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:10:59.066363    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:10:59.067344    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:07.946820    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 76 log entries
I0917 02:11:08.318153    1017 [ld:s1:db-bg-fl] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.371s to write().
I0917 02:11:08.316051    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() skipped at least 1 log entries
I0917 02:11:08.407838    1172 [ld:srv:WF0] debug.cpp:573] log() Slow log() call: it took 0.001s to prepare, 0.091s to write().
I0917 02:11:08.353417    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:08.422231    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from HEALTHY to UNHEALTHY
I0917 02:11:08.444648    1017 [ld:s1:db-bg-fl] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.091s to write().
I0917 02:11:08.472345    1172 [ld:srv:WF0] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.050s to write().
W0917 02:11:08.480290    1172 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() skipped at least 6 log entries
W0917 02:11:08.482316    1172 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.172s, source: [Message sent/received: GET_CLUSTER_STATE]
I0917 02:11:08.584148    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from HEALTHY to UNHEALTHY
I0917 02:11:08.995865    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from HEALTHY to UNHEALTHY
I0917 02:11:08.997110    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from HEALTHY to UNHEALTHY
I0917 02:11:08.997912    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from HEALTHY to UNHEALTHY
I0917 02:11:09.100233    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from UNHEALTHY to HEALTHY
I0917 02:11:09.510846    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from UNHEALTHY to HEALTHY
I0917 02:11:09.523843    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:09.524616    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:10.728355    1123 [ld:srv:WG3] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG3:C33 (127.0.0.1:55528)
I0917 02:11:11.949787    1191 [ld:srv:WB1] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [logsconfig] Applied delta record with lsn=e2n2 ts=2021-09-17 02:11:11.944
I0917 02:11:11.950796    1191 [ld:srv:WB1] LogsConfigManager.cpp:193] operator()() Received update from LogsConfigStateMachine, version 8589934594
I0917 02:11:11.952644    1191 [ld:srv:WB1] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:11:11.954286    1191 [ld:srv:WB1] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 1ms
I0917 02:11:11.955778    1191 [ld:srv:WB1] LogsConfigManager.cpp:331] updateLogsConfig() Published new LogsConfig (fully loaded? yes) version (8589934594) from LogsConfigManager
I0917 02:11:16.244184    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from UNHEALTHY to HEALTHY
I0917 02:11:18.093106    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 84 log entries
I0917 02:11:18.095319    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:19.145634    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:19.146784    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:28.111682    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:11:28.112374    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:29.165283    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:29.165896    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:32.681373    1123 [ld:srv:WG3] CONFIG_FETCH_Message.cpp:70] onReceived() skipped at least 6 log entries
I0917 02:11:32.683159    1123 [ld:srv:WG3] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG3:C33 (127.0.0.1:55528)
I0917 02:11:38.137299    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:11:38.137919    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:39.220446    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:39.221238    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:48.153399    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:11:48.153970    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:49.238119    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:49.239199    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:54.884433    1123 [ld:srv:WG3] CONFIG_FETCH_Message.cpp:70] onReceived() skipped at least 6 log entries
I0917 02:11:54.885179    1123 [ld:srv:WG3] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG3:C33 (127.0.0.1:55528)
I0917 02:11:58.172585    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:11:58.173442    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:59.256038    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:59.257615    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:08.191113    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:08.192050    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:09.274152    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:09.275229    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:16.968471    1123 [ld:srv:WG3] CONFIG_FETCH_Message.cpp:70] onReceived() skipped at least 6 log entries
I0917 02:12:16.969315    1123 [ld:srv:WG3] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG3:C33 (127.0.0.1:55528)
I0917 02:12:18.207559    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:18.208404    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:19.292361    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:19.293228    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:28.223303    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:28.224875    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:29.312057    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:29.312725    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:38.241046    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:38.241765    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:38.884186    1123 [ld:srv:WG3] CONFIG_FETCH_Message.cpp:70] onReceived() skipped at least 6 log entries
I0917 02:12:38.885356    1123 [ld:srv:WG3] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG3:C33 (127.0.0.1:55528)
I0917 02:12:39.329095    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:39.330103    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:48.259327    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:48.260395    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:49.351861    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:49.352640    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:52.863099    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from UNHEALTHY to HEALTHY
I0917 02:12:52.966225    1172 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from UNHEALTHY to HEALTHY
I0917 02:12:58.277296    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:58.277921    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:59.370297    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:59.371067    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:00.936525    1123 [ld:srv:WG3] CONFIG_FETCH_Message.cpp:70] onReceived() skipped at least 6 log entries
I0917 02:13:00.937653    1123 [ld:srv:WG3] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG3:C33 (127.0.0.1:55528)
I0917 02:13:08.293585    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:13:08.294899    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:09.389377    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:13:09.390645    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:18.315106    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:13:18.315897    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:19.410885    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:13:19.411886    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:22.840149    1123 [ld:srv:WG3] CONFIG_FETCH_Message.cpp:70] onReceived() skipped at least 6 log entries
I0917 02:13:22.841012    1123 [ld:srv:WG3] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG3:C33 (127.0.0.1:55528)
I0917 02:13:28.331784    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:13:28.332825    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:29.431316    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:13:29.432108    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:33.750381     315 [ld:conf] FileConfigSource.cpp:86] checkForUpdates() Change detected in config file /data/store/logdevice.conf, mtime = 1631844813641395829
I0917 02:13:33.752037     315 [ld:conf] TextConfigUpdater.cpp:116] onContents() Main config from file, hash = vj0b5rfpgt
I0917 02:13:33.753137     315 [ld:conf] TextConfigUpdater.cpp:245] compareServerConfig() Comparing new config (version 1) with existing config (version 1)
W0917 02:13:33.754001     315 [ld:conf] TextConfigUpdater.cpp:264] compareServerConfig() Received config with same version (1) but mismatched hash (9egjnxotid != vj0b5rfpgt)
I0917 02:13:33.929548     315 [ld:conf] Server.cpp:185] operator()() Updating settings from config took 174ms
I0917 02:13:33.930441     315 [ld:conf] UpdateableSecurityInfo.cpp:124] onConfigUpdate() PermissionChecker is changed
I0917 02:13:33.931201     315 [ld:conf] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:13:33.932509    1172 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting starting_state_finished message.
I0917 02:13:33.932588     315 [ld:conf] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 175ms, config update: 0ms, notifications: 2ms
I0917 02:13:33.933706    1172 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() skipped at least 6 log entries
I0917 02:13:33.933978     315 [ld:conf] TextConfigUpdater.cpp:306] pushServerConfig() Updated config (version: 1 - hash: vj0b5rfpgt)
I0917 02:13:33.935542     315 [ld:conf] TextConfigUpdater.cpp:397] pushLogsConfig() Ignoring changes in the 'logs' section in the config file because LogsConfigManager is ENABLED
I0917 02:13:33.934979    1172 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending starting_state_finished message with instance id:1631844617777 to node WF0:N3:1 (127.0.0.1:39332)
I0917 02:13:33.936615     315 [ld:conf] TextConfigUpdater.cpp:174] update() Config update result: ServerConfig=updated, ZK=skipped, LogsConfig=updated
I0917 02:13:33.937975    1172 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending starting_state_finished message with instance id:1631844617777 to node WF0:N2:1 (127.0.0.1:39343)
I0917 02:13:33.947719    1172 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() skipped at least 3 log entries
I0917 02:13:33.954223    1172 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received starting_state_finished message from N3:1 with instance id:1631844617866, sent_time:1631844813934ms
I0917 02:13:33.955489    1172 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N3
I0917 02:13:33.968965    1172 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received starting_state_finished message from N2:1 with instance id:1631844617789, sent_time:1631844813962ms
I0917 02:13:33.969892    1172 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N2
I0917 02:13:33.985517    1172 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received starting_state_finished message from N1:1 with instance id:1631844617782, sent_time:1631844813981ms
I0917 02:13:33.986100    1172 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N1
I0917 02:13:34.000116    1172 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received starting_state_finished message from N0:1 with instance id:1631844617844, sent_time:1631844813993ms
I0917 02:13:34.001605    1172 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N0
I0917 02:13:38.349849    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:13:38.350568    1017 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:39.448885    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:13:39.450045    1014 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:41.348620    1092 [ld:srv:WG0] ProtocolHandler.cpp:127] notifyErrorOnSocket() skipped at least 7 log entries
I0917 02:13:41.349097    1123 [ld:srv:WG3] Connection.cpp:724] close() Closing socket C33(127.0.0.1:55528). Reason: PEER_CLOSED: connection closed by peer
I0917 02:13:41.351810    1092 [ld:srv:WG0] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket C34(127.0.0.1:55552) hit error AsyncSocketException: Socket read end of file., type = End of file
I0917 02:13:41.353431    1123 [ld:srv:WG3] Connection.cpp:724] close() Closing socket C32(127.0.0.1:55524). Reason: PEER_CLOSED: connection closed by peer
I0917 02:14:06.955784     764 [logdeviced-main] main.cpp:399] main() Command line arguments: --local-log-store-path /data/store/N4:1/db --num-shards 2 --server-id wzt86edlui --log-file /data/store/N4:1/log --name Node4 --config-path file:/data/store/logdevice.conf --client-thrift-api-port 48321 --gossip-port 48315 --server-thrift-api-port 48320 --test-mode true --server-to-server-port 48319 --admin-port 48316 --loglevel info --port 48313 --sequencers lazy 
I0917 02:14:06.956963     764 [logdeviced-main] main.cpp:403] main() Plugins loaded: {"Thrift client factory plugin":"built-in","ZookeeperClient factory":"built-in","ConfigSource factory":["built-in"],"PermissionChecker factory":"built-in","Build Info":"built-in","Plugin provider":["Built-in plugin provider","Static plug-in loader","Dynamic plugin loader"]}
I0917 02:14:06.958239     764 [logdeviced-main] main.cpp:405] main() server starting
I0917 02:14:06.959202     764 [logdeviced-main] main.cpp:410] main() version 99.99.99
I0917 02:14:06.964658     764 [logdeviced-main] main.cpp:418] main() asserts off (NDEBUG set)
I0917 02:14:06.967824     764 [logdeviced-main] TextConfigUpdater.cpp:56] fetchFromSource() Requesting main config "/data/store/logdevice.conf" (source: file)
I0917 02:14:06.971251     764 [logdeviced-main] TextConfigUpdater.cpp:116] onContents() Main config from file, hash = hyg3dqvegx
I0917 02:14:07.702961     764 [logdeviced-main] Server.cpp:185] operator()() Updating settings from config took 730ms
I0917 02:14:07.705938     764 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 733ms, config update: 0ms, notifications: 0ms
I0917 02:14:07.707986     764 [logdeviced-main] TextConfigUpdater.cpp:306] pushServerConfig() Updated config (version: 1 - hash: hyg3dqvegx)
I0917 02:14:07.709527     764 [logdeviced-main] TextConfigUpdater.cpp:397] pushLogsConfig() Ignoring changes in the 'logs' section in the config file because LogsConfigManager is ENABLED
I0917 02:14:07.710381     764 [logdeviced-main] TextConfigUpdater.cpp:174] update() Config update result: ServerConfig=updated, ZK=skipped, LogsConfig=updated
I0917 02:14:07.712250     764 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:14:07.764654     764 [logdeviced-main] NodesConfigurationInit.cpp:233] operator()() Fetching initial nodes configuration (Attempt 1)...
I0917 02:14:07.784766     906 [ld:file-ncs] NodesConfigurationInit.cpp:290] operator()() Got a NodesConfiguration of version: 5
I0917 02:14:07.788382     906 [ld:file-ncs] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:07.790839     764 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:07.791750     764 [logdeviced-main] Server.cpp:510] init() My Node ID is N4:1
I0917 02:14:07.792751     764 [logdeviced-main] Server.cpp:517] init() My version is 0
I0917 02:14:07.797837     764 [logdeviced-main] NoopTraceLogger.cpp:22] NoopTraceLogger() NOOP TraceLogger is ON, no trace samples will be published.
I0917 02:14:07.817506     764 [logdeviced-main] FileBasedVersionedConfigStore.cpp:46] stopAndJoin() FileBasedVersionedConfigStore threads stopped.
I0917 02:14:07.818956     764 [logdeviced-main] main.cpp:144] set_fd_limit() Limit on number of file descriptors is 1048576
W0917 02:14:07.820360     764 [logdeviced-main] main.cpp:192] drop_root() Running under root, but no --user command line option specified. Will keep running as root
I0917 02:14:07.822696     764 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48313
I0917 02:14:07.828329     764 [logdeviced-main] Server.cpp:781] initListeners() Initializing a gossip listener.
I0917 02:14:07.830197     764 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48315
I0917 02:14:07.834683     764 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48319 (SSL)
I0917 02:14:07.836475     764 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48323 (SSL)
I0917 02:14:07.837993     764 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48322 (SSL)
I0917 02:14:07.958035     764 [logdeviced-main] RocksDBLogStoreConfig.cpp:162] RocksDBLogStoreConfig() LD manages flushes and all memory budgets on the node. atomic_flush is set to true.
I0917 02:14:08.011581     933 [io-stall:s1] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 1
I0917 02:14:08.012420     932 [io-stall:s0] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 0
I0917 02:14:08.023876     942 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:08.024407     943 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:08.347152     942 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard0/000034.log.trash as trash -- OK
I0917 02:14:08.354838     944 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N4:1/db/shard0/000034.log.trash
I0917 02:14:08.405760     942 [ld:open-rocks0] PartitionedRocksDBStore.cpp:891] open() Partition s0:1000000 is under-replicated: Start:2021-09-17 02:10:15.337, Min:2021-09-17 02:10:10.337, Max: 2021-09-17 02:10:20.337
I0917 02:14:08.410543     942 [ld:open-rocks0] PartitionedRocksDBStore.cpp:897] open() Shard[0] dirty ranges: [A:{{[2021-09-17 02:10:10.337,2021-09-17 02:10:20.337]}}]
I0917 02:14:08.427884     942 [ld:open-rocks0] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.000s. Read 5 records, 341 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:08.461346     943 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000037.log.trash as trash -- OK
I0917 02:14:08.482038     938 [rocks-high-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard0/000040.log.trash as trash -- OK
I0917 02:14:08.488773     942 [ld:open-rocks0] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N4:1/db/shard0 in 462 ms
I0917 02:14:08.489477     945 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N4:1/db/shard1/000037.log.trash
I0917 02:14:08.492866     944 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N4:1/db/shard0/000040.log.trash
I0917 02:14:08.543091     943 [ld:open-rocks1] PartitionedRocksDBStore.cpp:891] open() Partition s1:1000000 is under-replicated: Start:2021-09-17 02:10:15.332, Min:2021-09-17 02:10:10.332, Max: 2021-09-17 02:10:20.332
I0917 02:14:08.559196     943 [ld:open-rocks1] PartitionedRocksDBStore.cpp:897] open() Shard[1] dirty ranges: [A:{{[2021-09-17 02:10:10.332,2021-09-17 02:10:20.332]}}]
I0917 02:14:08.569953     943 [ld:open-rocks1] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.001s. Read 6 records, 448 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:08.641801     939 [rocks-high-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000043.log.trash as trash -- OK
I0917 02:14:08.642893    1229 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:14:08.651996     943 [ld:open-rocks1] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N4:1/db/shard1 in 620 ms
I0917 02:14:08.652597     945 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N4:1/db/shard1/000043.log.trash
I0917 02:14:08.662487     764 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:691] printDiskShardMapping() Disk -> Shard mapping: /data/store/N4:1/db/shard0 -> [0,1]
I0917 02:14:08.666393     764 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:285] init() Initialized sharded RocksDB instance at /data/store/N4:1/db with 2 shards
E0917 02:14:08.669436    1276 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState1"!
E0917 02:14:08.669934    1275 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState0"!
I0917 02:14:08.675724     764 [logdeviced-main] Server.cpp:1173] initLogStorageStateMap() Populating log storage state map successful.
E0917 02:14:08.687926     764 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:08.694830     764 [logdeviced-main] RecordCacheMonitorThread.cpp:27] RecordCacheMonitorThread() Record cache monitor thread started.
I0917 02:14:08.698645     764 [logdeviced-main] ClusterState.cpp:356] resizeClusterState() Cluster state size updated from 0 to 5
I0917 02:14:08.696683    1307 [ld:cache-evict] RecordCacheMonitorThread.cpp:44] threadMain() Record cache eviction thread started. Size limit is set to 4294967296 bytes.
E0917 02:14:08.724932     764 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:08.731567     764 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:08.751627     764 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:08.769984     764 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:08.799471     764 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:08.805174     764 [logdeviced-main] Processor.cpp:247] init() Initialized 5 workers of type GENERAL
E0917 02:14:08.828321     764 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:08.839882     764 [logdeviced-main] Processor.cpp:247] init() Initialized 1 workers of type FAILURE_DETECTOR
E0917 02:14:08.867345     764 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:08.899423     764 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:08.953190     764 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:08.975462     764 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:08.980222     764 [logdeviced-main] Processor.cpp:247] init() Initialized 4 workers of type BACKGROUND
I0917 02:14:08.982380     764 [logdeviced-main] FailureDetector.cpp:139] FailureDetector() Failure Detector created with instance id: 1631844848982
I0917 02:14:08.987966     764 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N0 changed from UNKNOWN to DEAD
I0917 02:14:08.991006     764 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from HEALTHY to UNHEALTHY
I0917 02:14:08.992497     764 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N1 changed from UNKNOWN to DEAD
I0917 02:14:08.993867     764 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from HEALTHY to UNHEALTHY
I0917 02:14:08.994879     764 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N2 changed from UNKNOWN to DEAD
I0917 02:14:08.996623     764 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from HEALTHY to UNHEALTHY
I0917 02:14:08.997618     764 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N3 changed from UNKNOWN to DEAD
I0917 02:14:08.999651     764 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from HEALTHY to UNHEALTHY
I0917 02:14:09.000783     764 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N4 changed from UNKNOWN to DEAD
I0917 02:14:09.002662     764 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from HEALTHY to UNHEALTHY
W0917 02:14:09.004635    1328 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 22 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967297), p :HI_PRI
W0917 02:14:09.011504    1332 [ld:srv:WG3] Worker.cpp:1322] processRequest() Request queued for 29 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967299), p :HI_PRI
W0917 02:14:09.017314    1334 [ld:srv:WG4] Worker.cpp:1322] processRequest() Request queued for 34 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967300), p :HI_PRI
I0917 02:14:09.025691     764 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
W0917 02:14:09.029333    1330 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 38 msec: NODE_STATE_UPDATED (id: 4294967303), p :LO_PRI
W0917 02:14:09.030997    1330 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 40 msec: NODE_STATE_UPDATED (id: 4294967309), p :LO_PRI
W0917 02:14:09.031989    1330 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 38 msec: NODE_STATE_UPDATED (id: 4294967313), p :LO_PRI
W0917 02:14:09.033316    1330 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 39 msec: NODE_STATE_UPDATED (id: 4294967319), p :LO_PRI
W0917 02:14:09.034331    1330 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 37 msec: NODE_STATE_UPDATED (id: 4294967323), p :LO_PRI
W0917 02:14:09.035957    1330 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 39 msec: NODE_STATE_UPDATED (id: 4294967329), p :LO_PRI
W0917 02:14:09.036866    1330 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 37 msec: NODE_STATE_UPDATED (id: 4294967333), p :LO_PRI
I0917 02:14:09.045036    1519 [ld:srv:WB3] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:14:09.048786    1519 [ld:srv:WB3] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 5ms
I0917 02:14:09.055196    1519 [ld:srv:WB3] NodesConfigurationManager.cpp:507] onProcessingFinished() Updated local nodes config to version 5...
I0917 02:14:09.060375    1300 [ld:s1:default:1] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:09.088087    1300 [ld:s1:default:1] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 1, totaling 0 bytes.
I0917 02:14:09.061010    1289 [ld:s0:default:0] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:09.091765    1289 [ld:s0:default:0] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 0, totaling 0 bytes.
I0917 02:14:09.094512     764 [logdeviced-main] Server.cpp:1319] initSequencers() Initializing FileEpochStore
I0917 02:14:09.095987     764 [logdeviced-main] Server.cpp:1398] initSequencerPlacement() using SequencerOptions::LAZY
I0917 02:14:09.096961     764 [logdeviced-main] Server.cpp:1430] initRebuildingCoordinator() Initializing EventLog RSM and RebuildingCoordinator
I0917 02:14:09.097957     764 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387903)
I0917 02:14:09.099268     764 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387903, is_server:1)
I0917 02:14:09.101557     764 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:09.102483     764 [logdeviced-main] Server.cpp:1467] initRebuildingCoordinator() Starting RebuildingSupervisor
I0917 02:14:09.103770     764 [logdeviced-main] Server.cpp:1480] initRebuildingCoordinator() Starting RebuildingCoordinator
I0917 02:14:09.103894    1334 [ld:srv:WG4] RebuildingSupervisor.cpp:62] init() Starting Rebuilding Supervisor
I0917 02:14:09.106387    1334 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N3 to execute in 1200s
I0917 02:14:09.107198    1334 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N2 to execute in 1200s
I0917 02:14:09.108981    1334 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N1 to execute in 1200s
I0917 02:14:09.114516    1334 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N0 to execute in 1200s
W0917 02:14:09.116721    1334 [ld:srv:WG4] RebuildingSupervisor.cpp:705] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:14:09.116386    1519 [ld:srv:WB3] RebuildingCoordinator.cpp:309] subscribeToEventLogIfNeeded() RebuildingCoordinator did not start yet because LogsConfig is not fully loaded yet
I0917 02:14:09.123212    1519 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [eventlog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:09.117957    1334 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
W0917 02:14:09.128287    1334 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.024s, source: [Request: REBUILDING_SUPERVISOR]
I0917 02:14:09.118541     764 [logdeviced-main] LogStoreMonitor.cpp:190] start() Logstore monitoring thread started.
I0917 02:14:09.134741     764 [logdeviced-main] UnreleasedRecordDetector.cpp:106] start() Unreleased record detector thread started.
I0917 02:14:09.125186    1519 [ld:srv:WB3] EventLogStateMachine.cpp:146] gotInitialState() Got base rebuilding set: {}
I0917 02:14:09.143527    1519 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [eventlog] Retrieving tail lsn of delta log...
I0917 02:14:09.140919     764 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387901)
W0917 02:14:09.147421    1519 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.024s, source: [Request: START_EVENT_LOG_READER]
E0917 02:14:09.147576    1332 [ld:srv:WG3] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387903. All sequencer nodes are unavailable.
E0917 02:14:09.159637    1332 [ld:srv:WG3] SequencerRouter.cpp:56] operator()() Error during sequencer lookup for log 4611686018427387903 (NOSEQUENCER), reporting NOSEQUENCER.
I0917 02:14:09.150688     764 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387901, is_server:1)
I0917 02:14:09.167488     764 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:09.153334    1519 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [maintenancelog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
E0917 02:14:09.164629    1332 [ld:srv:WG3] SequencerRouter.cpp:105] onFailure() Error during sequencer routing for log 4611686018427387903 (NOSEQUENCER), request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7fb53bba4028].
W0917 02:14:09.178435    1332 [ld:srv:WG3] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387903, rqid:8589934613, ctx:rsm, err(NOSEQUENCER)
I0917 02:14:09.169516    1382 [ld:srv:WB1] LogsConfigManager.cpp:38] execute() Starting LogsConfigManager on Worker 1 in pool: BACKGROUND
I0917 02:14:09.185436    1382 [ld:srv:WB1] LogsConfigManager.cpp:165] start() Starting LogsConfig Manager RSM
I0917 02:14:09.186591    1382 [ld:srv:WB1] LogsConfigManager.cpp:206] start() Starting LogsConfig Replicated State Machine
I0917 02:14:09.172056    1519 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [maintenancelog] Retrieving tail lsn of delta log...
W0917 02:14:09.181415    1332 [ld:srv:WG3] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387903 (rqid:8589934613, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
I0917 02:14:09.190793    1382 [ld:srv:WB1] ReplicatedStateMachine-inl.h:38] startFetchingSnapshot() [logsconfig] Using RSMSnapshotStore...
I0917 02:14:09.210572    1382 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1294] initSnapshotFetchTimer() [logsconfig] Creating timer to fetch snapshots ...
E0917 02:14:09.193441    1334 [ld:srv:WG4] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387899. All sequencer nodes are unavailable.
W0917 02:14:09.216635    1334 [ld:srv:WG4] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387899, rqid:8589934615, ctx:rsm, err(NOSEQUENCER)
E0917 02:14:09.201426    1519 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:8589934613) for log:4611686018427387903, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
W0917 02:14:09.219240    1334 [ld:srv:WG4] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387899 (rqid:8589934615, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
I0917 02:14:09.219419     764 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server LogDevice Admin API Service will listen on port 48316
E0917 02:14:09.225384    1519 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:8589934615) for log:4611686018427387899, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:14:09.227606     764 [logdeviced-main] Server.cpp:1540] createAndAttachMaintenanceManager() Not initializing MaintenanceManager since it is disabled in settings
I0917 02:14:09.231938     764 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: s2s-api
I0917 02:14:09.239817     764 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server s2s-api will listen on port 48320
I0917 02:14:09.241247     764 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: c2s-api
I0917 02:14:09.245778     764 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server c2s-api will listen on port 48321
I0917 02:14:09.247590     764 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:09.251797     924 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:09.254805     764 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:09.262510     927 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:09.273366     764 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server s2s-api
I0917 02:14:09.273403    1337 [ld:srv:WF0] FailureDetector.cpp:228] startGetClusterState() Sending GET_CLUSTER_STATE to build initial FD cluster view
I0917 02:14:09.278875    1337 [ld:srv:WF0] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket N3:1(127.0.0.1:48326) hit error AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused)
I0917 02:14:09.297199    1337 [ld:srv:WF0] FailureDetector.cpp:267] operator()() Cluster state received with 5 dead nodes (N0,N1,N2,N3,N4) and 0 boycotted nodes ()
I0917 02:14:09.302296    1337 [ld:srv:WF0] FailureDetector.cpp:288] buildInitialState() Wait over (cluster state received)
I0917 02:14:09.304055    1337 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from DEAD to STARTING
I0917 02:14:09.307826    1337 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N0 transitioned to ALIVE
I0917 02:14:09.311716    1337 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N1 transitioned to DEAD
I0917 02:14:09.311551    1334 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N0
I0917 02:14:09.314772    1337 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N2 transitioned to DEAD
I0917 02:14:09.320728    1337 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N3 transitioned to DEAD
I0917 02:14:09.325276    1337 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from UNHEALTHY to HEALTHY
I0917 02:14:09.326966    1337 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N0 transitioned to HEALTHY (status)
I0917 02:14:09.330106    1337 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N1 transitioned to UNHEALTHY (status)
I0917 02:14:09.335061    1337 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N2 transitioned to UNHEALTHY (status)
I0917 02:14:09.339440    1337 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N3 transitioned to UNHEALTHY (status)
I0917 02:14:09.341560    1337 [ld:srv:WF0] FailureDetector.cpp:344] buildInitialState() Initializing DomainIsolationChecker
I0917 02:14:09.346023    1337 [ld:srv:WF0] FailureDetector.cpp:915] startSuspectTimer() Starting suspect state timer
I0917 02:14:09.348851    1337 [ld:srv:WF0] FailureDetector.cpp:1285] updateNodeState() N4 transitioned from DEAD to ALIVE, FD State:(gossip: 0, instance-id: 0, failover: 0, starting: 1)
I0917 02:14:09.351419    1337 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from DEAD to STARTING
I0917 02:14:09.342813     764 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server c2s-api
I0917 02:14:09.355328    1337 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting suspect-state-finished message.
I0917 02:14:09.372412    1337 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844848982 to node WF0:N3:1 (127.0.0.1:48326)
I0917 02:14:09.375223    1337 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844848982 to node WF0:N2:1 (UNKNOWN)
I0917 02:14:09.379445    1337 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting bringup message.
I0917 02:14:09.383570    1337 [ld:srv:WF0] FailureDetector.cpp:937] startGossiping() Start Gossiping.
I0917 02:14:09.387388    1337 [ld:srv:WF0] FailureDetector.cpp:925] operator()() Suspect timeout expired
I0917 02:14:09.393031    1337 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N2:1 with instance id:1631844848952, sent_time:1631844849351ms
I0917 02:14:09.396419    1337 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from DEAD to STARTING
I0917 02:14:09.398996    1337 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N2 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844848952, failover: 0, starting: 1)
I0917 02:14:09.400628    1337 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N2:1 with instance id:1631844848952, sent_time:1631844849373ms
I0917 02:14:09.399163    1334 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N2
I0917 02:14:09.402107    1337 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N2
I0917 02:14:09.407496     764 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server LogDevice Admin API Service
I0917 02:14:09.464917     764 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:09.470401     928 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:09.472536     764 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:09.477285     924 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:09.481288     764 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:09.483655     924 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:09.485228     764 [logdeviced-main] main.cpp:464] main() Listeners initialized
I0917 02:14:09.489050    1337 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from UNHEALTHY to UNDEFINED
I0917 02:14:09.592365    1337 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from UNDEFINED to HEALTHY
I0917 02:14:09.594319    1337 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N3:1 (127.0.0.1:48326): CONNFAILED: connection failed. Trying another node.
I0917 02:14:09.610626    1337 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from UNHEALTHY to HEALTHY
I0917 02:14:09.619889    1334 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163711 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:09.671851    1328 [ld:srv:WG1] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387903 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:09.749056    1334 [ld:srv:WG4] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [1, 1] for log 13835058055282163711.
I0917 02:14:09.791825    1254 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:14:09.792994    1254 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:14:09.799767    1309 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:238] getSequencer() Sequencer for log:4611686018427387899 is absent, state=UNAVAILABLE, cur_epoch=0, attempting to activate it upon receiving GSS (rqid:8589934617, ctx:rsm, min_epoch:none) from WG0:C5 (127.0.0.1:44916)
I0917 02:14:09.828735    1309 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387899, rqid:8589934617, ctx:rsm) from WG0:C5 (127.0.0.1:44916), but its data log sequencer's state is ACTIVATING
I0917 02:14:09.831922    1309 [ld:srv:WG0] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 4611686018427387899 epoch 4.
I0917 02:14:09.840833    1309 [ld:srv:WG0] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 4611686018427387899: {[E:1 (at 2021-09-17 02:14:09.809) since:1 (at 2021-09-17 02:10:15.170) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S1,N1:S1,N2:S1,N3:S1,N4:S1} W:[]], Until:4}.
I0917 02:14:09.850482    1309 [ld:srv:WG0] AllSequencers.cpp:527] onEpochMetaDataFromEpochStore() Activated a sequencer for log 4611686018427387899 (reason: GET_SEQ_STATE) with epoch 4, metadata: [E:4 (at 2021-09-17 02:14:09.809) since:1 (at 2021-09-17 02:10:15.170) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S1,N1:S1,N2:S1,N3:S1,N4:S1} W:[]]. Activation Result: RECOVERY.
I0917 02:14:09.857712    1334 [ld:srv:WG4] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 4611686018427387899 with next_epoch 4
I0917 02:14:09.860463    1330 [ld:srv:WG2] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 13835058055282163707 epoch 4.
I0917 02:14:09.858070    1309 [ld:srv:WG0] PeriodicReleases.cpp:416] execute() Start broadcasting releases for log 4611686018427387899.
I0917 02:14:09.863365    1309 [ld:srv:WG0] MetaDataLogTrimmer.cpp:115] schedulePeriodicTrimming() Will run periodic trimming every ~7200000 s for 4611686018427387899
I0917 02:14:09.861970    1330 [ld:srv:WG2] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 13835058055282163707: {[E:1 (at -inf) since:1 (at -inf) R:[node: 3] V:2 flags: params:{target:0 seed:0 signature:0} N:{N0:S1,N1:S1,N2:S1,N3:S1,N4:S1} W:[]], Until:4}.
I0917 02:14:09.869201    1330 [ld:srv:WG2] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 13835058055282163707 with next_epoch 4
I0917 02:14:09.896065    1334 [ld:srv:WG4] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [2, 3] of log 4611686018427387899
W0917 02:14:09.907549    1330 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() skipped at least 10 log entries
W0917 02:14:09.909909    1330 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.038s, source: [Request: LOG_RECOVERY]
I0917 02:14:09.915761    1330 [ld:srv:WG2] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [2, 3] of log 13835058055282163707
E0917 02:14:09.917905    1334 [ld:srv:WG4] HELLO_Message.cpp:389] onReceived() PROTOCOL ERROR: got a HELLO from the passive side of connection WG4:N1:1 (127.0.0.1:48346). Closing.
I0917 02:14:09.923982    1334 [ld:srv:WG4] Connection.cpp:724] close() Closing socket N1:1(127.0.0.1:48346). Reason: PROTO: protocol error
I0917 02:14:09.956580    1337 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N3:1 with instance id:1631844849516, sent_time:1631844849893ms
I0917 02:14:09.960658    1337 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N3 changed from DEAD to STARTING
I0917 02:14:09.962725    1337 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N3 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844849516, failover: 0, starting: 1)
I0917 02:14:09.963885    1337 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N3:1 with instance id:1631844849516, sent_time:1631844849948ms
I0917 02:14:09.962716    1334 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N3
I0917 02:14:09.965659    1337 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N3
W0917 02:14:09.966893    1334 [ld:srv:WG4] RebuildingSupervisor.cpp:734] adjustRebuildingThrottle() Exiting throttling mode: #draining=0, #rebuilding=0, #triggers=1, #adjusted cluster size=5, threshold=35%, actual=20%
I0917 02:14:09.968807    1334 [ld:srv:WG4] RebuildingSupervisor.cpp:751] adjustRebuildingThrottle() Not triggering new rebuildings until 2021-09-17 02:34:09.968: It's too soon after exiting throttling mode
I0917 02:14:10.032438    1328 [ld:srv:WG1] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387903 has already been cleaned. No purge needed. last clean epoch: 2, purge to: 2.
I0917 02:14:10.060857    1334 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163711 has already been cleaned. No purge needed. last clean epoch: 2, purge to: 2.
I0917 02:14:10.128788    1330 [ld:srv:WG2] EpochRecovery.cpp:1502] onDigestMayHaveBecomeComplete() Completing an authoritative partial digest for epoch 2 of log 13835058055282163707 because grace period with timeout of 100ms expired. State: {s:N1:S1 m:N0:S1,N2:S1,N3:S1,N4:S1 DIGEST}
I0917 02:14:10.132538    1330 [ld:srv:WG2] EpochRecovery.cpp:566] startMutations() Log 13835058055282163707 epoch 2 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 0, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_INCOMPLETE, mutation set: {N0:S1, N2:S1, N3:S1, N4:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:13835058055282163707 N:e1n1 T:0 AOM:{246:0} F:16], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:13835058055282163707 N:e1n1 T:0 AOM:{246:0} F:16]. Recovery set state when mutation started: {s:N1:S1 m:N0:S1,N2:S1,N3:S1,N4:S1 MUTATION}.
I0917 02:14:10.135006    1334 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163707 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:10.152405    1309 [ld:srv:WG0] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163708 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:10.171198    1334 [ld:srv:WG4] EpochRecovery.cpp:1502] onDigestMayHaveBecomeComplete() Completing an authoritative partial digest for epoch 2 of log 4611686018427387899 because grace period with timeout of 100ms expired. State: {s:N1:S1 m:N0:S1,N2:S1,N3:S1,N4:S1 DIGEST}
I0917 02:14:10.176325    1330 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387900 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:10.181775    1334 [ld:srv:WG4] EpochRecovery.cpp:566] startMutations() Log 4611686018427387899 epoch 2 final digest before mutation: consensus LNG 0, start esn: 1, 0 entries, first esn: 0, last esn: 0, bridge esn: 1, tail esn: 0, mutation set fmajority results: AUTHORITATIVE_INCOMPLETE, mutation set: {N0:S1, N2:S1, N3:S1, N4:S1}, last timestamp: 0, last timestamp from seals: 0. Tail record before this epoch: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0], Tail record from sealed: [L:0 N:LSN_INVALID T:0 AOM:{} F:0](Invalid), final tail record: [L:4611686018427387899 N:LSN_INVALID T:0 AOM:{246:0} F:0]. Recovery set state when mutation started: {s:N1:S1 m:N0:S1,N2:S1,N3:S1,N4:S1 MUTATION}.
I0917 02:14:10.183430    1337 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from UNHEALTHY to HEALTHY
W0917 02:14:10.194864    1330 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.018s, source: [Message sent/received: CLEAN]
I0917 02:14:10.211931    1334 [ld:srv:WG4] Mutator.cpp:400] finalize() Mutator 4611686018427387899e2n1 completed (OK). Trace: W1{N3:S1,N2:S1};X:N3:S1:K;X:N2:S1:K;Y1:N2:S1:K;Y1:N3:S1:K;done:can_replicate:OK;
I0917 02:14:10.212203    1309 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387899, rqid:55834574851, ctx:store-message) from WG0:C13 (127.0.0.1:45050), but its data log sequencer's state is Recovery Incomplete
I0917 02:14:10.213731    1332 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:10.216157    1382 [ld:srv:WB1] ReplicatedStateMachine-inl.h:130] getSnapshot() [logsconfig] Fetching snapshot with ver:e0n1, (waiting_for_snapshot_:LSN_INVALID, version_:e0n1). sync_state_:0
I0917 02:14:10.214297    1309 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387899, rqid:17179869188, ctx:store-message) from WG0:C14 (127.0.0.1:45052), but its data log sequencer's state is Recovery Incomplete
I0917 02:14:10.235890    1519 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [maintenancelog] Tail lsn of delta log is e4n0
I0917 02:14:16.957498    2580 [logdeviced-main] main.cpp:399] main() Command line arguments: --local-log-store-path /data/store/N4:1/db --num-shards 2 --server-id 0pv4i88zl8 --log-file /data/store/N4:1/log --name Node4 --config-path file:/data/store/logdevice.conf --client-thrift-api-port 41053 --gossip-port 41047 --server-thrift-api-port 41052 --test-mode true --server-to-server-port 41051 --admin-port 41048 --loglevel info --port 41045 --sequencers lazy 
I0917 02:14:16.961710    2580 [logdeviced-main] main.cpp:403] main() Plugins loaded: {"Thrift client factory plugin":"built-in","ZookeeperClient factory":"built-in","ConfigSource factory":["built-in"],"PermissionChecker factory":"built-in","Build Info":"built-in","Plugin provider":["Built-in plugin provider","Static plug-in loader","Dynamic plugin loader"]}
I0917 02:14:16.965393    2580 [logdeviced-main] main.cpp:405] main() server starting
I0917 02:14:16.967945    2580 [logdeviced-main] main.cpp:410] main() version 99.99.99
I0917 02:14:16.973105    2580 [logdeviced-main] main.cpp:418] main() asserts off (NDEBUG set)
I0917 02:14:16.980651    2580 [logdeviced-main] TextConfigUpdater.cpp:56] fetchFromSource() Requesting main config "/data/store/logdevice.conf" (source: file)
I0917 02:14:16.996738    2580 [logdeviced-main] TextConfigUpdater.cpp:116] onContents() Main config from file, hash = 99e4033bvf
I0917 02:14:18.049845    2580 [logdeviced-main] Server.cpp:185] operator()() Updating settings from config took 1046ms
I0917 02:14:18.051886    2580 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 1048ms, config update: 0ms, notifications: 0ms
I0917 02:14:18.063694    2580 [logdeviced-main] TextConfigUpdater.cpp:306] pushServerConfig() Updated config (version: 1 - hash: 99e4033bvf)
I0917 02:14:18.070099    2580 [logdeviced-main] TextConfigUpdater.cpp:397] pushLogsConfig() Ignoring changes in the 'logs' section in the config file because LogsConfigManager is ENABLED
I0917 02:14:18.072892    2580 [logdeviced-main] TextConfigUpdater.cpp:174] update() Config update result: ServerConfig=updated, ZK=skipped, LogsConfig=updated
I0917 02:14:18.076492    2580 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:14:18.087446    2580 [logdeviced-main] NodesConfigurationInit.cpp:233] operator()() Fetching initial nodes configuration (Attempt 1)...
I0917 02:14:18.101522    2746 [ld:file-ncs] NodesConfigurationInit.cpp:290] operator()() Got a NodesConfiguration of version: 5
I0917 02:14:18.108897    2746 [ld:file-ncs] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:18.114281    2580 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:18.118358    2580 [logdeviced-main] Server.cpp:510] init() My Node ID is N4:1
I0917 02:14:18.126018    2580 [logdeviced-main] Server.cpp:517] init() My version is 0
I0917 02:14:18.132057    2580 [logdeviced-main] NoopTraceLogger.cpp:22] NoopTraceLogger() NOOP TraceLogger is ON, no trace samples will be published.
I0917 02:14:18.141642    2580 [logdeviced-main] FileBasedVersionedConfigStore.cpp:46] stopAndJoin() FileBasedVersionedConfigStore threads stopped.
I0917 02:14:18.145066    2580 [logdeviced-main] main.cpp:144] set_fd_limit() Limit on number of file descriptors is 1048576
W0917 02:14:18.149668    2580 [logdeviced-main] main.cpp:192] drop_root() Running under root, but no --user command line option specified. Will keep running as root
I0917 02:14:18.175675    2580 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 41045
I0917 02:14:18.183964    2580 [logdeviced-main] Server.cpp:781] initListeners() Initializing a gossip listener.
I0917 02:14:18.220490    2580 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 41047
I0917 02:14:18.236952    2580 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 41051 (SSL)
I0917 02:14:18.240697    2580 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 41055 (SSL)
I0917 02:14:18.243857    2580 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 41054 (SSL)
I0917 02:14:18.315585    2580 [logdeviced-main] RocksDBLogStoreConfig.cpp:162] RocksDBLogStoreConfig() LD manages flushes and all memory budgets on the node. atomic_flush is set to true.
I0917 02:14:18.328888    2817 [io-stall:s1] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 1
I0917 02:14:18.344509    2816 [io-stall:s0] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 0
I0917 02:14:18.344565    2825 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:18.352125    2824 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:19.578963    2824 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard0/000051.log.trash as trash -- OK
I0917 02:14:19.599610    2825 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000057.log.trash as trash -- OK
I0917 02:14:19.599745    2827 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N4:1/db/shard0/000051.log.trash
I0917 02:14:19.633135    2826 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N4:1/db/shard1/000057.log.trash
I0917 02:14:19.727643    2824 [ld:open-rocks0] PartitionedRocksDBStore.cpp:891] open() Partition s0:1000000 is under-replicated: Start:2021-09-17 02:10:15.337, Min:2021-09-17 02:10:05.337, Max: 2021-09-17 02:10:25.337
I0917 02:14:19.734720    2824 [ld:open-rocks0] PartitionedRocksDBStore.cpp:897] open() Shard[0] dirty ranges: [A:{{[2021-09-17 02:10:05.337,2021-09-17 02:10:25.337]}}]
I0917 02:14:19.754906    2825 [ld:open-rocks1] PartitionedRocksDBStore.cpp:891] open() Partition s1:1000000 is under-replicated: Start:2021-09-17 02:10:15.332, Min:2021-09-17 02:10:05.332, Max: 2021-09-17 02:10:25.332
I0917 02:14:19.758878    2825 [ld:open-rocks1] PartitionedRocksDBStore.cpp:897] open() Shard[1] dirty ranges: [A:{{[2021-09-17 02:10:05.332,2021-09-17 02:10:25.332]}}]
I0917 02:14:19.775300    2824 [ld:open-rocks0] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.001s. Read 5 records, 341 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:19.786033    2825 [ld:open-rocks1] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.001s. Read 8 records, 534 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:19.971521    2822 [rocks-high-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000063.log.trash as trash -- OK
I0917 02:14:19.985868    3282 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 1ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:14:19.997657    2823 [rocks-high-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard0/000056.log.trash as trash -- OK
I0917 02:14:19.997978    2825 [ld:open-rocks1] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N4:1/db/shard1 in 1636 ms
I0917 02:14:20.005667    2826 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N4:1/db/shard1/000063.log.trash
I0917 02:14:20.029906    2824 [ld:open-rocks0] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N4:1/db/shard0 in 1656 ms
I0917 02:14:20.035466    2827 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N4:1/db/shard0/000056.log.trash
I0917 02:14:20.066475    2580 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:691] printDiskShardMapping() Disk -> Shard mapping: /data/store/N4:1/db/shard0 -> [0,1]
I0917 02:14:20.070363    2580 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:285] init() Initialized sharded RocksDB instance at /data/store/N4:1/db with 2 shards
I0917 02:14:20.074438    2819 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000067.sst.trash as trash -- OK
E0917 02:14:20.077933    3392 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState1"!
E0917 02:14:20.080840    3391 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState0"!
I0917 02:14:20.099676    2826 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N4:1/db/shard1/000067.sst.trash
I0917 02:14:20.111734    2580 [logdeviced-main] Server.cpp:1173] initLogStorageStateMap() Populating log storage state map successful.
I0917 02:14:20.112384    2819 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000061.sst.trash as trash -- OK
I0917 02:14:20.168745    2819 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000058.sst.trash as trash -- OK
E0917 02:14:20.168827    2580 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.177067    2826 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N4:1/db/shard1/000061.sst.trash
I0917 02:14:20.190102    2580 [logdeviced-main] RecordCacheMonitorThread.cpp:27] RecordCacheMonitorThread() Record cache monitor thread started.
I0917 02:14:20.197747    2580 [logdeviced-main] ClusterState.cpp:356] resizeClusterState() Cluster state size updated from 0 to 5
I0917 02:14:20.191524    3446 [ld:cache-evict] RecordCacheMonitorThread.cpp:44] threadMain() Record cache eviction thread started. Size limit is set to 4294967296 bytes.
I0917 02:14:20.203106    2826 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N4:1/db/shard1/000058.sst.trash
E0917 02:14:20.207859    2580 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.247326    2819 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000056.sst.trash as trash -- OK
E0917 02:14:20.267149    2580 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.285711    2819 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000049.sst.trash as trash -- OK
I0917 02:14:20.290851    2826 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N4:1/db/shard1/000056.sst.trash
E0917 02:14:20.292097    2580 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:20.321317    2580 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.327410    2819 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000047.sst.trash as trash -- OK
I0917 02:14:20.336380    2826 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N4:1/db/shard1/000049.sst.trash
E0917 02:14:20.336453    2580 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.356979    2580 [logdeviced-main] Processor.cpp:247] init() Initialized 5 workers of type GENERAL
I0917 02:14:20.366990    2826 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N4:1/db/shard1/000047.sst.trash
E0917 02:14:20.373439    2580 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.379639    2580 [logdeviced-main] Processor.cpp:247] init() Initialized 1 workers of type FAILURE_DETECTOR
I0917 02:14:20.384660    2819 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000041.sst.trash as trash -- OK
E0917 02:14:20.399291    2580 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:20.419933    2580 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.425566    2819 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000038.sst.trash as trash -- OK
I0917 02:14:20.435742    2826 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N4:1/db/shard1/000041.sst.trash
E0917 02:14:20.437806    2580 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.471086    2826 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N4:1/db/shard1/000038.sst.trash
E0917 02:14:20.485045    2580 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.498296    2819 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000036.sst.trash as trash -- OK
I0917 02:14:20.504108    2580 [logdeviced-main] Processor.cpp:247] init() Initialized 4 workers of type BACKGROUND
I0917 02:14:20.532638    2580 [logdeviced-main] FailureDetector.cpp:139] FailureDetector() Failure Detector created with instance id: 1631844860532
I0917 02:14:20.542497    2580 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N0 changed from UNKNOWN to DEAD
I0917 02:14:20.547067    2580 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from HEALTHY to UNHEALTHY
I0917 02:14:20.556147    2580 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N1 changed from UNKNOWN to DEAD
I0917 02:14:20.560043    2580 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from HEALTHY to UNHEALTHY
I0917 02:14:20.571588    2580 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N2 changed from UNKNOWN to DEAD
I0917 02:14:20.580527    2826 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N4:1/db/shard1/000036.sst.trash
I0917 02:14:20.574417    2819 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000029.sst.trash as trash -- OK
I0917 02:14:20.580999    2580 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from HEALTHY to UNHEALTHY
I0917 02:14:20.602045    2580 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N3 changed from UNKNOWN to DEAD
I0917 02:14:20.605366    2580 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from HEALTHY to UNHEALTHY
I0917 02:14:20.609204    2580 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N4 changed from UNKNOWN to DEAD
I0917 02:14:20.611183    2580 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from HEALTHY to UNHEALTHY
I0917 02:14:20.607967    2826 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 13after deleting file /data/store/N4:1/db/shard1/000029.sst.trash
W0917 02:14:20.619113    3456 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 86 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967296), p :HI_PRI
W0917 02:14:20.656226    3469 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 123 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967298), p :HI_PRI
W0917 02:14:20.673916    3456 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 127 msec: NODE_STATE_UPDATED (id: 4294967301), p :LO_PRI
W0917 02:14:20.680934    3456 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 134 msec: NODE_STATE_UPDATED (id: 4294967306), p :LO_PRI
W0917 02:14:20.703927    3456 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 156 msec: NODE_STATE_UPDATED (id: 4294967307), p :LO_PRI
W0917 02:14:20.721088    3456 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 161 msec: NODE_STATE_UPDATED (id: 4294967311), p :LO_PRI
W0917 02:14:20.726472    3456 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 166 msec: NODE_STATE_UPDATED (id: 4294967316), p :LO_PRI
W0917 02:14:20.729556    3456 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 169 msec: NODE_STATE_UPDATED (id: 4294967317), p :LO_PRI
W0917 02:14:20.733624    3456 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 151 msec: NODE_STATE_UPDATED (id: 4294967321), p :LO_PRI
I0917 02:14:20.770939    2580 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:14:20.788897    3482 [ld:srv:WB1] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:14:20.782756    3456 [ld:srv:WG0] debug.cpp:573] log() Slow log() call: it took 0.002s to prepare, 0.049s to write().
I0917 02:14:20.804553    3482 [ld:srv:WB1] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 16ms
W0917 02:14:20.810680    3456 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 229 msec: NODE_STATE_UPDATED (id: 4294967326), p :LO_PRI
W0917 02:14:20.815365    3482 [ld:srv:WB1] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.028s, source: [Request: NODES_CONFIGURATION_MANAGER]
I0917 02:14:20.853570    3482 [ld:srv:WB1] NodesConfigurationManager.cpp:507] onProcessingFinished() Updated local nodes config to version 5...
I0917 02:14:20.867619    3425 [ld:s1:default:0] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:20.891430    3425 [ld:s1:default:0] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 1, totaling 0 bytes.
I0917 02:14:20.867854    3415 [ld:s0:default:0] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:20.901368    3415 [ld:s0:default:0] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 0, totaling 0 bytes.
I0917 02:14:20.912765    2580 [logdeviced-main] Server.cpp:1319] initSequencers() Initializing FileEpochStore
I0917 02:14:20.917953    2580 [logdeviced-main] Server.cpp:1398] initSequencerPlacement() using SequencerOptions::LAZY
I0917 02:14:20.925099    2580 [logdeviced-main] Server.cpp:1430] initRebuildingCoordinator() Initializing EventLog RSM and RebuildingCoordinator
I0917 02:14:20.935839    2580 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387903)
I0917 02:14:20.940644    2580 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387903, is_server:1)
I0917 02:14:20.949111    2580 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:20.958625    2580 [logdeviced-main] Server.cpp:1467] initRebuildingCoordinator() Starting RebuildingSupervisor
I0917 02:14:20.962849    2580 [logdeviced-main] Server.cpp:1480] initRebuildingCoordinator() Starting RebuildingCoordinator
I0917 02:14:20.963605    3476 [ld:srv:WG4] RebuildingSupervisor.cpp:62] init() Starting Rebuilding Supervisor
I0917 02:14:20.985390    2580 [logdeviced-main] LogStoreMonitor.cpp:190] start() Logstore monitoring thread started.
I0917 02:14:21.021938    2580 [logdeviced-main] UnreleasedRecordDetector.cpp:106] start() Unreleased record detector thread started.
I0917 02:14:20.985475    3476 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N3 to execute in 1200s
I0917 02:14:21.025100    2580 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387901)
I0917 02:14:20.988271    3488 [ld:srv:WB3] RebuildingCoordinator.cpp:309] subscribeToEventLogIfNeeded() RebuildingCoordinator did not start yet because LogsConfig is not fully loaded yet
I0917 02:14:21.054742    3488 [ld:srv:WB3] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.066s to write().
I0917 02:14:21.031934    3476 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N2 to execute in 1200s
I0917 02:14:21.041599    3285 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:14:21.085726    3285 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:14:21.049060    2580 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387901, is_server:1)
I0917 02:14:21.101804    2580 [logdeviced-main] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.053s to write().
I0917 02:14:21.103605    2580 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
W0917 02:14:21.060586    3488 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.073s, source: [Request: REBUILDING_COORDINATOR_INIT_REQUEST]
I0917 02:14:21.111424    3488 [ld:srv:WB3] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.051s to write().
I0917 02:14:21.079541    3476 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N1 to execute in 1200s
I0917 02:14:21.123276    3476 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N0 to execute in 1200s
I0917 02:14:21.106534    3482 [ld:srv:WB1] LogsConfigManager.cpp:38] execute() Starting LogsConfigManager on Worker 1 in pool: BACKGROUND
I0917 02:14:21.137485    3482 [ld:srv:WB1] LogsConfigManager.cpp:165] start() Starting LogsConfig Manager RSM
I0917 02:14:21.140931    3482 [ld:srv:WB1] LogsConfigManager.cpp:206] start() Starting LogsConfig Replicated State Machine
I0917 02:14:21.122258    3488 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [eventlog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:21.158827    3488 [ld:srv:WB3] EventLogStateMachine.cpp:146] gotInitialState() Got base rebuilding set: {}
W0917 02:14:21.127242    3476 [ld:srv:WG4] RebuildingSupervisor.cpp:705] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:14:21.176654    3476 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:14:21.149366    3482 [ld:srv:WB1] ReplicatedStateMachine-inl.h:38] startFetchingSnapshot() [logsconfig] Using RSMSnapshotStore...
I0917 02:14:21.169784    3488 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [eventlog] Retrieving tail lsn of delta log...
I0917 02:14:21.186656    3482 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1294] initSnapshotFetchTimer() [logsconfig] Creating timer to fetch snapshots ...
I0917 02:14:21.191860    3488 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [maintenancelog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:21.205692    3488 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [maintenancelog] Retrieving tail lsn of delta log...
E0917 02:14:21.191906    3474 [ld:srv:WG3] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387903. All sequencer nodes are unavailable.
E0917 02:14:21.222868    3474 [ld:srv:WG3] SequencerRouter.cpp:105] onFailure() Error during sequencer routing for log 4611686018427387903 (NOSEQUENCER), request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7f5c3f7a7028].
E0917 02:14:21.211906    3476 [ld:srv:WG4] SequencerRouter.cpp:56] operator()() Error during sequencer lookup for log 4611686018427387899 (NOSEQUENCER), reporting NOSEQUENCER.
W0917 02:14:21.232587    3476 [ld:srv:WG4] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387899 (rqid:30064771075, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
I0917 02:14:21.223019    2580 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server LogDevice Admin API Service will listen on port 41048
I0917 02:14:21.250935    2580 [logdeviced-main] Server.cpp:1540] createAndAttachMaintenanceManager() Not initializing MaintenanceManager since it is disabled in settings
W0917 02:14:21.225444    3474 [ld:srv:WG3] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387903, rqid:30064771073, ctx:rsm, err(NOSEQUENCER)
W0917 02:14:21.270107    3474 [ld:srv:WG3] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387903 (rqid:30064771073, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
E0917 02:14:21.238716    3488 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:30064771075) for log:4611686018427387899, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
E0917 02:14:21.277506    3488 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:30064771073) for log:4611686018427387903, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:14:21.254539    2580 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: s2s-api
I0917 02:14:21.293548    2580 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server s2s-api will listen on port 41052
I0917 02:14:21.314321    2580 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: c2s-api
I0917 02:14:21.328369    2580 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server c2s-api will listen on port 41053
I0917 02:14:21.330950    2580 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:21.341005    2777 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:21.347024    2580 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:21.367100    2793 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:21.375048    2580 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server s2s-api
I0917 02:14:21.377349    3478 [ld:srv:WF0] FailureDetector.cpp:228] startGetClusterState() Sending GET_CLUSTER_STATE to build initial FD cluster view
I0917 02:14:21.384408    3478 [ld:srv:WF0] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket N3:1(127.0.0.1:41058) hit error AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused)
I0917 02:14:21.405414    3478 [ld:srv:WF0] FailureDetector.cpp:267] operator()() Cluster state received with 5 dead nodes (N0,N1,N2,N3,N4) and 0 boycotted nodes ()
I0917 02:14:21.408102    3478 [ld:srv:WF0] FailureDetector.cpp:288] buildInitialState() Wait over (cluster state received)
I0917 02:14:21.410541    3478 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from DEAD to STARTING
I0917 02:14:21.414447    3478 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N0 transitioned to ALIVE
I0917 02:14:21.416523    3478 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N1 changed from DEAD to STARTING
I0917 02:14:21.415502    3476 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N0
I0917 02:14:21.420797    3478 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N1 transitioned to ALIVE
I0917 02:14:21.428696    3478 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N2 transitioned to DEAD
I0917 02:14:21.426952    3476 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N1
I0917 02:14:21.431651    3478 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N3 transitioned to DEAD
I0917 02:14:21.444970    3478 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N0 transitioned to UNHEALTHY (status)
I0917 02:14:21.447709    3478 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N1 transitioned to UNHEALTHY (status)
I0917 02:14:21.450939    3478 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N2 transitioned to UNHEALTHY (status)
I0917 02:14:21.452809    3478 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N3 transitioned to UNHEALTHY (status)
I0917 02:14:21.455683    3478 [ld:srv:WF0] FailureDetector.cpp:344] buildInitialState() Initializing DomainIsolationChecker
I0917 02:14:21.458700    3478 [ld:srv:WF0] FailureDetector.cpp:915] startSuspectTimer() Starting suspect state timer
I0917 02:14:21.462262    3478 [ld:srv:WF0] FailureDetector.cpp:1285] updateNodeState() N4 transitioned from DEAD to ALIVE, FD State:(gossip: 0, instance-id: 0, failover: 0, starting: 1)
I0917 02:14:21.465901    3478 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from DEAD to STARTING
I0917 02:14:21.463482    2580 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server c2s-api
I0917 02:14:21.468991    3478 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting suspect-state-finished message.
I0917 02:14:21.473931    3478 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844860532 to node WF0:N3:1 (127.0.0.1:41058)
I0917 02:14:21.476461    3478 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844860532 to node WF0:N2:1 (UNKNOWN)
I0917 02:14:21.480582    3478 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting bringup message.
I0917 02:14:21.487027    3478 [ld:srv:WF0] FailureDetector.cpp:937] startGossiping() Start Gossiping.
I0917 02:14:21.492435    3478 [ld:srv:WF0] FailureDetector.cpp:925] operator()() Suspect timeout expired
W0917 02:14:21.535384    3469 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() skipped at least 10 log entries
W0917 02:14:21.539422    3469 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.012s, source: [Message sent/received: START]
I0917 02:14:21.540494    2580 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server LogDevice Admin API Service
I0917 02:14:21.583538    2580 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:21.596045    2811 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:21.601840    2580 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:21.604614    2777 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:21.685582    3469 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163711 has already been cleaned. No purge needed. last clean epoch: 3, purge to: 3.
I0917 02:14:21.798135    3469 [ld:srv:WG2] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [3, 3] for log 13835058055282163711.
I0917 02:14:21.810772    3478 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N3:1 (127.0.0.1:41058): CONNFAILED: connection failed. Trying another node.
I0917 02:14:30.462057    4399 [logdeviced-main] main.cpp:399] main() Command line arguments: --local-log-store-path /data/store/N4:1/db --num-shards 2 --server-id 8qyq7zq321 --log-file /data/store/N4:1/log --name Node4 --config-path file:/data/store/logdevice.conf --client-thrift-api-port 48416 --gossip-port 48410 --server-thrift-api-port 48415 --test-mode true --server-to-server-port 48414 --admin-port 48411 --loglevel info --port 48408 --sequencers lazy 
I0917 02:14:30.464756    4399 [logdeviced-main] main.cpp:403] main() Plugins loaded: {"Thrift client factory plugin":"built-in","ZookeeperClient factory":"built-in","ConfigSource factory":["built-in"],"PermissionChecker factory":"built-in","Build Info":"built-in","Plugin provider":["Built-in plugin provider","Static plug-in loader","Dynamic plugin loader"]}
I0917 02:14:30.465653    4399 [logdeviced-main] main.cpp:405] main() server starting
I0917 02:14:30.466625    4399 [logdeviced-main] main.cpp:410] main() version 99.99.99
I0917 02:14:30.467400    4399 [logdeviced-main] main.cpp:418] main() asserts off (NDEBUG set)
I0917 02:14:30.469858    4399 [logdeviced-main] TextConfigUpdater.cpp:56] fetchFromSource() Requesting main config "/data/store/logdevice.conf" (source: file)
I0917 02:14:30.472539    4399 [logdeviced-main] TextConfigUpdater.cpp:116] onContents() Main config from file, hash = ndhqu97h59
I0917 02:14:30.919187    4399 [logdeviced-main] Server.cpp:185] operator()() Updating settings from config took 445ms
I0917 02:14:30.922857    4399 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 448ms, config update: 0ms, notifications: 0ms
I0917 02:14:30.926222    4399 [logdeviced-main] TextConfigUpdater.cpp:306] pushServerConfig() Updated config (version: 1 - hash: ndhqu97h59)
I0917 02:14:30.927891    4399 [logdeviced-main] TextConfigUpdater.cpp:397] pushLogsConfig() Ignoring changes in the 'logs' section in the config file because LogsConfigManager is ENABLED
I0917 02:14:30.929281    4399 [logdeviced-main] TextConfigUpdater.cpp:174] update() Config update result: ServerConfig=updated, ZK=skipped, LogsConfig=updated
I0917 02:14:30.930844    4399 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:14:30.945079    4399 [logdeviced-main] NodesConfigurationInit.cpp:233] operator()() Fetching initial nodes configuration (Attempt 1)...
I0917 02:14:30.952124    4698 [ld:file-ncs] NodesConfigurationInit.cpp:290] operator()() Got a NodesConfiguration of version: 5
I0917 02:14:30.957092    4698 [ld:file-ncs] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:30.961817    4399 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:30.963449    4399 [logdeviced-main] Server.cpp:510] init() My Node ID is N4:1
I0917 02:14:30.965175    4399 [logdeviced-main] Server.cpp:517] init() My version is 0
I0917 02:14:30.966718    4399 [logdeviced-main] NoopTraceLogger.cpp:22] NoopTraceLogger() NOOP TraceLogger is ON, no trace samples will be published.
I0917 02:14:30.975856    4399 [logdeviced-main] FileBasedVersionedConfigStore.cpp:46] stopAndJoin() FileBasedVersionedConfigStore threads stopped.
I0917 02:14:30.981291    4399 [logdeviced-main] main.cpp:144] set_fd_limit() Limit on number of file descriptors is 1048576
W0917 02:14:30.983982    4399 [logdeviced-main] main.cpp:192] drop_root() Running under root, but no --user command line option specified. Will keep running as root
I0917 02:14:30.988244    4399 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48408
I0917 02:14:30.992702    4399 [logdeviced-main] Server.cpp:781] initListeners() Initializing a gossip listener.
I0917 02:14:31.000883    4399 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48410
I0917 02:14:31.009468    4399 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48414 (SSL)
I0917 02:14:31.012336    4399 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48418 (SSL)
I0917 02:14:31.013692    4399 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48417 (SSL)
I0917 02:14:31.065504    4399 [logdeviced-main] RocksDBLogStoreConfig.cpp:162] RocksDBLogStoreConfig() LD manages flushes and all memory budgets on the node. atomic_flush is set to true.
I0917 02:14:31.065706    4775 [io-stall:s1] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 1
I0917 02:14:31.066055    4774 [io-stall:s0] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 0
I0917 02:14:31.082507    4803 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:31.082724    4802 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:31.461670    4803 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000078.log.trash as trash -- OK
I0917 02:14:31.475191    4802 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard0/000070.log.trash as trash -- OK
I0917 02:14:31.475698    4805 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N4:1/db/shard1/000078.log.trash
I0917 02:14:31.492428    4804 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N4:1/db/shard0/000070.log.trash
I0917 02:14:31.517798    4803 [ld:open-rocks1] PartitionedRocksDBStore.cpp:891] open() Partition s1:1000000 is under-replicated: Start:2021-09-17 02:10:15.332, Min:2021-09-17 02:10:00.332, Max: 2021-09-17 02:10:30.332
I0917 02:14:31.519237    4803 [ld:open-rocks1] PartitionedRocksDBStore.cpp:897] open() Shard[1] dirty ranges: [A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
I0917 02:14:31.529472    4803 [ld:open-rocks1] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.001s. Read 9 records, 577 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:31.536865    4802 [ld:open-rocks0] PartitionedRocksDBStore.cpp:891] open() Partition s0:1000000 is under-replicated: Start:2021-09-17 02:10:15.337, Min:2021-09-17 02:10:00.337, Max: 2021-09-17 02:10:30.337
I0917 02:14:31.542123    4802 [ld:open-rocks0] PartitionedRocksDBStore.cpp:897] open() Shard[0] dirty ranges: [A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
I0917 02:14:31.555879    4802 [ld:open-rocks0] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.000s. Read 5 records, 341 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:31.631952    4782 [rocks-high-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard0/000076.log.trash as trash -- OK
I0917 02:14:31.640105    4802 [ld:open-rocks0] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N4:1/db/shard0 in 552 ms
I0917 02:14:31.648806    4780 [rocks-high-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N4:1/db/shard1/000084.log.trash as trash -- OK
I0917 02:14:31.648934    4804 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N4:1/db/shard0/000076.log.trash
I0917 02:14:31.661149    4803 [ld:open-rocks1] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N4:1/db/shard1 in 577 ms
I0917 02:14:31.662025    4805 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N4:1/db/shard1/000084.log.trash
I0917 02:14:31.687512    4399 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:691] printDiskShardMapping() Disk -> Shard mapping: /data/store/N4:1/db/shard0 -> [0,1]
I0917 02:14:31.693794    4399 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:285] init() Initialized sharded RocksDB instance at /data/store/N4:1/db with 2 shards
E0917 02:14:31.697518    5301 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState1"!
E0917 02:14:31.697672    5300 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState0"!
I0917 02:14:31.705196    4399 [logdeviced-main] Server.cpp:1173] initLogStorageStateMap() Populating log storage state map successful.
E0917 02:14:31.716247    4399 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:31.722890    4399 [logdeviced-main] RecordCacheMonitorThread.cpp:27] RecordCacheMonitorThread() Record cache monitor thread started.
I0917 02:14:31.723750    5325 [ld:cache-evict] RecordCacheMonitorThread.cpp:44] threadMain() Record cache eviction thread started. Size limit is set to 4294967296 bytes.
I0917 02:14:31.726895    4399 [logdeviced-main] ClusterState.cpp:356] resizeClusterState() Cluster state size updated from 0 to 5
I0917 02:14:31.732405    5234 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
E0917 02:14:31.741025    4399 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.750966    4399 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.765112    4399 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.773092    4399 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.777126    4399 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:31.781536    4399 [logdeviced-main] Processor.cpp:247] init() Initialized 5 workers of type GENERAL
E0917 02:14:31.785477    4399 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:31.788843    4399 [logdeviced-main] Processor.cpp:247] init() Initialized 1 workers of type FAILURE_DETECTOR
E0917 02:14:31.791353    4399 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.796182    4399 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.800651    4399 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.810240    4399 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:31.812799    4399 [logdeviced-main] Processor.cpp:247] init() Initialized 4 workers of type BACKGROUND
I0917 02:14:31.814882    4399 [logdeviced-main] FailureDetector.cpp:139] FailureDetector() Failure Detector created with instance id: 1631844871814
I0917 02:14:31.815756    4399 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N0 changed from UNKNOWN to DEAD
I0917 02:14:31.816920    4399 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from HEALTHY to UNHEALTHY
I0917 02:14:31.817728    4399 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N1 changed from UNKNOWN to DEAD
I0917 02:14:31.818834    4399 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from HEALTHY to UNHEALTHY
I0917 02:14:31.820244    4399 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N2 changed from UNKNOWN to DEAD
I0917 02:14:31.821646    4399 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from HEALTHY to UNHEALTHY
I0917 02:14:31.822660    4399 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N3 changed from UNKNOWN to DEAD
I0917 02:14:31.823509    4399 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from HEALTHY to UNHEALTHY
I0917 02:14:31.824196    4399 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N4 changed from UNKNOWN to DEAD
I0917 02:14:31.826532    4399 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from HEALTHY to UNHEALTHY
W0917 02:14:31.837500    5330 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 21 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967296), p :HI_PRI
W0917 02:14:31.846461    5345 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 29 msec: NODE_STATE_UPDATED (id: 4294967302), p :LO_PRI
W0917 02:14:31.873531    5345 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 56 msec: NODE_STATE_UPDATED (id: 4294967308), p :LO_PRI
W0917 02:14:31.875048    5345 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 56 msec: NODE_STATE_UPDATED (id: 4294967312), p :LO_PRI
W0917 02:14:31.876842    5345 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 58 msec: NODE_STATE_UPDATED (id: 4294967318), p :LO_PRI
W0917 02:14:31.879553    5345 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 58 msec: NODE_STATE_UPDATED (id: 4294967322), p :LO_PRI
W0917 02:14:31.881994    5345 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 60 msec: NODE_STATE_UPDATED (id: 4294967328), p :LO_PRI
I0917 02:14:31.883294    4399 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
W0917 02:14:31.884469    5345 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 61 msec: NODE_STATE_UPDATED (id: 4294967332), p :LO_PRI
I0917 02:14:31.885977    5355 [ld:srv:WB0] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:14:31.889515    5355 [ld:srv:WB0] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 4ms
W0917 02:14:31.887197    5345 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 63 msec: NODE_STATE_UPDATED (id: 4294967338), p :LO_PRI
W0917 02:14:31.893450    5345 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 68 msec: NODE_STATE_UPDATED (id: 4294967342), p :LO_PRI
W0917 02:14:31.896446    5355 [ld:srv:WB0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.012s, source: [Request: NODES_CONFIGURATION_MANAGER]
I0917 02:14:31.898896    5355 [ld:srv:WB0] NodesConfigurationManager.cpp:507] onProcessingFinished() Updated local nodes config to version 5...
I0917 02:14:31.900033    5307 [ld:s0:default:0] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:31.901246    5307 [ld:s0:default:0] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 0, totaling 0 bytes.
I0917 02:14:31.900059    5316 [ld:s1:default:0] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:31.902888    5316 [ld:s1:default:0] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 1, totaling 0 bytes.
I0917 02:14:31.904245    4399 [logdeviced-main] Server.cpp:1319] initSequencers() Initializing FileEpochStore
I0917 02:14:31.905001    4399 [logdeviced-main] Server.cpp:1398] initSequencerPlacement() using SequencerOptions::LAZY
I0917 02:14:31.906348    4399 [logdeviced-main] Server.cpp:1430] initRebuildingCoordinator() Initializing EventLog RSM and RebuildingCoordinator
I0917 02:14:31.908207    4399 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387903)
I0917 02:14:31.909007    4399 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387903, is_server:1)
I0917 02:14:31.909863    4399 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:31.910892    4399 [logdeviced-main] Server.cpp:1467] initRebuildingCoordinator() Starting RebuildingSupervisor
I0917 02:14:31.911705    4399 [logdeviced-main] Server.cpp:1480] initRebuildingCoordinator() Starting RebuildingCoordinator
I0917 02:14:31.912083    5352 [ld:srv:WG4] RebuildingSupervisor.cpp:62] init() Starting Rebuilding Supervisor
I0917 02:14:31.913272    5352 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N3 to execute in 1200s
I0917 02:14:31.914416    5352 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N2 to execute in 1200s
I0917 02:14:31.915329    5352 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N1 to execute in 1200s
I0917 02:14:31.914609    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:309] subscribeToEventLogIfNeeded() RebuildingCoordinator did not start yet because LogsConfig is not fully loaded yet
I0917 02:14:31.917118    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [eventlog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:31.914650    4399 [logdeviced-main] LogStoreMonitor.cpp:190] start() Logstore monitoring thread started.
I0917 02:14:31.916602    5352 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N0 to execute in 1200s
I0917 02:14:31.917936    5363 [ld:srv:WB3] EventLogStateMachine.cpp:146] gotInitialState() Got base rebuilding set: {}
I0917 02:14:31.919111    4399 [logdeviced-main] UnreleasedRecordDetector.cpp:106] start() Unreleased record detector thread started.
W0917 02:14:31.919953    5352 [ld:srv:WG4] RebuildingSupervisor.cpp:705] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:14:31.922405    5352 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:14:31.920802    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [eventlog] Retrieving tail lsn of delta log...
I0917 02:14:31.921576    4399 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387901)
W0917 02:14:31.923281    5352 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.011s, source: [Request: REBUILDING_SUPERVISOR]
I0917 02:14:31.924576    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [maintenancelog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:31.926986    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [maintenancelog] Retrieving tail lsn of delta log...
E0917 02:14:31.924620    5351 [ld:srv:WG3] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387903. All sequencer nodes are unavailable.
I0917 02:14:31.925219    4399 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387901, is_server:1)
E0917 02:14:31.928432    5352 [ld:srv:WG4] SequencerRouter.cpp:56] operator()() Error during sequencer lookup for log 4611686018427387899 (NOSEQUENCER), reporting NOSEQUENCER.
W0917 02:14:31.931000    5352 [ld:srv:WG4] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387899, rqid:25769803779, ctx:rsm, err(NOSEQUENCER)
E0917 02:14:31.929128    5351 [ld:srv:WG3] SequencerRouter.cpp:105] onFailure() Error during sequencer routing for log 4611686018427387903 (NOSEQUENCER), request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7f78cce99028].
I0917 02:14:31.930212    4399 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
W0917 02:14:31.932407    5352 [ld:srv:WG4] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387899 (rqid:25769803779, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
W0917 02:14:31.933261    5351 [ld:srv:WG3] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387903, rqid:25769803777, ctx:rsm, err(NOSEQUENCER)
W0917 02:14:31.935738    5351 [ld:srv:WG3] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387903 (rqid:25769803777, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
I0917 02:14:31.934386    5356 [ld:srv:WB1] LogsConfigManager.cpp:38] execute() Starting LogsConfigManager on Worker 1 in pool: BACKGROUND
E0917 02:14:31.934995    5363 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:25769803779) for log:4611686018427387899, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:14:31.937942    5356 [ld:srv:WB1] LogsConfigManager.cpp:165] start() Starting LogsConfig Manager RSM
I0917 02:14:31.941833    5356 [ld:srv:WB1] LogsConfigManager.cpp:206] start() Starting LogsConfig Replicated State Machine
E0917 02:14:31.940750    5363 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:25769803777) for log:4611686018427387903, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:14:31.942739    5356 [ld:srv:WB1] ReplicatedStateMachine-inl.h:38] startFetchingSnapshot() [logsconfig] Using RSMSnapshotStore...
I0917 02:14:31.944514    5356 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1294] initSnapshotFetchTimer() [logsconfig] Creating timer to fetch snapshots ...
I0917 02:14:31.946730    4399 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server LogDevice Admin API Service will listen on port 48411
I0917 02:14:31.947673    4399 [logdeviced-main] Server.cpp:1540] createAndAttachMaintenanceManager() Not initializing MaintenanceManager since it is disabled in settings
I0917 02:14:31.948405    4399 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: s2s-api
I0917 02:14:31.950374    4399 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server s2s-api will listen on port 48415
I0917 02:14:31.951191    4399 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: c2s-api
I0917 02:14:31.952047    4399 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server c2s-api will listen on port 48416
I0917 02:14:31.952865    4399 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:31.954506    4708 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:31.956143    4399 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:31.957765    4709 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:31.959752    5354 [ld:srv:WF0] FailureDetector.cpp:228] startGetClusterState() Sending GET_CLUSTER_STATE to build initial FD cluster view
I0917 02:14:31.959752    4399 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server s2s-api
I0917 02:14:31.964176    5354 [ld:srv:WF0] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket N3:1(127.0.0.1:48421) hit error AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused)
I0917 02:14:31.969225    5354 [ld:srv:WF0] FailureDetector.cpp:267] operator()() Cluster state received with 5 dead nodes (N0,N1,N2,N3,N4) and 0 boycotted nodes ()
I0917 02:14:31.971428    5354 [ld:srv:WF0] FailureDetector.cpp:288] buildInitialState() Wait over (cluster state received)
I0917 02:14:31.972476    5354 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from DEAD to STARTING
I0917 02:14:31.974338    5352 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N0
I0917 02:14:31.975911    5354 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N0 transitioned to ALIVE
I0917 02:14:31.976825    5354 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N1 changed from DEAD to STARTING
I0917 02:14:31.976953    4399 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server c2s-api
I0917 02:14:31.978316    5352 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N1
I0917 02:14:31.979056    5354 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N1 transitioned to ALIVE
I0917 02:14:31.980664    5354 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from DEAD to STARTING
I0917 02:14:31.983204    5354 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N2 transitioned to ALIVE
I0917 02:14:31.983161    5352 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N2
W0917 02:14:31.984911    5352 [ld:srv:WG4] RebuildingSupervisor.cpp:734] adjustRebuildingThrottle() Exiting throttling mode: #draining=0, #rebuilding=0, #triggers=1, #adjusted cluster size=5, threshold=35%, actual=20%
I0917 02:14:31.984147    5354 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N3 transitioned to DEAD
I0917 02:14:31.986402    5352 [ld:srv:WG4] RebuildingSupervisor.cpp:751] adjustRebuildingThrottle() Not triggering new rebuildings until 2021-09-17 02:34:31.986: It's too soon after exiting throttling mode
I0917 02:14:31.987588    5354 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from UNHEALTHY to UNDEFINED
I0917 02:14:31.989497    5354 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N0 transitioned to UNDEFINED (status)
I0917 02:14:31.990774    5354 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from UNHEALTHY to HEALTHY
I0917 02:14:31.991752    5354 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N1 transitioned to HEALTHY (status)
I0917 02:14:31.992953    5354 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from UNHEALTHY to HEALTHY
I0917 02:14:31.993758    5354 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N2 transitioned to HEALTHY (status)
I0917 02:14:31.994965    5354 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N3 transitioned to UNHEALTHY (status)
I0917 02:14:31.995886    5354 [ld:srv:WF0] FailureDetector.cpp:344] buildInitialState() Initializing DomainIsolationChecker
I0917 02:14:31.996975    5354 [ld:srv:WF0] FailureDetector.cpp:915] startSuspectTimer() Starting suspect state timer
I0917 02:14:31.997854    5354 [ld:srv:WF0] FailureDetector.cpp:1285] updateNodeState() N4 transitioned from DEAD to ALIVE, FD State:(gossip: 0, instance-id: 0, failover: 0, starting: 1)
I0917 02:14:31.998661    5354 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from DEAD to STARTING
I0917 02:14:32.000095    5354 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting suspect-state-finished message.
I0917 02:14:32.000465    4399 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server LogDevice Admin API Service
I0917 02:14:32.000890    5354 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844871814 to node WF0:N3:1 (127.0.0.1:48421)
I0917 02:14:32.005742    5354 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844871814 to node WF0:N2:1 (UNKNOWN)
I0917 02:14:32.010729    5354 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting bringup message.
I0917 02:14:32.011652    5354 [ld:srv:WF0] FailureDetector.cpp:937] startGossiping() Start Gossiping.
I0917 02:14:32.015098    5354 [ld:srv:WF0] FailureDetector.cpp:925] operator()() Suspect timeout expired
I0917 02:14:32.024803    4399 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:32.026739    4711 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:32.028269    4399 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:32.029427    4708 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:32.032420    4399 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:32.033726    4708 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:32.035271    4399 [logdeviced-main] main.cpp:464] main() Listeners initialized
I0917 02:14:32.094104    5354 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N3:1 with instance id:1631844871925, sent_time:1631844872081ms
I0917 02:14:32.095142    5354 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N3 changed from DEAD to STARTING
I0917 02:14:32.096667    5354 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N3 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844871925, failover: 0, starting: 1)
I0917 02:14:32.096745    5352 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N3
I0917 02:14:32.097509    5354 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N3:1 with instance id:1631844871925, sent_time:1631844872084ms
I0917 02:14:32.099736    5354 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N3
I0917 02:14:32.116986    5354 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from UNHEALTHY to UNDEFINED
I0917 02:14:32.423983    5354 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from UNDEFINED to HEALTHY
I0917 02:14:32.708407    5352 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163707 shard 1 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 2.
I0917 02:14:32.709490    5352 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163707 shard 1 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 3.
I0917 02:14:32.710376    5352 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163707 shard 1 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 4.
I0917 02:14:32.715590    5352 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163707 shard 1 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 5.
I0917 02:14:32.720350    5352 [ld:srv:WG4] PurgeUncleanEpochs.cpp:401] onGetEpochRecoveryMetadataComplete() Nothing to purge. Epoch is empty locally and EpochRecoveryMetadata consensus is also EMPTY for log: 13835058055282163707,epoch:5
I0917 02:14:32.728314    5330 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG0:C17 (127.0.0.1:59928)
I0917 02:14:32.737171    5319 [ld:s1:default:1] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 4611686018427387903 epoch 4: cache not found but cannot declare no data. head epoch : 7, last_nonauthoritative_epoch: 4.
I0917 02:14:32.770989    5253 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:14:32.773786    5352 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 4611686018427387903 shard 1 epochs [4,6] purge_to 6 got at least one reply with E::EMPTY, for the epoch 5.
I0917 02:14:32.774119    5253 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:14:32.775241    5352 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 4611686018427387903 shard 1 epochs [4,6] purge_to 6 got at least one reply with E::EMPTY, for the epoch 6.
I0917 02:14:32.779995    5352 [ld:srv:WG4] PurgeSingleEpoch.cpp:154] purgeRecords() Going to delete records in [1, 1] in epoch 4, log 4611686018427387903, shard 1, purge to 6, epoch recovery metadata status: OK, metadata: EpochRecoveryMetadata([S:7 L:0 H:1 F:0 T:[L:0 N:LSN_INVALID T:0 AOM:{246:0} F:0](Invalid) Z:{246:0} O:{246:0}])
I0917 02:14:32.789934    5352 [ld:srv:WG4] PurgeUncleanEpochs.cpp:524] onPurgeSingleEpochDone() Successfully purged epoch 4 for log 4611686018427387903, 0 epochs remaining.
I0917 02:14:32.835471    5352 [ld:srv:WG4] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [1, 5] for log 13835058055282163707.
I0917 02:14:32.835584    5354 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() skipped at least 2 log entries
I0917 02:14:32.837344    5354 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from UNDEFINED to HEALTHY
I0917 02:14:32.837837    5351 [ld:srv:WG3] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163708 shard 0 epochs [2,6] purge_to 6 got at least one reply with E::EMPTY, for the epoch 2.
I0917 02:14:32.842179    5351 [ld:srv:WG3] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163708 shard 0 epochs [2,6] purge_to 6 got at least one reply with E::EMPTY, for the epoch 3.
I0917 02:14:32.842968    5351 [ld:srv:WG3] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163708 shard 0 epochs [2,6] purge_to 6 got at least one reply with E::EMPTY, for the epoch 4.
I0917 02:14:32.844040    5351 [ld:srv:WG3] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163708 shard 0 epochs [2,6] purge_to 6 got at least one reply with E::EMPTY, for the epoch 5.
I0917 02:14:32.846065    5351 [ld:srv:WG3] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163708 shard 0 epochs [2,6] purge_to 6 got at least one reply with E::EMPTY, for the epoch 6.
I0917 02:14:32.892383    5345 [ld:srv:WG1] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 2, purge to: 2.
I0917 02:14:32.946665    5356 [ld:srv:WB1] ReplicatedStateMachine-inl.h:130] getSnapshot() [logsconfig] Fetching snapshot with ver:e0n1, (waiting_for_snapshot_:LSN_INVALID, version_:e0n1). sync_state_:0
I0917 02:14:32.947028    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [maintenancelog] Tail lsn of delta log is e8n0
I0917 02:14:32.952865    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [eventlog] Tail lsn of delta log is e9n0
I0917 02:14:32.991556    5352 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163707 has already been cleaned. No purge needed. last clean epoch: 6, purge to: 6.
I0917 02:14:33.005152    5352 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387903 has already been cleaned. No purge needed. last clean epoch: 7, purge to: 7.
I0917 02:14:33.068002    5351 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163708 has already been cleaned. No purge needed. last clean epoch: 7, purge to: 7.
I0917 02:14:33.081544    5345 [ld:srv:WG1] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387900 has already been cleaned. No purge needed. last clean epoch: 2, purge to: 2.
I0917 02:14:33.094837    5345 [ld:srv:WG1] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 3, purge to: 3.
I0917 02:14:33.214735    5363 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 2 is not available. Highest epoch known is 1.
I0917 02:14:33.231827    5363 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 3 is not available. Highest epoch known is 1.
I0917 02:14:33.271715    5352 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:172] checkAllFullyAuthoritativeNodesResponded() GetEpochRecoveryMetadataRequest for log 13835058055282163711 shard 1 epochs [2,3] purge_to 3 received reply from all fully authoritative nodes in thenodeset but still unable to make a decision. It is likely that some epoch has been recovered by non-authoritative recovery.
I0917 02:14:33.272498    5352 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:199] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163711 shard 1 epochs [2,3] purge_to 3 - All nodes responded but there is no valid response for epoch:2
I0917 02:14:33.274176    5352 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:199] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163711 shard 1 epochs [2,3] purge_to 3 - All nodes responded but there is no valid response for epoch:3
I0917 02:14:33.277113    5352 [ld:srv:WG4] PurgeUncleanEpochs.cpp:387] onGetEpochRecoveryMetadataComplete() GetEpochRecoveryMetadataRequest for log 13835058055282163711 did not get a valid response for epoch 3. Skipping purging for this epoch
I0917 02:14:33.278460    5352 [ld:srv:WG4] PurgeUncleanEpochs.cpp:387] onGetEpochRecoveryMetadataComplete() GetEpochRecoveryMetadataRequest for log 13835058055282163711 did not get a valid response for epoch 2. Skipping purging for this epoch
I0917 02:14:33.290922    5363 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 8 is not available. Highest epoch known is 1.
I0917 02:14:33.320418    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [eventlog] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:14:33.355692    5363 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (1)
I0917 02:14:33.366973    5345 [ld:srv:WG1] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 4, purge to: 4.
W0917 02:14:33.372042    5363 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() skipped at least 3 log entries
W0917 02:14:33.372953    5363 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.081s, source: [Message sent/received: GAP]
I0917 02:14:33.383067    5345 [ld:srv:WG1] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387900 has already been cleaned. No purge needed. last clean epoch: 3, purge to: 3.
I0917 02:14:33.492347    5345 [ld:srv:WG1] PurgeUncleanEpochs.cpp:592] complete() skipped at least 10 log entries
I0917 02:14:33.494044    5345 [ld:srv:WG1] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [3, 3] for log 4611686018427387900.
I0917 02:14:33.598484    5352 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163711 has already been cleaned. No purge needed. last clean epoch: 4, purge to: 4.
I0917 02:14:33.627512    5345 [ld:srv:WG1] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 5, purge to: 5.
I0917 02:14:33.769826    5330 [ld:srv:WG0] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163706 shard 0 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 2.
I0917 02:14:33.773331    5330 [ld:srv:WG0] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163706 shard 0 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 3.
I0917 02:14:33.775612    5330 [ld:srv:WG0] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163706 shard 0 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 4.
I0917 02:14:33.777042    5330 [ld:srv:WG0] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163706 shard 0 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 5.
I0917 02:14:33.779869    5330 [ld:srv:WG0] PurgeUncleanEpochs.cpp:401] onGetEpochRecoveryMetadataComplete() skipped at least 10 log entries
I0917 02:14:33.780991    5330 [ld:srv:WG0] PurgeUncleanEpochs.cpp:401] onGetEpochRecoveryMetadataComplete() Nothing to purge. Epoch is empty locally and EpochRecoveryMetadata consensus is also EMPTY for log: 13835058055282163706,epoch:5
I0917 02:14:33.845113    5330 [ld:srv:WG0] PurgeUncleanEpochs.cpp:592] complete() skipped at least 3 log entries
I0917 02:14:33.846230    5330 [ld:srv:WG0] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [1, 5] for log 13835058055282163706.
I0917 02:14:34.110351    5363 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387899 epoch 2 is not available. Highest epoch known is 1.
I0917 02:14:34.156393    5363 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387899 epoch 8 is not available. Highest epoch known is 1.
I0917 02:14:34.163094    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [maintenancelog] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:14:34.166060    5363 [ld:srv:WB3] ClusterMaintenanceStateMachine.cpp:112] onUpdate() [maintenancelog] Published new ClusterMaintenanceState version (1)
W0917 02:14:34.167219    5363 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.011s, source: [Message sent/received: GAP]
I0917 02:14:34.561882    5330 [ld:srv:WG0] PurgeUncleanEpochs.cpp:592] complete() skipped at least 10 log entries
I0917 02:14:34.564214    5330 [ld:srv:WG0] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [6, 6] for log 13835058055282163706.
I0917 02:14:34.926349    5345 [ld:srv:WG1] PurgeUncleanEpochs.cpp:592] complete() skipped at least 3 log entries
I0917 02:14:34.927086    5345 [ld:srv:WG1] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [6, 6] for log 4611686018427387898.
W0917 02:14:35.700997    5330 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:2 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.709014    5330 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:31 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.715209    5330 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:55 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.718520    5330 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:56 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.720929    5330 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:60 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.724795    5352 [ld:srv:WG4] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() skipped at least 10 log entries
W0917 02:14:35.728806    5352 [ld:srv:WG4] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:88 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.730299    5352 [ld:srv:WG4] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:72057594037927936 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.734514    5330 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:16 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.739899    5330 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:24 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.745002    5330 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:26 (status=NOTFOUND), replying with E::NOSEQUENCER.
I0917 02:14:35.782487    5363 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.754, e9n1: SHARD_NEEDS_REBUILD(nodeIdx=2, shardIdx=1, source=N2, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:35.784736    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n1 ts=2021-09-17 02:14:35.754
I0917 02:14:35.786395    5363 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705665)
I0917 02:14:35.806935    5354 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from STARTING to FULLY_STARTED
I0917 02:14:35.823985    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n1 ts=2021-09-17 02:14:35.812 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:35.833827    5363 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.823, e9n2: SHARD_NEEDS_REBUILD(nodeIdx=2, shardIdx=0, source=N2, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:35.836166    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n2 ts=2021-09-17 02:14:35.823
I0917 02:14:35.838174    5363 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705666)
I0917 02:14:35.855699    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n2 ts=2021-09-17 02:14:35.840 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:35.881242    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n3 ts=2021-09-17 02:14:35.869 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:35.915707    5363 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.881, e9n3: SHARD_NEEDS_REBUILD(nodeIdx=1, shardIdx=1, source=N1, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}]
I0917 02:14:35.919729    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n3 ts=2021-09-17 02:14:35.881
I0917 02:14:35.921936    5363 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705667)
I0917 02:14:35.936246    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n4 ts=2021-09-17 02:14:35.881 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:35.943135    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n5 ts=2021-09-17 02:14:35.892 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:35.959084    5363 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.929, e9n4: SHARD_NEEDS_REBUILD(nodeIdx=1, shardIdx=0, source=N1, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}]
I0917 02:14:35.965850    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n4 ts=2021-09-17 02:14:35.929
I0917 02:14:35.965908    5356 [ld:srv:WB1] LogBasedRSMSnapshotStore.cpp:298] onGotLastReleased() Returning EMPTY for log:4611686018427387900, last_released_real_lsn:LSN_INVALID
I0917 02:14:35.971144    5356 [ld:srv:WB1] ReplicatedStateMachine-inl.h:83] operator()() [logsconfig] getSnapshot()'s callback. st:EMPTY, snapshot blob size:0, attrs:(base_ver:LSN_INVALID, ts:0)
I0917 02:14:35.967467    5363 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705668)
I0917 02:14:35.979306    5363 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.933, e9n5: SHARD_NEEDS_REBUILD(nodeIdx=0, shardIdx=1, source=N0, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:09:59.858,2021-09-17 02:10:29.858]}}]
W0917 02:14:35.978459    5356 [ld:srv:WB1] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.013s, source: [Request: WORKER_CALLBACK_HELPER]
I0917 02:14:35.983796    5356 [ld:srv:WB1] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [logsconfig] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:35.981712    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n5 ts=2021-09-17 02:14:35.933
I0917 02:14:35.987266    5363 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705669)
I0917 02:14:35.984807    5356 [ld:srv:WB1] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [logsconfig] Retrieving tail lsn of delta log...
W0917 02:14:35.989993    5363 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.011s, source: [Message sent/received: RECORD]
I0917 02:14:35.999151    5356 [ld:srv:WB1] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [logsconfig] Tail lsn of delta log is e6n0
I0917 02:14:36.003412    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n6 ts=2021-09-17 02:14:35.928 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.008971    5363 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.965, e9n6: SHARD_NEEDS_REBUILD(nodeIdx=0, shardIdx=0, source=N0, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:09:59.859,2021-09-17 02:10:29.859]}}]
I0917 02:14:36.011258    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n6 ts=2021-09-17 02:14:35.965
I0917 02:14:36.016930    5363 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705670)
I0917 02:14:36.013780    5352 [ld:srv:WG4] PurgeUncleanEpochs.cpp:592] complete() skipped at least 6 log entries
I0917 02:14:36.014973    5354 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N1 changed from STARTING to FULLY_STARTED
I0917 02:14:36.019328    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n7 ts=2021-09-17 02:14:35.952 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.020561    5352 [ld:srv:WG4] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [1, 1] for log 13835058055282163710.
I0917 02:14:36.030841    5356 [ld:srv:WB1] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387901 epoch 2 is not available. Highest epoch known is 1.
W0917 02:14:36.033692    5356 [ld:srv:WB1] ClientReadStream.cpp:2476] updateCurrentMetaData() Existing epoch metadata has changed for log 4611686018427387901 on epoch 1, check metadata log!
I0917 02:14:36.041554    5356 [ld:srv:WB1] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [logsconfig] Applied delta record with lsn=e2n1 ts=2021-09-17 02:10:19.558
I0917 02:14:36.042833    5356 [ld:srv:WB1] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [logsconfig] Applied delta record with lsn=e2n2 ts=2021-09-17 02:11:11.944
I0917 02:14:36.051189    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n8 ts=2021-09-17 02:14:36.040 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.056054    5356 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [logsconfig] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:14:36.057684    5356 [ld:srv:WB1] LogsConfigManager.cpp:193] operator()() Received update from LogsConfigStateMachine, version 8589934594
I0917 02:14:36.058508    5356 [ld:srv:WB1] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:14:36.059961    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1740] publishDirtyShards() Publishing dirty shards.
I0917 02:14:36.059988    5356 [ld:srv:WB1] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 1ms
I0917 02:14:36.062491    5356 [ld:srv:WB1] LogsConfigManager.cpp:331] updateLogsConfig() Published new LogsConfig (fully loaded? yes) version (8589934594) from LogsConfigManager
I0917 02:14:36.061499    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 1, reason=Node came back with data intact
I0917 02:14:36.064891    5363 [ld:srv:WB3] EventLogWriter.cpp:86] writeEvent() (Queue size: 0) Enqueueing event SHARD_NEEDS_REBUILD(nodeIdx=4, shardIdx=1, source=N4, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
I0917 02:14:36.068038    5363 [ld:srv:WB3] EventLogWriter.cpp:50] writeNextEventInQueue() (Queue size: 1) Writing event SHARD_NEEDS_REBUILD(nodeIdx=4, shardIdx=1, source=N4, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
I0917 02:14:36.070047    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 0, reason=Node came back with data intact
I0917 02:14:36.072093    5363 [ld:srv:WB3] EventLogWriter.cpp:86] writeEvent() (Queue size: 1) Enqueueing event SHARD_NEEDS_REBUILD(nodeIdx=4, shardIdx=0, source=N4, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
I0917 02:14:36.073724    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 0 after 1ms
I0917 02:14:36.074746    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 1 after 1ms
I0917 02:14:36.077439    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:2064] subscribeToEventLog() Subscribed to EventLog
I0917 02:14:36.079029    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 0 and rebuilding set N0:S0[A:{{[2021-09-17 02:09:59.859,2021-09-17 02:10:29.859]}}],N1:S0[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}],N2:S0[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:36.081337    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 1 and rebuilding set N0:S1[A:{{[2021-09-17 02:09:59.858,2021-09-17 02:10:29.858]}}],N1:S1[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}],N2:S1[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:36.083457    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n9 ts=2021-09-17 02:14:36.059 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.088212    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n10 ts=2021-09-17 02:14:36.063 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.095383    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n11 ts=2021-09-17 02:14:36.068 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.110106    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n12 ts=2021-09-17 02:14:36.080 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.111284    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [eventlog] Successfully wrote delta with lsn e9n7
I0917 02:14:36.112258    5363 [ld:srv:WB3] EventLogWriter.cpp:67] operator()() Wrote record with lsn e9n7
I0917 02:14:36.113541    5363 [ld:srv:WB3] EventLogWriter.cpp:50] writeNextEventInQueue() (Queue size: 1) Writing event SHARD_NEEDS_REBUILD(nodeIdx=4, shardIdx=0, source=N4, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
I0917 02:14:36.115287    5363 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:36.083, e9n7: SHARD_NEEDS_REBUILD(nodeIdx=4, shardIdx=1, source=N4, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
I0917 02:14:36.116803    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n7 ts=2021-09-17 02:14:36.083
I0917 02:14:36.118039    5363 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705671)
I0917 02:14:36.120206    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 1 after 1ms
I0917 02:14:36.123438    5354 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from STARTING to FULLY_STARTED
I0917 02:14:36.125038    5354 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from STARTING to FULLY_STARTED
I0917 02:14:36.128348    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 1, reason=Shard came back with data intact
I0917 02:14:36.132120    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 1 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.133261    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
I0917 02:14:36.134982    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
I0917 02:14:36.136312    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1883] abortForMyShard() Dirty ranges for my shard 1 successfully published
I0917 02:14:36.137132    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:472] noteRangesPublished() Noting dirty ranges published for shard 1
I0917 02:14:36.142256    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 1 and rebuilding set N0:S1[A:{{[2021-09-17 02:09:59.858,2021-09-17 02:10:29.858]}}],N1:S1[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}],N2:S1[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}],N4:S1[A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
I0917 02:14:36.150963    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n13
I0917 02:14:36.157798    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n13 ts=2021-09-17 02:14:36.084 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.161027    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n14 ts=2021-09-17 02:14:36.092 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.164764    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n15 ts=2021-09-17 02:14:36.094 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.166065    5363 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n13
I0917 02:14:36.173250    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n16 ts=2021-09-17 02:14:36.144 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.174993    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [eventlog] Successfully wrote delta with lsn e9n8
I0917 02:14:36.179862    5363 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:36.125, e9n8: SHARD_NEEDS_REBUILD(nodeIdx=4, shardIdx=0, source=N4, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
I0917 02:14:36.182490    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n8 ts=2021-09-17 02:14:36.125
I0917 02:14:36.184532    5363 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705672)
I0917 02:14:36.187853    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 0 after 1ms
I0917 02:14:36.190293    5363 [ld:srv:WB3] EventLogWriter.cpp:67] operator()() Wrote record with lsn e9n8
I0917 02:14:36.199202    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 0, reason=Shard came back with data intact
I0917 02:14:36.202679    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 0 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.206520    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
I0917 02:14:36.213756    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
I0917 02:14:36.215351    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1883] abortForMyShard() Dirty ranges for my shard 0 successfully published
I0917 02:14:36.216391    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:472] noteRangesPublished() Noting dirty ranges published for shard 0
I0917 02:14:36.217292    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 0 and rebuilding set N0:S0[A:{{[2021-09-17 02:09:59.859,2021-09-17 02:10:29.859]}}],N1:S0[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}],N2:S0[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}],N4:S0[A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
I0917 02:14:36.220889    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n18
I0917 02:14:36.223901    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n17 ts=2021-09-17 02:14:36.171 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.226449    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n18 ts=2021-09-17 02:14:36.182 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.228937    5363 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n18
I0917 02:14:36.239310    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n19 ts=2021-09-17 02:14:36.225 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.246184    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n20 ts=2021-09-17 02:14:36.230 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.267993    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n21
I0917 02:14:36.271568    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n21 ts=2021-09-17 02:14:36.237 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.272470    5363 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n21
I0917 02:14:36.283900    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n22 ts=2021-09-17 02:14:36.271 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.287490    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n23
I0917 02:14:36.289481    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n23 ts=2021-09-17 02:14:36.276 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.290646    5363 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n23
I0917 02:14:36.313442    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n24 ts=2021-09-17 02:14:36.285 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.315082    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n25 ts=2021-09-17 02:14:36.285 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.316243    5363 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:36.286, e9n9: SHARD_NEEDS_REBUILD(nodeIdx=3, shardIdx=1, source=N3, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:09:59.669,2021-09-17 02:10:29.669]}}]
I0917 02:14:36.316966    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n9 ts=2021-09-17 02:14:36.286
I0917 02:14:36.319012    5363 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705673)
I0917 02:14:36.323353    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 1 after 1ms
I0917 02:14:36.326387    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 1, reason=Shard came back with data intact
I0917 02:14:36.329413    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 1 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.332214    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
I0917 02:14:36.335181    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
I0917 02:14:36.337237    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 1. Converting abort into no-op.
I0917 02:14:36.338893    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 1 and rebuilding set N0:S1[A:{{[2021-09-17 02:09:59.858,2021-09-17 02:10:29.858]}}],N1:S1[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}],N2:S1[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}],N3:S1[A:{{[2021-09-17 02:09:59.669,2021-09-17 02:10:29.669]}}],N4:S1[A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
I0917 02:14:36.340914    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n26 ts=2021-09-17 02:14:36.291 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.342664    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n27 ts=2021-09-17 02:14:36.304 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.348825    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n28
I0917 02:14:36.350281    5363 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n28
I0917 02:14:36.352125    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n28 ts=2021-09-17 02:14:36.342 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.364937    5363 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:36.350, e9n10: SHARD_NEEDS_REBUILD(nodeIdx=3, shardIdx=0, source=N3, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:09:59.666,2021-09-17 02:10:29.666]}}]
I0917 02:14:36.367917    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n10 ts=2021-09-17 02:14:36.350
I0917 02:14:36.369114    5363 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705674)
I0917 02:14:36.370519    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 0 after 1ms
I0917 02:14:36.374430    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n29 ts=2021-09-17 02:14:36.353 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.377740    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n30 ts=2021-09-17 02:14:36.358 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.379477    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 0, reason=Shard came back with data intact
I0917 02:14:36.385263    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 0 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.388870    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
I0917 02:14:36.396878    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
I0917 02:14:36.404072    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 0. Converting abort into no-op.
I0917 02:14:36.406339    5363 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 0 and rebuilding set N0:S0[A:{{[2021-09-17 02:09:59.859,2021-09-17 02:10:29.859]}}],N1:S0[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}],N2:S0[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}],N3:S0[A:{{[2021-09-17 02:09:59.666,2021-09-17 02:10:29.666]}}],N4:S0[A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
W0917 02:14:36.407482    5363 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() skipped at least 10 log entries
W0917 02:14:36.410665    5363 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.028s, source: [Message sent/received: RECORD]
I0917 02:14:36.412407    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n31 ts=2021-09-17 02:14:36.362 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.418998    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n32 ts=2021-09-17 02:14:36.375 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.434403    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n33 ts=2021-09-17 02:14:36.412 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.435965    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n34 ts=2021-09-17 02:14:36.412 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.438161    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n35 ts=2021-09-17 02:14:36.417 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.439376    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n35
I0917 02:14:36.440747    5363 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n35
I0917 02:14:36.452760    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n36 ts=2021-09-17 02:14:36.429 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.456226    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n37 ts=2021-09-17 02:14:36.433 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.466960    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n38 ts=2021-09-17 02:14:36.453 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.475966    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n39 ts=2021-09-17 02:14:36.463 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.505806    5363 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n40 ts=2021-09-17 02:14:36.496 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.507085    5356 [ld:srv:WB1] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [logsconfig] Could not apply delta record with lsn=e6n1 ts=2021-09-17 02:14:36.493 on base with version e2n2: EXISTS, Adding LogGroup with the path "/test_logs" which already exists in the tree!
I0917 02:14:36.517765    5345 [ld:srv:WG1] Connection.cpp:724] close() Closing socket C22(127.0.0.1:59966). Reason: PEER_CLOSED: connection closed by peer
I0917 02:14:36.518946    5330 [ld:srv:WG0] Connection.cpp:724] close() Closing socket C30(127.0.0.1:60078). Reason: PEER_CLOSED: connection closed by peer
I0917 02:14:36.521494    5330 [ld:srv:WG0] Connection.cpp:724] close() Closing socket C17(127.0.0.1:59928). Reason: PEER_CLOSED: connection closed by peer
