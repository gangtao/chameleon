I0917 02:10:16.996484     310 [logdeviced-main] main.cpp:399] main() Command line arguments: --local-log-store-path /data/store/N2:1/db --num-shards 2 --server-id 5j1xxb6vec --log-file /data/store/N2:1/log --name Node2 --config-path file:/data/store/logdevice.conf --client-thrift-api-port 39349 --gossip-port 39343 --server-thrift-api-port 39348 --test-mode true --server-to-server-port 39347 --admin-port 39344 --loglevel info --port 39341 --sequencers lazy 
I0917 02:10:16.997424     310 [logdeviced-main] main.cpp:403] main() Plugins loaded: {"Thrift client factory plugin":"built-in","ZookeeperClient factory":"built-in","ConfigSource factory":["built-in"],"PermissionChecker factory":"built-in","Build Info":"built-in","Plugin provider":["Built-in plugin provider","Static plug-in loader","Dynamic plugin loader"]}
I0917 02:10:16.998201     310 [logdeviced-main] main.cpp:405] main() server starting
I0917 02:10:16.999221     310 [logdeviced-main] main.cpp:410] main() version 99.99.99
I0917 02:10:16.999954     310 [logdeviced-main] main.cpp:418] main() asserts off (NDEBUG set)
I0917 02:10:17.002624     310 [logdeviced-main] TextConfigUpdater.cpp:56] fetchFromSource() Requesting main config "/data/store/logdevice.conf" (source: file)
I0917 02:10:17.005368     310 [logdeviced-main] TextConfigUpdater.cpp:116] onContents() Main config from file, hash = 9egjnxotid
I0917 02:10:17.177984     310 [logdeviced-main] Server.cpp:185] operator()() Updating settings from config took 171ms
I0917 02:10:17.178946     310 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 171ms, config update: 0ms, notifications: 0ms
I0917 02:10:17.179729     310 [logdeviced-main] TextConfigUpdater.cpp:306] pushServerConfig() Updated config (version: 1 - hash: 9egjnxotid)
I0917 02:10:17.180352     310 [logdeviced-main] TextConfigUpdater.cpp:397] pushLogsConfig() Ignoring changes in the 'logs' section in the config file because LogsConfigManager is ENABLED
I0917 02:10:17.180970     310 [logdeviced-main] TextConfigUpdater.cpp:174] update() Config update result: ServerConfig=updated, ZK=skipped, LogsConfig=updated
I0917 02:10:17.182425     310 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:10:17.186679     310 [logdeviced-main] NodesConfigurationInit.cpp:233] operator()() Fetching initial nodes configuration (Attempt 1)...
I0917 02:10:17.195423     319 [ld:file-ncs] NodesConfigurationInit.cpp:290] operator()() Got a NodesConfiguration of version: 5
I0917 02:10:17.197711     319 [ld:file-ncs] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 1ms, notifications: 0ms
I0917 02:10:17.199198     310 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:10:17.199989     310 [logdeviced-main] Server.cpp:510] init() My Node ID is N2:1
I0917 02:10:17.200537     310 [logdeviced-main] Server.cpp:517] init() My version is 0
I0917 02:10:17.200989     310 [logdeviced-main] NoopTraceLogger.cpp:22] NoopTraceLogger() NOOP TraceLogger is ON, no trace samples will be published.
I0917 02:10:17.202847     310 [logdeviced-main] FileBasedVersionedConfigStore.cpp:46] stopAndJoin() FileBasedVersionedConfigStore threads stopped.
I0917 02:10:17.203752     310 [logdeviced-main] main.cpp:144] set_fd_limit() Limit on number of file descriptors is 1048576
W0917 02:10:17.207775     310 [logdeviced-main] main.cpp:192] drop_root() Running under root, but no --user command line option specified. Will keep running as root
I0917 02:10:17.209786     310 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 39341
I0917 02:10:17.211414     310 [logdeviced-main] Server.cpp:781] initListeners() Initializing a gossip listener.
I0917 02:10:17.212650     310 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 39343
I0917 02:10:17.214742     310 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 39347 (SSL)
I0917 02:10:17.215406     310 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 39351 (SSL)
I0917 02:10:17.215998     310 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 39350 (SSL)
I0917 02:10:17.240611     336 [io-stall:s1] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 1
I0917 02:10:17.243826     310 [logdeviced-main] RocksDBLogStoreConfig.cpp:162] RocksDBLogStoreConfig() LD manages flushes and all memory budgets on the node. atomic_flush is set to true.
I0917 02:10:17.244390     335 [io-stall:s0] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 0
I0917 02:10:17.251004     370 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:10:17.255603     369 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:10:17.528078     370 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard1/000015.log.trash as trash -- OK
I0917 02:10:17.537071     372 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N2:1/db/shard1/000015.log.trash
I0917 02:10:17.551686     369 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000015.log.trash as trash -- OK
I0917 02:10:17.563415     373 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N2:1/db/shard0/000015.log.trash
I0917 02:10:17.593744     370 [ld:open-rocks1] PartitionedRocksDBStore.cpp:897] open() Shard[1] dirty ranges: []
I0917 02:10:17.597752     370 [ld:open-rocks1] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.000s. Read 2 records, 214 bytes. Wrote 0 records, 0 bytes.
I0917 02:10:17.612557     369 [ld:open-rocks0] PartitionedRocksDBStore.cpp:897] open() Shard[0] dirty ranges: []
I0917 02:10:17.618656     369 [ld:open-rocks0] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.000s. Read 2 records, 214 bytes. Wrote 0 records, 0 bytes.
I0917 02:10:17.675312     359 [rocks-high-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard1/000021.log.trash as trash -- OK
I0917 02:10:17.682339     360 [rocks-high-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000021.log.trash as trash -- OK
I0917 02:10:17.683970     370 [ld:open-rocks1] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N2:1/db/shard1 in 431 ms
I0917 02:10:17.685841     372 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N2:1/db/shard1/000021.log.trash
I0917 02:10:17.690935     369 [ld:open-rocks0] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N2:1/db/shard0 in 433 ms
I0917 02:10:17.691069     373 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N2:1/db/shard0/000021.log.trash
I0917 02:10:17.706190     310 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:691] printDiskShardMapping() Disk -> Shard mapping: /data/store/N2:1/db/shard0 -> [0,1]
I0917 02:10:17.707908     310 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:285] init() Initialized sharded RocksDB instance at /data/store/N2:1/db with 2 shards
E0917 02:10:17.710549    1091 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState1"!
E0917 02:10:17.710590    1090 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState0"!
I0917 02:10:17.723615     310 [logdeviced-main] Server.cpp:1173] initLogStorageStateMap() Populating log storage state map successful.
E0917 02:10:17.730133     310 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:10:17.731688     310 [logdeviced-main] RecordCacheMonitorThread.cpp:27] RecordCacheMonitorThread() Record cache monitor thread started.
I0917 02:10:17.734374     310 [logdeviced-main] ClusterState.cpp:356] resizeClusterState() Cluster state size updated from 0 to 5
I0917 02:10:17.732502    1135 [ld:cache-evict] RecordCacheMonitorThread.cpp:44] threadMain() Record cache eviction thread started. Size limit is set to 4294967296 bytes.
E0917 02:10:17.737789     310 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.742587     310 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.746731     310 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.750798     310 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.764356     310 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:10:17.766698     310 [logdeviced-main] Processor.cpp:247] init() Initialized 5 workers of type GENERAL
E0917 02:10:17.769072     310 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:10:17.770482     310 [logdeviced-main] Processor.cpp:247] init() Initialized 1 workers of type FAILURE_DETECTOR
E0917 02:10:17.772566     310 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.776662     310 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.780136     310 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:10:17.784857     310 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:10:17.786805     310 [logdeviced-main] Processor.cpp:247] init() Initialized 4 workers of type BACKGROUND
I0917 02:10:17.789453     310 [logdeviced-main] FailureDetector.cpp:139] FailureDetector() Failure Detector created with instance id: 1631844617789
I0917 02:10:17.790878     310 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N0 changed from UNKNOWN to DEAD
I0917 02:10:17.792238     310 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from HEALTHY to UNHEALTHY
I0917 02:10:17.793735     310 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N1 changed from UNKNOWN to DEAD
I0917 02:10:17.794913     310 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from HEALTHY to UNHEALTHY
I0917 02:10:17.795719     310 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N2 changed from UNKNOWN to DEAD
I0917 02:10:17.800578     310 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from HEALTHY to UNHEALTHY
I0917 02:10:17.802144     310 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N3 changed from UNKNOWN to DEAD
I0917 02:10:17.805325     310 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from HEALTHY to UNHEALTHY
I0917 02:10:17.804814    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:10:17.809536     310 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N4 changed from UNKNOWN to DEAD
I0917 02:10:17.819914     310 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from HEALTHY to UNHEALTHY
W0917 02:10:17.827677    1161 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 38 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967298), p :HI_PRI
W0917 02:10:17.830383    1139 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 41 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967296), p :HI_PRI
W0917 02:10:17.831606    1167 [ld:srv:WG3] Worker.cpp:1322] processRequest() Request queued for 42 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967299), p :HI_PRI
W0917 02:10:17.835322    1150 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 46 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967297), p :HI_PRI
W0917 02:10:17.842188    1139 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 50 msec: NODE_STATE_UPDATED (id: 4294967301), p :LO_PRI
W0917 02:10:17.845811    1139 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 53 msec: NODE_STATE_UPDATED (id: 4294967306), p :LO_PRI
W0917 02:10:17.846838    1139 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 54 msec: NODE_STATE_UPDATED (id: 4294967307), p :LO_PRI
W0917 02:10:17.847903    1139 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 53 msec: NODE_STATE_UPDATED (id: 4294967311), p :LO_PRI
I0917 02:10:17.848815     310 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
W0917 02:10:17.849233    1139 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 54 msec: NODE_STATE_UPDATED (id: 4294967316), p :LO_PRI
I0917 02:10:17.852054    1203 [ld:srv:WB1] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:10:17.852848    1203 [ld:srv:WB1] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 1ms
W0917 02:10:17.851872    1139 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 57 msec: NODE_STATE_UPDATED (id: 4294967317), p :LO_PRI
I0917 02:10:17.860875    1203 [ld:srv:WB1] NodesConfigurationManager.cpp:507] onProcessingFinished() Updated local nodes config to version 5...
I0917 02:10:17.862002    1118 [ld:s0:default:0] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:10:17.863115    1118 [ld:s0:default:0] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 0, totaling 0 bytes.
I0917 02:10:17.863947    1130 [ld:s1:default:0] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:10:17.865668    1130 [ld:s1:default:0] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 1, totaling 0 bytes.
I0917 02:10:17.868428     310 [logdeviced-main] Server.cpp:1319] initSequencers() Initializing FileEpochStore
I0917 02:10:17.869163     310 [logdeviced-main] Server.cpp:1398] initSequencerPlacement() using SequencerOptions::LAZY
I0917 02:10:17.871626     310 [logdeviced-main] Server.cpp:1430] initRebuildingCoordinator() Initializing EventLog RSM and RebuildingCoordinator
I0917 02:10:17.873066     310 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387903)
I0917 02:10:17.875144     310 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387903, is_server:1)
I0917 02:10:17.876585     310 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:10:17.880034     310 [logdeviced-main] Server.cpp:1467] initRebuildingCoordinator() Starting RebuildingSupervisor
I0917 02:10:17.881051     310 [logdeviced-main] Server.cpp:1480] initRebuildingCoordinator() Starting RebuildingCoordinator
I0917 02:10:17.881341    1174 [ld:srv:WG4] RebuildingSupervisor.cpp:62] init() Starting Rebuilding Supervisor
I0917 02:10:17.887574    1174 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N4 to execute in 1200s
I0917 02:10:17.889411    1174 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N3 to execute in 1200s
I0917 02:10:17.889647     310 [logdeviced-main] LogStoreMonitor.cpp:190] start() Logstore monitoring thread started.
I0917 02:10:17.892881     310 [logdeviced-main] UnreleasedRecordDetector.cpp:106] start() Unreleased record detector thread started.
I0917 02:10:17.889630    1210 [ld:srv:WB3] RebuildingCoordinator.cpp:309] subscribeToEventLogIfNeeded() RebuildingCoordinator did not start yet because LogsConfig is not fully loaded yet
I0917 02:10:17.891435    1174 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N1 to execute in 1200s
I0917 02:10:17.893801     310 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387901)
I0917 02:10:17.895236    1210 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [eventlog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:10:17.900887    1210 [ld:srv:WB3] EventLogStateMachine.cpp:146] gotInitialState() Got base rebuilding set: {}
I0917 02:10:17.897162    1174 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N0 to execute in 1200s
I0917 02:10:17.899702     310 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387901, is_server:1)
I0917 02:10:17.908549    1210 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [eventlog] Retrieving tail lsn of delta log...
W0917 02:10:17.913460    1210 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.018s, source: [Request: START_EVENT_LOG_READER]
W0917 02:10:17.911315    1174 [ld:srv:WG4] RebuildingSupervisor.cpp:705] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:10:17.912473     310 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
E0917 02:10:17.913713    1167 [ld:srv:WG3] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387903. All sequencer nodes are unavailable.
E0917 02:10:17.921636    1167 [ld:srv:WG3] SequencerRouter.cpp:56] operator()() Error during sequencer lookup for log 4611686018427387903 (NOSEQUENCER), reporting NOSEQUENCER.
I0917 02:10:17.914776    1210 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [maintenancelog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:10:17.917455    1174 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
W0917 02:10:17.924100    1174 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.043s, source: [Request: REBUILDING_SUPERVISOR]
I0917 02:10:17.920770    1203 [ld:srv:WB1] LogsConfigManager.cpp:38] execute() Starting LogsConfigManager on Worker 1 in pool: BACKGROUND
I0917 02:10:17.927980    1203 [ld:srv:WB1] LogsConfigManager.cpp:165] start() Starting LogsConfig Manager RSM
E0917 02:10:17.922677    1167 [ld:srv:WG3] SequencerRouter.cpp:105] onFailure() Error during sequencer routing for log 4611686018427387903 (NOSEQUENCER), request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7fb23d5a4028].
W0917 02:10:17.931358    1167 [ld:srv:WG3] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387903, rqid:30064771073, ctx:rsm, err(NOSEQUENCER)
I0917 02:10:17.923513    1210 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [maintenancelog] Retrieving tail lsn of delta log...
I0917 02:10:17.930445    1203 [ld:srv:WB1] LogsConfigManager.cpp:206] start() Starting LogsConfig Replicated State Machine
I0917 02:10:17.935826    1203 [ld:srv:WB1] ReplicatedStateMachine-inl.h:38] startFetchingSnapshot() [logsconfig] Using RSMSnapshotStore...
W0917 02:10:17.933506    1167 [ld:srv:WG3] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387903 (rqid:30064771073, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
E0917 02:10:17.934738    1174 [ld:srv:WG4] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387899. All sequencer nodes are unavailable.
I0917 02:10:17.938782    1203 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1294] initSnapshotFetchTimer() [logsconfig] Creating timer to fetch snapshots ...
E0917 02:10:17.940686    1210 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:30064771073) for log:4611686018427387903, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
W0917 02:10:17.942040    1174 [ld:srv:WG4] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387899, rqid:30064771075, ctx:rsm, err(NOSEQUENCER)
W0917 02:10:17.945939    1174 [ld:srv:WG4] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387899 (rqid:30064771075, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
I0917 02:10:17.945614     310 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server LogDevice Admin API Service will listen on port 39344
I0917 02:10:17.947833     310 [logdeviced-main] Server.cpp:1540] createAndAttachMaintenanceManager() Not initializing MaintenanceManager since it is disabled in settings
E0917 02:10:17.946912    1210 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:30064771075) for log:4611686018427387899, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:10:17.948750     310 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: s2s-api
I0917 02:10:17.954447     310 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server s2s-api will listen on port 39348
I0917 02:10:17.955370     310 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: c2s-api
I0917 02:10:17.957379     310 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server c2s-api will listen on port 39349
I0917 02:10:17.958414     310 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:10:17.960085     326 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:10:17.961519     310 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:10:17.964633     329 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:10:17.968035     310 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server s2s-api
I0917 02:10:17.968454    1196 [ld:srv:WF0] FailureDetector.cpp:228] startGetClusterState() Sending GET_CLUSTER_STATE to build initial FD cluster view
I0917 02:10:17.982152    1196 [ld:srv:WF0] GET_CLUSTER_STATE_Message.cpp:49] onReceived() Failure detector is not ready
W0917 02:10:17.986981    1196 [ld:srv:WF0] GetClusterStateRequest.cpp:289] onReply() Could not retrieve the state of the cluster from WF0:N1:1 (127.0.0.1:39354): NOTREADY: operation cannot be processed at this time
I0917 02:10:17.985761     310 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server c2s-api
I0917 02:10:18.003960    1196 [ld:srv:WF0] FailureDetector.cpp:267] operator()() Cluster state received with 5 dead nodes (N0,N1,N2,N3,N4) and 0 boycotted nodes ()
I0917 02:10:18.006040    1196 [ld:srv:WF0] FailureDetector.cpp:288] buildInitialState() Wait over (cluster state received)
I0917 02:10:18.007418    1196 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N0 transitioned to DEAD
I0917 02:10:18.008634    1196 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N1 transitioned to DEAD
I0917 02:10:18.010349    1196 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N3 transitioned to DEAD
I0917 02:10:18.011534    1196 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from DEAD to STARTING
I0917 02:10:18.013408    1196 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N4 transitioned to ALIVE
I0917 02:10:18.014641    1174 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N4
I0917 02:10:18.014731    1196 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N0 transitioned to UNHEALTHY (status)
I0917 02:10:18.015479     310 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server LogDevice Admin API Service
I0917 02:10:18.016604    1196 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N1 transitioned to UNHEALTHY (status)
I0917 02:10:18.019098    1196 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N3 transitioned to UNHEALTHY (status)
I0917 02:10:18.020522    1196 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N4 transitioned to UNHEALTHY (status)
I0917 02:10:18.021078    1196 [ld:srv:WF0] FailureDetector.cpp:344] buildInitialState() Initializing DomainIsolationChecker
I0917 02:10:18.021906    1196 [ld:srv:WF0] FailureDetector.cpp:915] startSuspectTimer() Starting suspect state timer
I0917 02:10:18.022660    1196 [ld:srv:WF0] FailureDetector.cpp:1285] updateNodeState() N2 transitioned from DEAD to ALIVE, FD State:(gossip: 0, instance-id: 0, failover: 0, starting: 1)
I0917 02:10:18.023360    1196 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from DEAD to STARTING
I0917 02:10:18.026148    1196 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting suspect-state-finished message.
I0917 02:10:18.027916    1196 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844617789 to node WF0:N4:1 (127.0.0.1:39321)
I0917 02:10:18.030201    1196 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844617789 to node WF0:N3:1 (UNKNOWN)
I0917 02:10:18.033582    1196 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting bringup message.
I0917 02:10:18.035391    1196 [ld:srv:WF0] FailureDetector.cpp:937] startGossiping() Start Gossiping.
I0917 02:10:18.037597    1196 [ld:srv:WF0] FailureDetector.cpp:925] operator()() Suspect timeout expired
I0917 02:10:18.038458     310 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:10:18.041064     330 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:10:18.042333    1196 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N1:1 with instance id:1631844617782, sent_time:1631844618000ms
I0917 02:10:18.044150    1196 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N1 changed from DEAD to STARTING
I0917 02:10:18.042746     310 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:10:18.047991    1196 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N1 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844617782, failover: 0, starting: 1)
I0917 02:10:18.048640    1174 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N1
I0917 02:10:18.049529     326 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:10:18.050887    1196 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N1:1 with instance id:1631844617782, sent_time:1631844618005ms
I0917 02:10:18.054753     310 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:10:18.055742    1196 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N1
I0917 02:10:18.083970     326 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:10:18.085628    1196 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N4:1 with instance id:1631844617777, sent_time:1631844617992ms
I0917 02:10:18.086608     310 [logdeviced-main] main.cpp:464] main() Listeners initialized
I0917 02:10:18.087277    1196 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N4:1 with instance id:1631844617777, sent_time:1631844617995ms
I0917 02:10:18.089563    1196 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N4
I0917 02:10:18.094903    1196 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N3:1 with instance id:1631844617866, sent_time:1631844618044ms
I0917 02:10:18.095853    1196 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N3 changed from DEAD to STARTING
I0917 02:10:18.098210    1174 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N3
W0917 02:10:18.108419    1174 [ld:srv:WG4] RebuildingSupervisor.cpp:734] adjustRebuildingThrottle() Exiting throttling mode: #draining=0, #rebuilding=0, #triggers=1, #adjusted cluster size=5, threshold=35%, actual=20%
I0917 02:10:18.098816    1196 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N3 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844617866, failover: 0, starting: 1)
I0917 02:10:18.110070    1174 [ld:srv:WG4] RebuildingSupervisor.cpp:751] adjustRebuildingThrottle() Not triggering new rebuildings until 2021-09-17 02:30:18.109: It's too soon after exiting throttling mode
I0917 02:10:18.111569    1196 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N3
I0917 02:10:18.137182    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from UNHEALTHY to UNDEFINED
I0917 02:10:18.159403    1196 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from DEAD to STARTING
I0917 02:10:18.161109    1174 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N0
I0917 02:10:18.161539    1196 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N0 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844617844, failover: 0, starting: 1)
I0917 02:10:18.167535    1196 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N0
I0917 02:10:18.442902    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from UNDEFINED to HEALTHY
I0917 02:10:18.497687    1150 [ld:srv:WG1] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket C5(127.0.0.1:60438) hit error AsyncSocketException: Socket read end of file., type = End of file
I0917 02:10:18.498712    1150 [ld:srv:WG1] Connection.cpp:724] close() Closing socket C5(127.0.0.1:60438). Reason: PEER_CLOSED: connection closed by peer
I0917 02:10:18.524831    1161 [ld:srv:WG2] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG2:C9 (127.0.0.1:60474)
I0917 02:10:18.526147    1119 [ld:s0:default:1] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 13835058055282163708 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:18.530939    1118 [ld:s0:default:0] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 4611686018427387900 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:18.545174    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from UNHEALTHY to HEALTHY
I0917 02:10:18.545898    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from UNHEALTHY to HEALTHY
I0917 02:10:18.546558    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from UNHEALTHY to UNDEFINED
I0917 02:10:18.633132    1174 [ld:srv:WG4] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 13835058055282163708 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:18.647640    1139 [ld:srv:WG0] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387900 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:18.749982    1139 [ld:srv:WG0] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [0, 0] for log 4611686018427387900.
I0917 02:10:18.831202    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:10:18.831867    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:10:18.944698    1203 [ld:srv:WB1] ReplicatedStateMachine-inl.h:130] getSnapshot() [logsconfig] Fetching snapshot with ver:e0n1, (waiting_for_snapshot_:LSN_INVALID, version_:e0n1). sync_state_:0
I0917 02:10:18.984645    1203 [ld:srv:WB1] LogBasedRSMSnapshotStore.cpp:298] onGotLastReleased() Returning EMPTY for log:4611686018427387900, last_released_real_lsn:LSN_INVALID
I0917 02:10:18.987000    1203 [ld:srv:WB1] ReplicatedStateMachine-inl.h:83] operator()() [logsconfig] getSnapshot()'s callback. st:EMPTY, snapshot blob size:0, attrs:(base_ver:LSN_INVALID, ts:0)
I0917 02:10:18.985139    1167 [ld:srv:WG3] CHECK_SEAL_onReceived.cpp:48] prepareReplyWithHighestSeal() Soft seal for log:4611686018427387899 is [epoch:0, seq:[invalid NodeID]], but normal seal is absent; src_rqid:30064771078
I0917 02:10:18.988856    1203 [ld:srv:WB1] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [logsconfig] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:10:18.993219    1203 [ld:srv:WB1] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [logsconfig] Retrieving tail lsn of delta log...
I0917 02:10:18.996321    1210 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [eventlog] Tail lsn of delta log is e2n0
I0917 02:10:18.998859    1203 [ld:srv:WB1] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [logsconfig] Tail lsn of delta log is e2n0
W0917 02:10:19.014852    1203 [ld:srv:WB1] Worker.cpp:1000] onStoppedRunning() skipped at least 8 log entries
W0917 02:10:19.015488    1203 [ld:srv:WB1] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.016s, source: [Request: WORKER_CALLBACK_HELPER]
I0917 02:10:19.090486    1167 [ld:srv:WG3] RecordCache.cpp:257] getEpochRecordCache() skipped at least 10 log entries
I0917 02:10:19.092100    1167 [ld:srv:WG3] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 13835058055282163711 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:19.094013    1167 [ld:srv:WG3] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 13835058055282163709 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:19.098438    1167 [ld:srv:WG3] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 4611686018427387899 epoch 1: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 1.
I0917 02:10:19.114948    1167 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.125896    1167 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387901 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.136364    1161 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387903 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.221763    1167 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163707 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.339209    1210 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 2 is not available. Highest epoch known is 1.
I0917 02:10:19.345490    1210 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [eventlog] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:10:19.348406    1210 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (1)
I0917 02:10:19.347647    1203 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [logsconfig] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:10:19.350057    1203 [ld:srv:WB1] LogsConfigManager.cpp:193] operator()() Received update from LogsConfigStateMachine, version 1
W0917 02:10:19.349315    1210 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.010s, source: [Message sent/received: GAP]
I0917 02:10:19.351098    1203 [ld:srv:WB1] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:10:19.352829    1203 [ld:srv:WB1] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 1ms
I0917 02:10:19.353723    1203 [ld:srv:WB1] LogsConfigManager.cpp:331] updateLogsConfig() Published new LogsConfig (fully loaded? yes) version (1) from LogsConfigManager
I0917 02:10:19.353357    1210 [ld:srv:WB3] RebuildingCoordinator.cpp:1740] publishDirtyShards() Publishing dirty shards.
I0917 02:10:19.355237    1210 [ld:srv:WB3] RebuildingCoordinator.cpp:2064] subscribeToEventLog() Subscribed to EventLog
I0917 02:10:19.363136    1196 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from STARTING to FULLY_STARTED
I0917 02:10:19.468552    1196 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from STARTING to FULLY_STARTED
I0917 02:10:19.567025    1203 [ld:srv:WB1] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [logsconfig] Applied delta record with lsn=e2n1 ts=2021-09-17 02:10:19.558
I0917 02:10:19.568106    1203 [ld:srv:WB1] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:10:19.571707    1203 [ld:srv:WB1] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 3ms
I0917 02:10:19.573808    1167 [ld:srv:WG3] Connection.cpp:724] close() Closing socket C7(127.0.0.1:60468). Reason: PEER_CLOSED: connection closed by peer
I0917 02:10:19.574586    1203 [ld:srv:WB1] LogsConfigManager.cpp:331] updateLogsConfig() Published new LogsConfig (fully loaded? yes) version (8589934593) from LogsConfigManager
I0917 02:10:19.673215    1196 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N3 changed from STARTING to FULLY_STARTED
I0917 02:10:19.676000    1174 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387898 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.772393    1167 [ld:srv:WG3] PurgeUncleanEpochs.cpp:592] complete() skipped at least 4 log entries
I0917 02:10:19.773167    1167 [ld:srv:WG3] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [0, 0] for log 4611686018427387902.
I0917 02:10:19.776499    1161 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163706 has already been cleaned. No purge needed. last clean epoch: 0, purge to: 0.
I0917 02:10:19.958398    1210 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [maintenancelog] Tail lsn of delta log is e2n0
I0917 02:10:19.969576    1210 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387899 epoch 2 is not available. Highest epoch known is 1.
I0917 02:10:19.970412    1210 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [maintenancelog] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:10:19.971062    1210 [ld:srv:WB3] ClusterMaintenanceStateMachine.cpp:112] onUpdate() [maintenancelog] Published new ClusterMaintenanceState version (1)
I0917 02:10:20.082911    1196 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N1 changed from STARTING to FULLY_STARTED
I0917 02:10:20.084042    1196 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from STARTING to FULLY_STARTED
I0917 02:10:27.833152    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:10:27.834106    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.003MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.002MB, [unpartitioned A:0.001MB]
I0917 02:10:28.848328    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:10:28.849127    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.004MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.002MB, [unpartitioned A:0.001MB]
I0917 02:10:29.350375    1210 [ld:srv:WB3] ShardAuthoritativeStatusMap.cpp:165] broadcastToAllWorkers() Posting shard status update to workers: , version=e0n1
I0917 02:10:37.850429    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:10:37.851615    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.003MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.002MB, [unpartitioned A:0.001MB]
I0917 02:10:38.866648    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:10:38.867462    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.004MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.002MB, [unpartitioned A:0.001MB]
I0917 02:10:47.654382     359 [rocks-high-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard1/000024.log.trash as trash -- OK
I0917 02:10:47.660478     372 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 8after deleting file /data/store/N2:1/db/shard1/000024.log.trash
I0917 02:10:47.681093     360 [rocks-high-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000024.log.trash as trash -- OK
I0917 02:10:47.689636     373 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 8after deleting file /data/store/N2:1/db/shard0/000024.log.trash
I0917 02:10:47.697361     340 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard1/000027.sst.trash as trash -- OK
I0917 02:10:47.703875     372 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 12after deleting file /data/store/N2:1/db/shard1/000027.sst.trash
I0917 02:10:47.712677     340 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard1/000025.sst.trash as trash -- OK
I0917 02:10:47.722655     348 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000027.sst.trash as trash -- OK
I0917 02:10:47.722906     340 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard1/000019.sst.trash as trash -- OK
I0917 02:10:47.726838     372 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N2:1/db/shard1/000025.sst.trash
I0917 02:10:47.729593     373 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 12after deleting file /data/store/N2:1/db/shard0/000027.sst.trash
I0917 02:10:47.731022     372 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N2:1/db/shard1/000019.sst.trash
I0917 02:10:47.733198     348 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000025.sst.trash as trash -- OK
I0917 02:10:47.739650     373 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N2:1/db/shard0/000025.sst.trash
I0917 02:10:47.741172     340 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard1/000016.sst.trash as trash -- OK
I0917 02:10:47.746919     348 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000019.sst.trash as trash -- OK
I0917 02:10:47.752755     372 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N2:1/db/shard1/000016.sst.trash
I0917 02:10:47.754740     373 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N2:1/db/shard0/000019.sst.trash
I0917 02:10:47.762914     348 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000016.sst.trash as trash -- OK
I0917 02:10:47.763845     340 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard1/000014.sst.trash as trash -- OK
I0917 02:10:47.771031     372 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N2:1/db/shard1/000014.sst.trash
I0917 02:10:47.772242     348 [rocks-low-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000014.sst.trash as trash -- OK
I0917 02:10:47.773296     373 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N2:1/db/shard0/000016.sst.trash
I0917 02:10:47.777911     373 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 19after deleting file /data/store/N2:1/db/shard0/000014.sst.trash
I0917 02:10:47.870224    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:10:47.871978    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:10:48.890878    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:10:48.891638    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:10:57.890937    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:10:57.906519    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:10:59.108325    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:10:59.108941    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:07.946417    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 74 log entries
W0917 02:11:08.139431    1174 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() skipped at least 1 log entries
I0917 02:11:08.353260    1174 [ld:srv:WG4] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.214s to write().
I0917 02:11:08.240672    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() skipped at least 2 log entries
I0917 02:11:08.300252    1028 [ld:s1:db-bg-fl] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.354s to write().
I0917 02:11:08.422110    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 44ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
W0917 02:11:08.386375    1174 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.042s, source: [None]
I0917 02:11:08.475014    1174 [ld:srv:WG4] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.089s to write().
I0917 02:11:08.399383    1196 [ld:srv:WF0] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.159s to write().
I0917 02:11:08.482423    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from HEALTHY to UNHEALTHY
W0917 02:11:08.483889    1196 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.246s, source: [Message sent/received: GET_CLUSTER_STATE_REPLY]
I0917 02:11:08.585609    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from HEALTHY to UNHEALTHY
I0917 02:11:08.588501    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from HEALTHY to UNHEALTHY
I0917 02:11:08.692653    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from HEALTHY to UNHEALTHY
I0917 02:11:08.694164    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from HEALTHY to UNHEALTHY
I0917 02:11:09.204503    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from UNHEALTHY to HEALTHY
I0917 02:11:09.205208    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from UNHEALTHY to HEALTHY
I0917 02:11:09.452458    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:09.453301    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:10.685444    1174 [ld:srv:WG4] ProtocolHandler.cpp:127] notifyErrorOnSocket() skipped at least 3 log entries
I0917 02:11:10.686370    1174 [ld:srv:WG4] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket C33(127.0.0.1:61168) hit error AsyncSocketException: Socket read end of file., type = End of file
I0917 02:11:10.687599    1174 [ld:srv:WG4] Connection.cpp:724] close() Closing socket C33(127.0.0.1:61168). Reason: PEER_CLOSED: connection closed by peer
I0917 02:11:10.729078    1139 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG0:C34 (127.0.0.1:61184)
I0917 02:11:11.950781    1203 [ld:srv:WB1] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [logsconfig] Applied delta record with lsn=e2n2 ts=2021-09-17 02:11:11.944
I0917 02:11:11.952390    1203 [ld:srv:WB1] LogsConfigManager.cpp:193] operator()() skipped at least 1 log entries
I0917 02:11:11.953510    1203 [ld:srv:WB1] LogsConfigManager.cpp:193] operator()() Received update from LogsConfigStateMachine, version 8589934594
I0917 02:11:11.955158    1203 [ld:srv:WB1] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:11:11.957890    1203 [ld:srv:WB1] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 2ms
I0917 02:11:11.958572    1203 [ld:srv:WB1] LogsConfigManager.cpp:331] updateLogsConfig() Published new LogsConfig (fully loaded? yes) version (8589934594) from LogsConfigManager
I0917 02:11:16.540076    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from UNHEALTHY to HEALTHY
I0917 02:11:18.059640    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 84 log entries
I0917 02:11:18.060766    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:19.070927    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:19.072180    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:28.077223    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:11:28.077955    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:29.089099    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:29.089751    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:32.681440    1139 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() skipped at least 6 log entries
I0917 02:11:32.683293    1139 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG0:C34 (127.0.0.1:61184)
I0917 02:11:38.097745    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:11:38.099428    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:39.108982    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:39.109955    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:48.116590    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:11:48.118270    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:49.127650    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:49.128423    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:54.884545    1139 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() skipped at least 6 log entries
I0917 02:11:54.885334    1139 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG0:C34 (127.0.0.1:61184)
I0917 02:11:58.142211    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:11:58.143308    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:11:59.166082    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:11:59.167193    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:08.161493    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:08.162884    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:09.186807    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:09.187846    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:16.968516    1139 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() skipped at least 6 log entries
I0917 02:12:16.969425    1139 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG0:C34 (127.0.0.1:61184)
I0917 02:12:18.180788    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:18.181539    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
W0917 02:12:18.886102    1139 [ld:srv:WG0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.016s, source: [Message sent/received: RELEASE]
I0917 02:12:19.204062    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:19.205030    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:28.198966    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:28.199873    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:29.221507    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:29.222311    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:38.218315    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:38.219588    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:38.884216    1139 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() skipped at least 6 log entries
I0917 02:12:38.885563    1139 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG0:C34 (127.0.0.1:61184)
I0917 02:12:39.240390    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:39.241146    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:48.238145    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:48.239505    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:49.257603    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:49.258760    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:52.766958    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from UNHEALTHY to HEALTHY
I0917 02:12:53.073337    1196 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from UNHEALTHY to HEALTHY
I0917 02:12:58.256313    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:12:58.257184    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:12:59.276285    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:12:59.277238    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:00.936706    1139 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() skipped at least 6 log entries
I0917 02:13:00.937606    1139 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG0:C34 (127.0.0.1:61184)
I0917 02:13:08.277396    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:13:08.279048    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:09.295517    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:13:09.296536    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:18.303232    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:13:18.303835    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:19.317318    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:13:19.318325    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:22.840300    1139 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() skipped at least 6 log entries
I0917 02:13:22.841064    1139 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG0:C34 (127.0.0.1:61184)
I0917 02:13:28.322854    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:13:28.323950    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:29.334248    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:13:29.335840    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:33.750347     314 [ld:conf] FileConfigSource.cpp:86] checkForUpdates() Change detected in config file /data/store/logdevice.conf, mtime = 1631844813641395829
I0917 02:13:33.751666     314 [ld:conf] TextConfigUpdater.cpp:116] onContents() Main config from file, hash = vj0b5rfpgt
I0917 02:13:33.752833     314 [ld:conf] TextConfigUpdater.cpp:245] compareServerConfig() Comparing new config (version 1) with existing config (version 1)
W0917 02:13:33.753756     314 [ld:conf] TextConfigUpdater.cpp:264] compareServerConfig() Received config with same version (1) but mismatched hash (9egjnxotid != vj0b5rfpgt)
I0917 02:13:33.941818     314 [ld:conf] Server.cpp:185] operator()() Updating settings from config took 187ms
I0917 02:13:33.944843     314 [ld:conf] UpdateableSecurityInfo.cpp:124] onConfigUpdate() PermissionChecker is changed
I0917 02:13:33.946878    1196 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() skipped at least 3 log entries
I0917 02:13:33.950803    1196 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received starting_state_finished message from N4:1 with instance id:1631844617777, sent_time:1631844813937ms
I0917 02:13:33.946899     314 [ld:conf] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:13:33.955412    1196 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N4
I0917 02:13:33.957195     314 [ld:conf] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 190ms, config update: 0ms, notifications: 12ms
W0917 02:13:33.957988    1196 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.011s, source: [Message sent/received: GOSSIP]
I0917 02:13:33.958481     314 [ld:conf] TextConfigUpdater.cpp:306] pushServerConfig() Updated config (version: 1 - hash: vj0b5rfpgt)
I0917 02:13:33.960497     314 [ld:conf] TextConfigUpdater.cpp:397] pushLogsConfig() Ignoring changes in the 'logs' section in the config file because LogsConfigManager is ENABLED
I0917 02:13:33.959461    1196 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting starting_state_finished message.
I0917 02:13:33.961408     314 [ld:conf] TextConfigUpdater.cpp:174] update() Config update result: ServerConfig=updated, ZK=skipped, LogsConfig=updated
I0917 02:13:33.962206    1196 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() skipped at least 6 log entries
I0917 02:13:33.964189    1196 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending starting_state_finished message with instance id:1631844617789 to node WF0:N4:1 (127.0.0.1:39321)
I0917 02:13:33.965440    1196 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending starting_state_finished message with instance id:1631844617789 to node WF0:N3:1 (127.0.0.1:39332)
I0917 02:13:33.966778    1196 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received starting_state_finished message from N3:1 with instance id:1631844617866, sent_time:1631844813937ms
I0917 02:13:33.967550    1196 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N3
I0917 02:13:33.985965    1196 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received starting_state_finished message from N1:1 with instance id:1631844617782, sent_time:1631844813985ms
I0917 02:13:33.986984    1196 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N1
I0917 02:13:34.001153    1196 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received starting_state_finished message from N0:1 with instance id:1631844617844, sent_time:1631844813999ms
I0917 02:13:34.001871    1196 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N0
I0917 02:13:38.344187    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 88 log entries
I0917 02:13:38.344846    1028 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:39.352132    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:13:39.352964    1048 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:13:41.348754    1167 [ld:srv:WG3] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket C35(127.0.0.1:61200) hit error AsyncSocketException: Socket read end of file., type = End of file
I0917 02:13:41.349002    1139 [ld:srv:WG0] Connection.cpp:724] close() Closing socket C34(127.0.0.1:61184). Reason: PEER_CLOSED: connection closed by peer
I0917 02:14:07.269737     762 [logdeviced-main] main.cpp:399] main() Command line arguments: --local-log-store-path /data/store/N2:1/db --num-shards 2 --server-id doaxv3hjqq --log-file /data/store/N2:1/log --name Node2 --config-path file:/data/store/logdevice.conf --client-thrift-api-port 48343 --gossip-port 48337 --server-thrift-api-port 48342 --test-mode true --server-to-server-port 48341 --admin-port 48338 --loglevel info --port 48335 --sequencers lazy 
I0917 02:14:07.271408     762 [logdeviced-main] main.cpp:403] main() Plugins loaded: {"Thrift client factory plugin":"built-in","ZookeeperClient factory":"built-in","ConfigSource factory":["built-in"],"PermissionChecker factory":"built-in","Build Info":"built-in","Plugin provider":["Built-in plugin provider","Static plug-in loader","Dynamic plugin loader"]}
I0917 02:14:07.275170     762 [logdeviced-main] main.cpp:405] main() server starting
I0917 02:14:07.276590     762 [logdeviced-main] main.cpp:410] main() version 99.99.99
I0917 02:14:07.278364     762 [logdeviced-main] main.cpp:418] main() asserts off (NDEBUG set)
I0917 02:14:07.283272     762 [logdeviced-main] TextConfigUpdater.cpp:56] fetchFromSource() Requesting main config "/data/store/logdevice.conf" (source: file)
I0917 02:14:07.287035     762 [logdeviced-main] TextConfigUpdater.cpp:116] onContents() Main config from file, hash = hyg3dqvegx
I0917 02:14:07.613159     762 [logdeviced-main] Server.cpp:185] operator()() Updating settings from config took 323ms
I0917 02:14:07.614378     762 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 324ms, config update: 0ms, notifications: 0ms
I0917 02:14:07.615442     762 [logdeviced-main] TextConfigUpdater.cpp:306] pushServerConfig() Updated config (version: 1 - hash: hyg3dqvegx)
I0917 02:14:07.616339     762 [logdeviced-main] TextConfigUpdater.cpp:397] pushLogsConfig() Ignoring changes in the 'logs' section in the config file because LogsConfigManager is ENABLED
I0917 02:14:07.617229     762 [logdeviced-main] TextConfigUpdater.cpp:174] update() Config update result: ServerConfig=updated, ZK=skipped, LogsConfig=updated
I0917 02:14:07.618319     762 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:14:07.629770     762 [logdeviced-main] NodesConfigurationInit.cpp:233] operator()() Fetching initial nodes configuration (Attempt 1)...
I0917 02:14:07.637779     887 [ld:file-ncs] NodesConfigurationInit.cpp:290] operator()() Got a NodesConfiguration of version: 5
I0917 02:14:07.638747     887 [ld:file-ncs] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:07.642749     762 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:07.644212     762 [logdeviced-main] Server.cpp:510] init() My Node ID is N2:1
I0917 02:14:07.645165     762 [logdeviced-main] Server.cpp:517] init() My version is 0
I0917 02:14:07.645950     762 [logdeviced-main] NoopTraceLogger.cpp:22] NoopTraceLogger() NOOP TraceLogger is ON, no trace samples will be published.
I0917 02:14:07.649701     762 [logdeviced-main] FileBasedVersionedConfigStore.cpp:46] stopAndJoin() FileBasedVersionedConfigStore threads stopped.
I0917 02:14:07.650465     762 [logdeviced-main] main.cpp:144] set_fd_limit() Limit on number of file descriptors is 1048576
W0917 02:14:07.651278     762 [logdeviced-main] main.cpp:192] drop_root() Running under root, but no --user command line option specified. Will keep running as root
I0917 02:14:07.656907     762 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48335
I0917 02:14:07.658795     762 [logdeviced-main] Server.cpp:781] initListeners() Initializing a gossip listener.
I0917 02:14:07.660068     762 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48337
I0917 02:14:07.664389     762 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48341 (SSL)
I0917 02:14:07.665460     762 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48345 (SSL)
I0917 02:14:07.666340     762 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48344 (SSL)
I0917 02:14:07.697073     762 [logdeviced-main] RocksDBLogStoreConfig.cpp:162] RocksDBLogStoreConfig() LD manages flushes and all memory budgets on the node. atomic_flush is set to true.
I0917 02:14:07.704978     896 [io-stall:s1] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 1
I0917 02:14:07.705335     895 [io-stall:s0] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 0
I0917 02:14:07.748671     903 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:07.753073     904 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:08.345806     903 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000037.log.trash as trash -- OK
I0917 02:14:08.362607     905 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N2:1/db/shard0/000037.log.trash
I0917 02:14:08.404753     903 [ld:open-rocks0] PartitionedRocksDBStore.cpp:891] open() Partition s0:1000000 is under-replicated: Start:2021-09-17 02:10:15.550, Min:2021-09-17 02:10:10.550, Max: 2021-09-17 02:10:20.550
I0917 02:14:08.406193     903 [ld:open-rocks0] PartitionedRocksDBStore.cpp:897] open() Shard[0] dirty ranges: [A:{{[2021-09-17 02:10:10.550,2021-09-17 02:10:20.550]}}]
I0917 02:14:08.420041     903 [ld:open-rocks0] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.001s. Read 6 records, 448 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:08.478773     904 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard1/000035.log.trash as trash -- OK
I0917 02:14:08.506538     923 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N2:1/db/shard1/000035.log.trash
I0917 02:14:08.511459     902 [rocks-high-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000043.log.trash as trash -- OK
I0917 02:14:08.518226     905 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N2:1/db/shard0/000043.log.trash
I0917 02:14:08.519294     903 [ld:open-rocks0] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N2:1/db/shard0 in 767 ms
I0917 02:14:08.538819     904 [ld:open-rocks1] PartitionedRocksDBStore.cpp:891] open() Partition s1:1000000 is under-replicated: Start:2021-09-17 02:10:15.557, Min:2021-09-17 02:10:10.557, Max: 2021-09-17 02:10:20.557
I0917 02:14:08.541910     904 [ld:open-rocks1] PartitionedRocksDBStore.cpp:897] open() Shard[1] dirty ranges: [A:{{[2021-09-17 02:10:10.557,2021-09-17 02:10:20.557]}}]
I0917 02:14:08.566549     904 [ld:open-rocks1] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.000s. Read 4 records, 298 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:08.646946    1226 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 9ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:14:08.653372     901 [rocks-high-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard1/000040.log.trash as trash -- OK
I0917 02:14:08.659375     904 [ld:open-rocks1] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N2:1/db/shard1 in 902 ms
I0917 02:14:08.659649     923 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N2:1/db/shard1/000040.log.trash
I0917 02:14:08.674484     762 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:691] printDiskShardMapping() Disk -> Shard mapping: /data/store/N2:1/db/shard0 -> [0,1]
I0917 02:14:08.679207     762 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:285] init() Initialized sharded RocksDB instance at /data/store/N2:1/db with 2 shards
E0917 02:14:08.683405    1295 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState0"!
E0917 02:14:08.686850    1296 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState1"!
I0917 02:14:08.695701     762 [logdeviced-main] Server.cpp:1173] initLogStorageStateMap() Populating log storage state map successful.
E0917 02:14:08.750593     762 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:08.758425     762 [logdeviced-main] RecordCacheMonitorThread.cpp:27] RecordCacheMonitorThread() Record cache monitor thread started.
I0917 02:14:08.766091     762 [logdeviced-main] ClusterState.cpp:356] resizeClusterState() Cluster state size updated from 0 to 5
I0917 02:14:08.759173    1331 [ld:cache-evict] RecordCacheMonitorThread.cpp:44] threadMain() Record cache eviction thread started. Size limit is set to 4294967296 bytes.
E0917 02:14:08.783997     762 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:08.800089     762 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:08.827669     762 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:08.847970     762 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:08.852941     762 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:08.857343     762 [logdeviced-main] Processor.cpp:247] init() Initialized 5 workers of type GENERAL
E0917 02:14:08.861009     762 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:08.869989     762 [logdeviced-main] Processor.cpp:247] init() Initialized 1 workers of type FAILURE_DETECTOR
E0917 02:14:08.872734     762 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:08.888053     762 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:08.913551     762 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:08.933219     762 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:08.941217     762 [logdeviced-main] Processor.cpp:247] init() Initialized 4 workers of type BACKGROUND
I0917 02:14:08.955880     762 [logdeviced-main] FailureDetector.cpp:139] FailureDetector() Failure Detector created with instance id: 1631844848952
I0917 02:14:08.957810     762 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N0 changed from UNKNOWN to DEAD
I0917 02:14:08.959043     762 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from HEALTHY to UNHEALTHY
I0917 02:14:08.961724     762 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N1 changed from UNKNOWN to DEAD
I0917 02:14:08.967086     762 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from HEALTHY to UNHEALTHY
I0917 02:14:08.968802     762 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N2 changed from UNKNOWN to DEAD
I0917 02:14:08.973016     762 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from HEALTHY to UNHEALTHY
I0917 02:14:08.975193     762 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N3 changed from UNKNOWN to DEAD
I0917 02:14:08.978011     762 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from HEALTHY to UNHEALTHY
I0917 02:14:08.981194     762 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N4 changed from UNKNOWN to DEAD
I0917 02:14:08.986312     762 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from HEALTHY to UNHEALTHY
W0917 02:14:08.998499    1333 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 46 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967296), p :HI_PRI
W0917 02:14:09.000561    1335 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 48 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967297), p :HI_PRI
W0917 02:14:09.015036    1338 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 56 msec: NODE_STATE_UPDATED (id: 4294967303), p :LO_PRI
I0917 02:14:09.036783     762 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
W0917 02:14:09.039016    1338 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 80 msec: NODE_STATE_UPDATED (id: 4294967309), p :LO_PRI
W0917 02:14:09.048359    1338 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 85 msec: NODE_STATE_UPDATED (id: 4294967313), p :LO_PRI
W0917 02:14:09.049907    1338 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 83 msec: NODE_STATE_UPDATED (id: 4294967319), p :LO_PRI
W0917 02:14:09.051680    1338 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 82 msec: NODE_STATE_UPDATED (id: 4294967323), p :LO_PRI
W0917 02:14:09.054973    1338 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 81 msec: NODE_STATE_UPDATED (id: 4294967329), p :LO_PRI
W0917 02:14:09.056603    1338 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 78 msec: NODE_STATE_UPDATED (id: 4294967333), p :LO_PRI
I0917 02:14:09.053120    1384 [ld:srv:WB2] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:14:09.088359    1384 [ld:srv:WB2] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 35ms
W0917 02:14:09.058187    1338 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 80 msec: NODE_STATE_UPDATED (id: 4294967339), p :LO_PRI
W0917 02:14:09.092859    1384 [ld:srv:WB2] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.052s, source: [Request: NODES_CONFIGURATION_MANAGER]
I0917 02:14:09.097752    1384 [ld:srv:WB2] NodesConfigurationManager.cpp:507] onProcessingFinished() Updated local nodes config to version 5...
I0917 02:14:09.100345    1323 [ld:s1:default:0] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:09.102975    1323 [ld:s1:default:0] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 1, totaling 0 bytes.
I0917 02:14:09.101606    1316 [ld:s0:default:1] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:09.105621    1316 [ld:s0:default:1] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 0, totaling 0 bytes.
I0917 02:14:09.110456     762 [logdeviced-main] Server.cpp:1319] initSequencers() Initializing FileEpochStore
I0917 02:14:09.115084     762 [logdeviced-main] Server.cpp:1398] initSequencerPlacement() using SequencerOptions::LAZY
I0917 02:14:09.116439     762 [logdeviced-main] Server.cpp:1430] initRebuildingCoordinator() Initializing EventLog RSM and RebuildingCoordinator
I0917 02:14:09.118819     762 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387903)
I0917 02:14:09.123300     762 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387903, is_server:1)
I0917 02:14:09.125224     762 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:09.126456     762 [logdeviced-main] Server.cpp:1467] initRebuildingCoordinator() Starting RebuildingSupervisor
I0917 02:14:09.128426     762 [logdeviced-main] Server.cpp:1480] initRebuildingCoordinator() Starting RebuildingCoordinator
I0917 02:14:09.128545    1341 [ld:srv:WG4] RebuildingSupervisor.cpp:62] init() Starting Rebuilding Supervisor
I0917 02:14:09.132499    1341 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N4 to execute in 1200s
I0917 02:14:09.134831    1341 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N3 to execute in 1200s
I0917 02:14:09.134762    1458 [ld:srv:WB3] RebuildingCoordinator.cpp:309] subscribeToEventLogIfNeeded() RebuildingCoordinator did not start yet because LogsConfig is not fully loaded yet
I0917 02:14:09.142884    1458 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [eventlog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:09.134891     762 [logdeviced-main] LogStoreMonitor.cpp:190] start() Logstore monitoring thread started.
I0917 02:14:09.147201     762 [logdeviced-main] UnreleasedRecordDetector.cpp:106] start() Unreleased record detector thread started.
I0917 02:14:09.138736    1341 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N1 to execute in 1200s
I0917 02:14:09.150626    1341 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N0 to execute in 1200s
I0917 02:14:09.144138    1458 [ld:srv:WB3] EventLogStateMachine.cpp:146] gotInitialState() Got base rebuilding set: {}
I0917 02:14:09.152707    1458 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [eventlog] Retrieving tail lsn of delta log...
I0917 02:14:09.148637     762 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387901)
I0917 02:14:09.161733     762 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387901, is_server:1)
W0917 02:14:09.151692    1341 [ld:srv:WG4] RebuildingSupervisor.cpp:705] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
W0917 02:14:09.158332    1458 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.015s, source: [Request: START_EVENT_LOG_READER]
E0917 02:14:09.158693    1339 [ld:srv:WG3] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387903. All sequencer nodes are unavailable.
E0917 02:14:09.172766    1339 [ld:srv:WG3] SequencerRouter.cpp:56] operator()() Error during sequencer lookup for log 4611686018427387903 (NOSEQUENCER), reporting NOSEQUENCER.
I0917 02:14:09.167447     762 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:09.169187    1341 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:14:09.171959    1458 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [maintenancelog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:09.190716    1458 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [maintenancelog] Retrieving tail lsn of delta log...
E0917 02:14:09.178360    1339 [ld:srv:WG3] SequencerRouter.cpp:105] onFailure() Error during sequencer routing for log 4611686018427387903 (NOSEQUENCER), request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7efee47a3028].
W0917 02:14:09.196004    1339 [ld:srv:WG3] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387903, rqid:25769803777, ctx:rsm, err(NOSEQUENCER)
I0917 02:14:09.183209    1349 [ld:srv:WB1] LogsConfigManager.cpp:38] execute() Starting LogsConfigManager on Worker 1 in pool: BACKGROUND
I0917 02:14:09.198687    1349 [ld:srv:WB1] LogsConfigManager.cpp:165] start() Starting LogsConfig Manager RSM
E0917 02:14:09.195044    1341 [ld:srv:WG4] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387899. All sequencer nodes are unavailable.
W0917 02:14:09.205050    1341 [ld:srv:WG4] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387899, rqid:25769803779, ctx:rsm, err(NOSEQUENCER)
W0917 02:14:09.197384    1339 [ld:srv:WG3] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387903 (rqid:25769803777, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
I0917 02:14:09.199799    1349 [ld:srv:WB1] LogsConfigManager.cpp:206] start() Starting LogsConfig Replicated State Machine
I0917 02:14:09.215208    1349 [ld:srv:WB1] ReplicatedStateMachine-inl.h:38] startFetchingSnapshot() [logsconfig] Using RSMSnapshotStore...
E0917 02:14:09.207381    1458 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:25769803779) for log:4611686018427387899, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
E0917 02:14:09.219824    1458 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:25769803777) for log:4611686018427387903, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:14:09.218058    1349 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1294] initSnapshotFetchTimer() [logsconfig] Creating timer to fetch snapshots ...
I0917 02:14:09.226061     762 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server LogDevice Admin API Service will listen on port 48338
I0917 02:14:09.228315     762 [logdeviced-main] Server.cpp:1540] createAndAttachMaintenanceManager() Not initializing MaintenanceManager since it is disabled in settings
I0917 02:14:09.234039     762 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: s2s-api
I0917 02:14:09.241395     762 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server s2s-api will listen on port 48342
I0917 02:14:09.244026     762 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: c2s-api
I0917 02:14:09.245541     762 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server c2s-api will listen on port 48343
I0917 02:14:09.247369     762 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:09.251877     888 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:09.255312     762 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:09.261005     889 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:09.268678     762 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server s2s-api
I0917 02:14:09.269390    1345 [ld:srv:WF0] FailureDetector.cpp:228] startGetClusterState() Sending GET_CLUSTER_STATE to build initial FD cluster view
I0917 02:14:09.287573    1345 [ld:srv:WF0] FailureDetector.cpp:267] operator()() Cluster state received with 5 dead nodes (N0,N1,N2,N3,N4) and 0 boycotted nodes ()
I0917 02:14:09.288989    1345 [ld:srv:WF0] FailureDetector.cpp:288] buildInitialState() Wait over (cluster state received)
I0917 02:14:09.296351    1345 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from DEAD to STARTING
I0917 02:14:09.303824    1341 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N0
I0917 02:14:09.305097    1345 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N0 transitioned to ALIVE
I0917 02:14:09.310013    1345 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N1 transitioned to DEAD
I0917 02:14:09.312516    1345 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N3 transitioned to DEAD
I0917 02:14:09.315039    1345 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N4 transitioned to DEAD
I0917 02:14:09.319057    1345 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from UNHEALTHY to HEALTHY
I0917 02:14:09.321016    1345 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N0 transitioned to HEALTHY (status)
I0917 02:14:09.322708    1345 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N1 transitioned to UNHEALTHY (status)
I0917 02:14:09.324425    1345 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N3 transitioned to UNHEALTHY (status)
I0917 02:14:09.326940    1345 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N4 transitioned to UNHEALTHY (status)
I0917 02:14:09.331168    1345 [ld:srv:WF0] FailureDetector.cpp:344] buildInitialState() Initializing DomainIsolationChecker
I0917 02:14:09.336607    1345 [ld:srv:WF0] FailureDetector.cpp:915] startSuspectTimer() Starting suspect state timer
I0917 02:14:09.334393     762 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server c2s-api
I0917 02:14:09.341560    1345 [ld:srv:WF0] FailureDetector.cpp:1285] updateNodeState() N2 transitioned from DEAD to ALIVE, FD State:(gossip: 0, instance-id: 0, failover: 0, starting: 1)
I0917 02:14:09.345907    1345 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from DEAD to STARTING
I0917 02:14:09.350473    1345 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting suspect-state-finished message.
I0917 02:14:09.351958    1345 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844848952 to node WF0:N4:1 (127.0.0.1:48315)
I0917 02:14:09.356736    1345 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844848952 to node WF0:N3:1 (UNKNOWN)
I0917 02:14:09.358517    1345 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting bringup message.
I0917 02:14:09.374206    1345 [ld:srv:WF0] FailureDetector.cpp:937] startGossiping() Start Gossiping.
I0917 02:14:09.379455    1345 [ld:srv:WF0] FailureDetector.cpp:925] operator()() Suspect timeout expired
I0917 02:14:09.383570    1345 [ld:srv:WF0] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket N3:1(127.0.0.1:48326) hit error AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused)
I0917 02:14:09.400441     762 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server LogDevice Admin API Service
I0917 02:14:09.407770    1345 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N4:1 with instance id:1631844848982, sent_time:1631844849375ms
I0917 02:14:09.408650    1345 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from DEAD to STARTING
I0917 02:14:09.410494    1345 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N4 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844848982, failover: 0, starting: 1)
I0917 02:14:09.413670    1345 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N4:1 with instance id:1631844848982, sent_time:1631844849383ms
I0917 02:14:09.410895    1341 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N4
I0917 02:14:09.416267    1345 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N4
I0917 02:14:09.430137     762 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:09.433719     894 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:09.437776     762 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:09.439291     888 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:09.442032     762 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:09.443690     888 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:09.445343     762 [logdeviced-main] main.cpp:464] main() Listeners initialized
I0917 02:14:09.478335    1345 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from UNHEALTHY to UNDEFINED
I0917 02:14:09.581420    1345 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from UNDEFINED to HEALTHY
I0917 02:14:09.585550    1345 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N1:1 (127.0.0.1:48348): CONNFAILED: connection failed. Trying another node.
I0917 02:14:09.620765    1339 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163711 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:09.672073    1338 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387903 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:09.743640    1338 [ld:srv:WG2] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [1, 1] for log 4611686018427387903.
I0917 02:14:09.785981    1251 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:14:09.787302    1251 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.002MB in 2 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, [unpartitioned A:0.001MB]
I0917 02:14:09.966710    1345 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N3:1 with instance id:1631844849516, sent_time:1631844849896ms
I0917 02:14:09.967585    1345 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N3 changed from DEAD to STARTING
I0917 02:14:09.969759    1345 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N3 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844849516, failover: 0, starting: 1)
I0917 02:14:09.970664    1345 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N3:1 with instance id:1631844849516, sent_time:1631844849948ms
I0917 02:14:09.969906    1341 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N3
W0917 02:14:09.976634    1341 [ld:srv:WG4] RebuildingSupervisor.cpp:734] adjustRebuildingThrottle() Exiting throttling mode: #draining=0, #rebuilding=0, #triggers=1, #adjusted cluster size=5, threshold=35%, actual=20%
I0917 02:14:09.971665    1345 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N3
I0917 02:14:09.977817    1341 [ld:srv:WG4] RebuildingSupervisor.cpp:751] adjustRebuildingThrottle() Not triggering new rebuildings until 2021-09-17 02:34:09.977: It's too soon after exiting throttling mode
I0917 02:14:10.003442    1345 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from UNHEALTHY to HEALTHY
I0917 02:14:10.032670    1338 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387903 has already been cleaned. No purge needed. last clean epoch: 2, purge to: 2.
I0917 02:14:10.060783    1339 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163711 has already been cleaned. No purge needed. last clean epoch: 2, purge to: 2.
I0917 02:14:10.135884    1333 [ld:srv:WG0] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163707 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:10.152894    1341 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163708 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:10.168026    1339 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387900 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:10.176091    1339 [ld:srv:WG3] GET_SEQ_STATE_Message.cpp:238] getSequencer() Sequencer for log:4611686018427387898 is absent, state=UNAVAILABLE, cur_epoch=0, attempting to activate it upon receiving GSS (rqid:12884901892, ctx:rsm, min_epoch:none) from WG3:C12 (127.0.0.1:52718)
I0917 02:14:10.210315    1339 [ld:srv:WG3] GET_SEQ_STATE_Message.cpp:567] continueExecution() Received a GET_SEQ_STATE message (log:4611686018427387898, rqid:12884901892, ctx:rsm) from WG3:C12 (127.0.0.1:52718), but its data log sequencer's state is ACTIVATING
W0917 02:14:10.211402    1339 [ld:srv:WG3] Worker.cpp:1000] onStoppedRunning() skipped at least 7 log entries
W0917 02:14:10.214234    1339 [ld:srv:WG3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.035s, source: [Message sent/received: GET_SEQ_STATE]
I0917 02:14:10.214615    1338 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:10.215438    1339 [ld:srv:WG3] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 4611686018427387898 epoch 4.
I0917 02:14:10.219443    1339 [ld:srv:WG3] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 4611686018427387898: {[E:1 (at 2021-09-17 02:14:10.200) since:1 (at 2021-09-17 02:10:14.514) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S0,N1:S0,N2:S0,N3:S0,N4:S0} W:[]], Until:4}.
I0917 02:14:10.220890    1335 [ld:srv:WG1] PeriodicReleases.cpp:416] execute() Start broadcasting releases for log 4611686018427387898.
I0917 02:14:10.220883    1339 [ld:srv:WG3] AllSequencers.cpp:527] onEpochMetaDataFromEpochStore() Activated a sequencer for log 4611686018427387898 (reason: GET_SEQ_STATE) with epoch 4, metadata: [E:4 (at 2021-09-17 02:14:10.200) since:1 (at 2021-09-17 02:10:14.514) R:[node: 2] V:2 flags:WRITTEN_IN_METADATALOG params:{target:127 seed:0 signature:d4a0e78fab29e4f6} N:{N0:S0,N1:S0,N2:S0,N3:S0,N4:S0} W:[]]. Activation Result: RECOVERY.
I0917 02:14:10.225835    1335 [ld:srv:WG1] Sequencer.cpp:126] completeActivationWithMetaData() Activating sequencer for log 13835058055282163706 epoch 4.
W0917 02:14:10.225960    1339 [ld:srv:WG3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.010s, source: [Request: COMPLETION]
I0917 02:14:10.226039    1333 [ld:srv:WG0] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 4611686018427387898 with next_epoch 4
I0917 02:14:10.226528    1458 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [maintenancelog] Tail lsn of delta log is e4n0
I0917 02:14:10.225041    1349 [ld:srv:WB1] ReplicatedStateMachine-inl.h:130] getSnapshot() [logsconfig] Fetching snapshot with ver:e0n1, (waiting_for_snapshot_:LSN_INVALID, version_:e0n1). sync_state_:0
I0917 02:14:10.228389    1335 [ld:srv:WG1] Sequencer.cpp:242] completeActivationWithMetaData() Historical epoch metadata for log 13835058055282163706: {[E:1 (at -inf) since:1 (at -inf) R:[node: 3] V:2 flags: params:{target:0 seed:0 signature:0} N:{N0:S0,N1:S0,N2:S0,N3:S0,N4:S0} W:[]], Until:4}.
I0917 02:14:10.233609    1335 [ld:srv:WG1] LogRecoveryRequest.cpp:390] start() Started LogRecoveryRequest of log 13835058055282163706 with next_epoch 4
I0917 02:14:10.228609    1339 [ld:srv:WG3] MetaDataLogTrimmer.cpp:115] schedulePeriodicTrimming() Will run periodic trimming every ~7200000 s for 4611686018427387898
I0917 02:14:10.254182    1335 [ld:srv:WG1] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [2, 3] of log 13835058055282163706
I0917 02:14:10.267473    1333 [ld:srv:WG0] LogRecoveryRequest.cpp:1018] sealLog() Starting recovery of epochs [2, 3] of log 4611686018427387898
I0917 02:14:10.318945    1458 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [eventlog] Tail lsn of delta log is e4n0
I0917 02:14:10.319142    1345 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from UNHEALTHY to HEALTHY
I0917 02:14:10.321776    1338 [ld:srv:WG2] ProtocolHandler.cpp:127] notifyErrorOnSocket() skipped at least 10 log entries
I0917 02:14:10.325553    1338 [ld:srv:WG2] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket N4:1(127.0.0.1:48313) hit error AsyncSocketException: recv() failed (peer=127.0.0.1:48313, local=127.0.0.1:45100), type = Internal error, errno = 104 (Connection reset by peer)
I0917 02:14:10.327006    1338 [ld:srv:WG2] GetSeqStateRequest.cpp:385] onSent() Failed to send GET_SEQ_STATE message to N4:1 for log:13835058055282163707. Reason: CONNFAILED: connection failed
I0917 02:14:10.334830    1338 [ld:srv:WG2] SequencerRouter.cpp:321] onDeadNode() Node N4:1 unavailable for log:13835058055282163707, status=CONNFAILED. request[type:GET_SEQ_STATE_REQ_TYPE, handler_:0x7efed27163a8]
I0917 02:14:10.345647    1458 [ld:srv:WB3] ClientReadStream.cpp:650] sendStart() Cannot send START message to N1:S1 for log 4611686018427387899: DISABLED: server is marked down
W0917 02:14:10.352822    1338 [ld:srv:WG2] SocketSender.cpp:348] sendMessageImpl() Unable to send a message of type CLEANED to WG2:C6 (127.0.0.1:52618): error NOTCONN
I0917 02:14:10.352985    1333 [ld:srv:WG0] GET_SEQ_STATE_Message.cpp:831] shouldRedirectOrFail() Returning status=REDIRECTED to [WG0:C19 (127.0.0.1:52812)] for log:13835058055282163707. Redirect target is Node N4:1
I0917 02:14:10.377662    1338 [ld:srv:WG2] SequencerRouter.cpp:149] onRedirected() Got redirected from N2:1 to N4:1 for log:13835058055282163707, status:REDIRECTED, request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7efed27163a8]
I0917 02:14:16.939457    2578 [logdeviced-main] main.cpp:399] main() Command line arguments: --local-log-store-path /data/store/N2:1/db --num-shards 2 --server-id wbpfjds7rg --log-file /data/store/N2:1/log --name Node2 --config-path file:/data/store/logdevice.conf --client-thrift-api-port 41075 --gossip-port 41069 --server-thrift-api-port 41074 --test-mode true --server-to-server-port 41073 --admin-port 41070 --loglevel info --port 41067 --sequencers lazy 
I0917 02:14:16.949530    2578 [logdeviced-main] main.cpp:403] main() Plugins loaded: {"Thrift client factory plugin":"built-in","ZookeeperClient factory":"built-in","ConfigSource factory":["built-in"],"PermissionChecker factory":"built-in","Build Info":"built-in","Plugin provider":["Built-in plugin provider","Static plug-in loader","Dynamic plugin loader"]}
I0917 02:14:16.953296    2578 [logdeviced-main] main.cpp:405] main() server starting
I0917 02:14:16.955217    2578 [logdeviced-main] main.cpp:410] main() version 99.99.99
I0917 02:14:16.960251    2578 [logdeviced-main] main.cpp:418] main() asserts off (NDEBUG set)
I0917 02:14:16.967529    2578 [logdeviced-main] TextConfigUpdater.cpp:56] fetchFromSource() Requesting main config "/data/store/logdevice.conf" (source: file)
I0917 02:14:16.977414    2578 [logdeviced-main] TextConfigUpdater.cpp:116] onContents() Main config from file, hash = 99e4033bvf
I0917 02:14:18.308661    2578 [logdeviced-main] Server.cpp:185] operator()() Updating settings from config took 1325ms
I0917 02:14:18.316604    2578 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 1333ms, config update: 0ms, notifications: 0ms
I0917 02:14:18.321755    2578 [logdeviced-main] TextConfigUpdater.cpp:306] pushServerConfig() Updated config (version: 1 - hash: 99e4033bvf)
I0917 02:14:18.333951    2578 [logdeviced-main] TextConfigUpdater.cpp:397] pushLogsConfig() Ignoring changes in the 'logs' section in the config file because LogsConfigManager is ENABLED
I0917 02:14:18.348120    2578 [logdeviced-main] TextConfigUpdater.cpp:174] update() Config update result: ServerConfig=updated, ZK=skipped, LogsConfig=updated
I0917 02:14:18.352140    2578 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:14:18.387790    2578 [logdeviced-main] NodesConfigurationInit.cpp:233] operator()() Fetching initial nodes configuration (Attempt 1)...
I0917 02:14:18.400507    2828 [ld:file-ncs] NodesConfigurationInit.cpp:290] operator()() Got a NodesConfiguration of version: 5
I0917 02:14:18.412973    2828 [ld:file-ncs] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:18.423620    2578 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:18.433826    2578 [logdeviced-main] Server.cpp:510] init() My Node ID is N2:1
I0917 02:14:18.439240    2578 [logdeviced-main] Server.cpp:517] init() My version is 0
I0917 02:14:18.444646    2578 [logdeviced-main] NoopTraceLogger.cpp:22] NoopTraceLogger() NOOP TraceLogger is ON, no trace samples will be published.
I0917 02:14:18.463225    2578 [logdeviced-main] FileBasedVersionedConfigStore.cpp:46] stopAndJoin() FileBasedVersionedConfigStore threads stopped.
I0917 02:14:18.466742    2578 [logdeviced-main] main.cpp:144] set_fd_limit() Limit on number of file descriptors is 1048576
W0917 02:14:18.472821    2578 [logdeviced-main] main.cpp:192] drop_root() Running under root, but no --user command line option specified. Will keep running as root
I0917 02:14:18.483654    2578 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 41067
I0917 02:14:18.489486    2578 [logdeviced-main] Server.cpp:781] initListeners() Initializing a gossip listener.
I0917 02:14:18.495173    2578 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 41069
I0917 02:14:18.506727    2578 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 41073 (SSL)
I0917 02:14:18.511788    2578 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 41077 (SSL)
I0917 02:14:18.515081    2578 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 41076 (SSL)
I0917 02:14:18.631099    2913 [io-stall:s0] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 0
I0917 02:14:18.631351    2914 [io-stall:s1] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 1
I0917 02:14:18.635345    2578 [logdeviced-main] RocksDBLogStoreConfig.cpp:162] RocksDBLogStoreConfig() LD manages flushes and all memory budgets on the node. atomic_flush is set to true.
I0917 02:14:18.700954    2928 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:18.701488    2927 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:19.588323    2928 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard1/000054.log.trash as trash -- OK
I0917 02:14:19.618801    2929 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N2:1/db/shard1/000054.log.trash
I0917 02:14:19.712882    2927 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000056.log.trash as trash -- OK
I0917 02:14:19.723991    2930 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N2:1/db/shard0/000056.log.trash
I0917 02:14:19.755082    2928 [ld:open-rocks1] PartitionedRocksDBStore.cpp:891] open() Partition s1:1000000 is under-replicated: Start:2021-09-17 02:10:15.557, Min:2021-09-17 02:10:05.557, Max: 2021-09-17 02:10:25.557
I0917 02:14:19.759073    2928 [ld:open-rocks1] PartitionedRocksDBStore.cpp:897] open() Shard[1] dirty ranges: [A:{{[2021-09-17 02:10:05.557,2021-09-17 02:10:25.557]}}]
I0917 02:14:19.798762    2928 [ld:open-rocks1] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.002s. Read 7 records, 425 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:19.833314    2927 [ld:open-rocks0] PartitionedRocksDBStore.cpp:891] open() Partition s0:1000000 is under-replicated: Start:2021-09-17 02:10:15.550, Min:2021-09-17 02:10:05.550, Max: 2021-09-17 02:10:25.550
I0917 02:14:19.837449    2927 [ld:open-rocks0] PartitionedRocksDBStore.cpp:897] open() Shard[0] dirty ranges: [A:{{[2021-09-17 02:10:05.550,2021-09-17 02:10:25.550]}}]
I0917 02:14:19.867581    2927 [ld:open-rocks0] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.001s. Read 6 records, 448 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:20.033023    3304 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 13ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:14:20.049795    2920 [rocks-high-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard1/000060.log.trash as trash -- OK
I0917 02:14:20.053300    2919 [rocks-high-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000062.log.trash as trash -- OK
I0917 02:14:20.076665    2930 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N2:1/db/shard0/000062.log.trash
I0917 02:14:20.080388    2929 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N2:1/db/shard1/000060.log.trash
I0917 02:14:20.077411    2927 [ld:open-rocks0] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N2:1/db/shard0 in 1363 ms
I0917 02:14:20.083346    2928 [ld:open-rocks1] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N2:1/db/shard1 in 1377 ms
I0917 02:14:20.131890    2578 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:691] printDiskShardMapping() Disk -> Shard mapping: /data/store/N2:1/db/shard0 -> [0,1]
I0917 02:14:20.135131    2578 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:285] init() Initialized sharded RocksDB instance at /data/store/N2:1/db with 2 shards
E0917 02:14:20.148763    3429 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState1"!
I0917 02:14:20.150379    2917 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000066.sst.trash as trash -- OK
E0917 02:14:20.151032    3428 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState0"!
I0917 02:14:20.169831    2917 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000060.sst.trash as trash -- OK
I0917 02:14:20.177797    2578 [logdeviced-main] Server.cpp:1173] initLogStorageStateMap() Populating log storage state map successful.
I0917 02:14:20.184469    2930 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N2:1/db/shard0/000066.sst.trash
I0917 02:14:20.198938    2917 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000057.sst.trash as trash -- OK
I0917 02:14:20.204914    2930 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 21after deleting file /data/store/N2:1/db/shard0/000060.sst.trash
E0917 02:14:20.211034    2578 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.227428    2930 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 30after deleting file /data/store/N2:1/db/shard0/000057.sst.trash
I0917 02:14:20.229710    2578 [logdeviced-main] RecordCacheMonitorThread.cpp:27] RecordCacheMonitorThread() Record cache monitor thread started.
I0917 02:14:20.247478    2578 [logdeviced-main] ClusterState.cpp:356] resizeClusterState() Cluster state size updated from 0 to 5
I0917 02:14:20.231694    3465 [ld:cache-evict] RecordCacheMonitorThread.cpp:44] threadMain() Record cache eviction thread started. Size limit is set to 4294967296 bytes.
I0917 02:14:20.247294    2917 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000055.sst.trash as trash -- OK
E0917 02:14:20.259381    2578 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.290005    2930 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N2:1/db/shard0/000055.sst.trash
E0917 02:14:20.302664    2578 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.312681    2917 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000049.sst.trash as trash -- OK
E0917 02:14:20.313430    2578 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:20.323824    2578 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.336301    2917 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000047.sst.trash as trash -- OK
E0917 02:14:20.339522    2578 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.352749    2930 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N2:1/db/shard0/000049.sst.trash
I0917 02:14:20.357975    2578 [logdeviced-main] Processor.cpp:247] init() Initialized 5 workers of type GENERAL
I0917 02:14:20.375644    2917 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000041.sst.trash as trash -- OK
I0917 02:14:20.379543    2930 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 20after deleting file /data/store/N2:1/db/shard0/000047.sst.trash
E0917 02:14:20.380426    2578 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.396703    2917 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000038.sst.trash as trash -- OK
I0917 02:14:20.397610    2578 [logdeviced-main] Processor.cpp:247] init() Initialized 1 workers of type FAILURE_DETECTOR
I0917 02:14:20.407397    2930 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 10after deleting file /data/store/N2:1/db/shard0/000041.sst.trash
E0917 02:14:20.418705    2578 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.448408    2917 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000036.sst.trash as trash -- OK
I0917 02:14:20.456626    2930 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 9after deleting file /data/store/N2:1/db/shard0/000038.sst.trash
E0917 02:14:20.458087    2578 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.476900    2917 [rocks-low-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000029.sst.trash as trash -- OK
E0917 02:14:20.484083    2578 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.496340    2930 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 19after deleting file /data/store/N2:1/db/shard0/000036.sst.trash
E0917 02:14:20.527915    2578 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:20.531595    2930 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 32after deleting file /data/store/N2:1/db/shard0/000029.sst.trash
I0917 02:14:20.550979    2578 [logdeviced-main] Processor.cpp:247] init() Initialized 4 workers of type BACKGROUND
I0917 02:14:20.573710    2578 [logdeviced-main] FailureDetector.cpp:139] FailureDetector() Failure Detector created with instance id: 1631844860573
I0917 02:14:20.579016    2578 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N0 changed from UNKNOWN to DEAD
I0917 02:14:20.585607    2578 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from HEALTHY to UNHEALTHY
I0917 02:14:20.588947    2578 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N1 changed from UNKNOWN to DEAD
I0917 02:14:20.596906    2578 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from HEALTHY to UNHEALTHY
I0917 02:14:20.602386    2578 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N2 changed from UNKNOWN to DEAD
I0917 02:14:20.607452    2578 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from HEALTHY to UNHEALTHY
I0917 02:14:20.610308    2578 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N3 changed from UNKNOWN to DEAD
I0917 02:14:20.613571    2578 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from HEALTHY to UNHEALTHY
I0917 02:14:20.627712    2578 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N4 changed from UNKNOWN to DEAD
I0917 02:14:20.631614    2578 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from HEALTHY to UNHEALTHY
W0917 02:14:20.641498    3473 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 68 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967298), p :HI_PRI
W0917 02:14:20.653676    3466 [ld:srv:WG0] Worker.cpp:1322] processRequest() Request queued for 80 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967296), p :HI_PRI
W0917 02:14:20.688850    3471 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 103 msec: NODE_STATE_UPDATED (id: 4294967302), p :LO_PRI
W0917 02:14:20.696319    3471 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 110 msec: NODE_STATE_UPDATED (id: 4294967308), p :LO_PRI
W0917 02:14:20.701339    3471 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 104 msec: NODE_STATE_UPDATED (id: 4294967312), p :LO_PRI
W0917 02:14:20.713890    3471 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 117 msec: NODE_STATE_UPDATED (id: 4294967318), p :LO_PRI
W0917 02:14:20.725406    3471 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 118 msec: NODE_STATE_UPDATED (id: 4294967322), p :LO_PRI
W0917 02:14:20.731422    3471 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 124 msec: NODE_STATE_UPDATED (id: 4294967328), p :LO_PRI
W0917 02:14:20.739434    3471 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 126 msec: NODE_STATE_UPDATED (id: 4294967332), p :LO_PRI
W0917 02:14:20.747578    3471 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 133 msec: NODE_STATE_UPDATED (id: 4294967338), p :LO_PRI
W0917 02:14:20.751464    3475 [ld:srv:WG3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.038s, source: [Request: NODE_STATE_UPDATED]
I0917 02:14:20.821406    2578 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:14:20.828035    3490 [ld:srv:WB2] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:14:20.835698    3490 [ld:srv:WB2] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 8ms
W0917 02:14:20.854799    3490 [ld:srv:WB2] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.028s, source: [Request: NODES_CONFIGURATION_MANAGER]
I0917 02:14:20.872334    3490 [ld:srv:WB2] NodesConfigurationManager.cpp:507] onProcessingFinished() Updated local nodes config to version 5...
I0917 02:14:20.878685    3452 [ld:s0:default:0] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:20.882673    3452 [ld:s0:default:0] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 0, totaling 0 bytes.
I0917 02:14:20.883513    3462 [ld:s1:default:1] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:20.910364    3462 [ld:s1:default:1] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 1, totaling 0 bytes.
I0917 02:14:20.935030    2578 [logdeviced-main] Server.cpp:1319] initSequencers() Initializing FileEpochStore
I0917 02:14:20.939039    2578 [logdeviced-main] Server.cpp:1398] initSequencerPlacement() using SequencerOptions::LAZY
I0917 02:14:20.944695    2578 [logdeviced-main] Server.cpp:1430] initRebuildingCoordinator() Initializing EventLog RSM and RebuildingCoordinator
I0917 02:14:20.951942    2578 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387903)
I0917 02:14:20.963398    2578 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387903, is_server:1)
I0917 02:14:20.972674    2578 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:20.979357    2578 [logdeviced-main] Server.cpp:1467] initRebuildingCoordinator() Starting RebuildingSupervisor
I0917 02:14:20.982990    2578 [logdeviced-main] Server.cpp:1480] initRebuildingCoordinator() Starting RebuildingCoordinator
I0917 02:14:20.984994    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:62] init() Starting Rebuilding Supervisor
I0917 02:14:21.017933    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N4 to execute in 1200s
I0917 02:14:21.023816    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N3 to execute in 1200s
I0917 02:14:21.047048    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N1 to execute in 1200s
I0917 02:14:21.050931    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N0 to execute in 1200s
I0917 02:14:21.031332    2578 [logdeviced-main] LogStoreMonitor.cpp:190] start() Logstore monitoring thread started.
I0917 02:14:21.061765    2578 [logdeviced-main] UnreleasedRecordDetector.cpp:106] start() Unreleased record detector thread started.
I0917 02:14:21.032611    3494 [ld:srv:WB3] RebuildingCoordinator.cpp:309] subscribeToEventLogIfNeeded() RebuildingCoordinator did not start yet because LogsConfig is not fully loaded yet
I0917 02:14:21.085827    3494 [ld:srv:WB3] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.053s to write().
W0917 02:14:21.054401    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:705] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:14:21.092637    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:14:21.078763    2578 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387901)
I0917 02:14:21.102810    2578 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387901, is_server:1)
I0917 02:14:21.087940    3494 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [eventlog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:21.095867    3352 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:14:21.104985    2578 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:21.121969    3485 [ld:srv:WB1] LogsConfigManager.cpp:38] execute() Starting LogsConfigManager on Worker 1 in pool: BACKGROUND
I0917 02:14:21.108068    3494 [ld:srv:WB3] EventLogStateMachine.cpp:146] gotInitialState() Got base rebuilding set: {}
I0917 02:14:21.111998    3352 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:14:21.126687    3485 [ld:srv:WB1] LogsConfigManager.cpp:165] start() Starting LogsConfig Manager RSM
I0917 02:14:21.153425    3485 [ld:srv:WB1] LogsConfigManager.cpp:206] start() Starting LogsConfig Replicated State Machine
I0917 02:14:21.139068    3494 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [eventlog] Retrieving tail lsn of delta log...
I0917 02:14:21.159608    3485 [ld:srv:WB1] ReplicatedStateMachine-inl.h:38] startFetchingSnapshot() [logsconfig] Using RSMSnapshotStore...
I0917 02:14:21.176573    3485 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1294] initSnapshotFetchTimer() [logsconfig] Creating timer to fetch snapshots ...
I0917 02:14:21.169878    3494 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [maintenancelog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:21.195250    3494 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [maintenancelog] Retrieving tail lsn of delta log...
E0917 02:14:21.200233    3477 [ld:srv:WG4] SequencerRouter.cpp:56] operator()() Error during sequencer lookup for log 4611686018427387899 (NOSEQUENCER), reporting NOSEQUENCER.
E0917 02:14:21.170510    3475 [ld:srv:WG3] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387903. All sequencer nodes are unavailable.
I0917 02:14:21.221273    3475 [ld:srv:WG3] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.051s to write().
I0917 02:14:21.196842    2578 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server LogDevice Admin API Service will listen on port 41070
E0917 02:14:21.203032    3477 [ld:srv:WG4] SequencerRouter.cpp:105] onFailure() Error during sequencer routing for log 4611686018427387899 (NOSEQUENCER), request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7f95e15ab1e8].
W0917 02:14:21.245399    3477 [ld:srv:WG4] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387899 (rqid:25769803779, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
W0917 02:14:21.224764    3475 [ld:srv:WG3] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387903, rqid:25769803777, ctx:rsm, err(NOSEQUENCER)
W0917 02:14:21.261592    3475 [ld:srv:WG3] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387903 (rqid:25769803777, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
I0917 02:14:21.238703    2578 [logdeviced-main] Server.cpp:1540] createAndAttachMaintenanceManager() Not initializing MaintenanceManager since it is disabled in settings
E0917 02:14:21.260153    3494 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:25769803779) for log:4611686018427387899, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:14:21.275860    2578 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: s2s-api
E0917 02:14:21.278198    3494 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:25769803777) for log:4611686018427387903, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:14:21.284426    2578 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server s2s-api will listen on port 41074
I0917 02:14:21.297962    2578 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: c2s-api
I0917 02:14:21.303020    2578 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server c2s-api will listen on port 41075
I0917 02:14:21.315753    2578 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:21.328032    2890 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:21.336566    2578 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:21.342510    2891 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:21.347447    2578 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server s2s-api
I0917 02:14:21.347659    3479 [ld:srv:WF0] FailureDetector.cpp:228] startGetClusterState() Sending GET_CLUSTER_STATE to build initial FD cluster view
I0917 02:14:21.355651    3479 [ld:srv:WF0] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket N3:1(127.0.0.1:41058) hit error AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused)
I0917 02:14:21.400824    2578 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server c2s-api
I0917 02:14:21.423605    3479 [ld:srv:WF0] FailureDetector.cpp:267] operator()() Cluster state received with 5 dead nodes (N0,N1,N2,N3,N4) and 0 boycotted nodes ()
I0917 02:14:21.451052    3479 [ld:srv:WF0] FailureDetector.cpp:288] buildInitialState() Wait over (cluster state received)
I0917 02:14:21.455502    3479 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from DEAD to STARTING
I0917 02:14:21.455812    2578 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server LogDevice Admin API Service
I0917 02:14:21.479012    3461 [ld:s1:default:0] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 4611686018427387899 epoch 2: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 2.
I0917 02:14:21.566046    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N0
I0917 02:14:21.583538    2578 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:21.599442    3479 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N0 transitioned to ALIVE
I0917 02:14:21.601570    3479 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N1 changed from DEAD to STARTING
I0917 02:14:21.604129    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N1
I0917 02:14:21.607363    3479 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N1 transitioned to ALIVE
I0917 02:14:21.608847    3479 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N3 transitioned to DEAD
I0917 02:14:21.611090    3479 [ld:srv:WF0] FailureDetector.cpp:316] buildInitialState() N4 transitioned to DEAD
I0917 02:14:21.613380    3479 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N0 transitioned to UNHEALTHY (status)
I0917 02:14:21.614909    3479 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N1 transitioned to UNHEALTHY (status)
I0917 02:14:21.617417    3479 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N3 transitioned to UNHEALTHY (status)
I0917 02:14:21.623536    2892 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:21.651455    2578 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:21.655206    2890 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:21.660775    2578 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:21.663848    2890 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:21.671254    2578 [logdeviced-main] main.cpp:464] main() Listeners initialized
I0917 02:14:21.623561    3479 [ld:srv:WF0] FailureDetector.cpp:334] buildInitialState() N4 transitioned to UNHEALTHY (status)
I0917 02:14:21.661347    3475 [ld:srv:WG3] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 4611686018427387899 epoch 2: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 2.
W0917 02:14:21.753726    3473 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() skipped at least 10 log entries
W0917 02:14:21.761921    3473 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.015s, source: [Message sent/received: CLEAN]
I0917 02:14:21.681998    3479 [ld:srv:WF0] debug.cpp:573] log() Slow log() call: it took 0.000s to prepare, 0.058s to write().
I0917 02:14:21.779433    3479 [ld:srv:WF0] FailureDetector.cpp:344] buildInitialState() Initializing DomainIsolationChecker
I0917 02:14:21.782674    3479 [ld:srv:WF0] FailureDetector.cpp:915] startSuspectTimer() Starting suspect state timer
I0917 02:14:21.786425    3479 [ld:srv:WF0] FailureDetector.cpp:1285] updateNodeState() N2 transitioned from DEAD to ALIVE, FD State:(gossip: 0, instance-id: 0, failover: 0, starting: 1)
I0917 02:14:21.788396    3479 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from DEAD to STARTING
E0917 02:14:21.786862    3473 [ld:srv:WG2] WeightedCopySetSelector.cpp:1241] augment() Failed to select 3 nodes for rebuilding for log 13835058055282163711 because too many whole NODEs are unavailable. Copyset: []. Useful existing copies: 0. Nodeset: {N0:S1,N1:S1,N2:S1,N3:S1,N4:S1}. Unavailable nodes: {N4:S1,N3:S1,N2:S1}. Secondary replication: 3. NODE weights: [0.000(2.000-2.000), 0.000(2.000-2.000), 2.000, 0.000(2.000-2.000), 2.000]
E0917 02:14:21.801924    3473 [ld:srv:WG2] NodeSetAccessor.cpp:224] pickWaveFromCopySet() Failed to pick a copyset for log 13835058055282163711, given exisiting nodes .
I0917 02:14:21.795433    3479 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting suspect-state-finished message.
I0917 02:14:21.810837    3479 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844860573 to node WF0:N4:1 (UNKNOWN)
W0917 02:14:21.804826    3473 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.040s, source: [Request: MISC]
I0917 02:14:21.817455    3479 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844860573 to node WF0:N3:1 (127.0.0.1:41058)
I0917 02:14:21.832884    3479 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting bringup message.
I0917 02:14:21.837869    3479 [ld:srv:WF0] FailureDetector.cpp:937] startGossiping() Start Gossiping.
I0917 02:14:21.846083    3479 [ld:srv:WF0] FailureDetector.cpp:925] operator()() Suspect timeout expired
I0917 02:14:21.879017    3475 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163708 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:21.881623    3475 [ld:srv:WG3] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 4611686018427387899 epoch 2: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 2.
I0917 02:14:21.906355    3477 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387903 has already been cleaned. No purge needed. last clean epoch: 3, purge to: 3.
I0917 02:14:21.953032    3479 [ld:srv:WF0] FailureDetector.cpp:1285] updateNodeState() N4 transitioned from DEAD to ALIVE, FD State:(gossip: 2, instance-id: 1631844860532, failover: 0, starting: 1)
I0917 02:14:21.956141    3479 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from DEAD to STARTING
I0917 02:14:21.960844    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N4
W0917 02:14:21.963329    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:734] adjustRebuildingThrottle() Exiting throttling mode: #draining=0, #rebuilding=0, #triggers=1, #adjusted cluster size=5, threshold=35%, actual=20%
I0917 02:14:21.965876    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:751] adjustRebuildingThrottle() Not triggering new rebuildings until 2021-09-17 02:34:21.965: It's too soon after exiting throttling mode
I0917 02:14:21.982685    3475 [ld:srv:WG3] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [1, 1] for log 13835058055282163708.
I0917 02:14:21.993422    3479 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N3:1 (127.0.0.1:41058): CONNFAILED: connection failed. Trying another node.
I0917 02:14:22.196575    3485 [ld:srv:WB1] ReplicatedStateMachine-inl.h:130] getSnapshot() [logsconfig] Fetching snapshot with ver:e0n1, (waiting_for_snapshot_:LSN_INVALID, version_:e0n1). sync_state_:0
I0917 02:14:22.315944    3494 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [eventlog] Tail lsn of delta log is e7n0
I0917 02:14:22.412072    3494 [ld:srv:WB3] ProtocolHandler.cpp:127] notifyErrorOnSocket() skipped at least 10 log entries
I0917 02:14:22.417850    3494 [ld:srv:WB3] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket N3:1(127.0.0.1:41056) hit error AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused)
I0917 02:14:22.494368    3477 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163707 has already been cleaned. No purge needed. last clean epoch: 2, purge to: 2.
I0917 02:14:22.606273    3466 [ld:srv:WG0] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163708 has already been cleaned. No purge needed. last clean epoch: 2, purge to: 2.
I0917 02:14:22.845103    3477 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163707 has already been cleaned. No purge needed. last clean epoch: 3, purge to: 3.
I0917 02:14:22.952790    3466 [ld:srv:WG0] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163708 has already been cleaned. No purge needed. last clean epoch: 3, purge to: 3.
I0917 02:14:23.061455    3466 [ld:srv:WG0] PurgeUncleanEpochs.cpp:592] complete() skipped at least 4 log entries
I0917 02:14:23.063420    3466 [ld:srv:WG0] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [3, 3] for log 13835058055282163708.
W0917 02:14:23.216484    3479 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() skipped at least 7 log entries
W0917 02:14:23.219729    3479 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.016s, source: [Message sent/received: GOSSIP]
I0917 02:14:23.222939    3479 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() skipped at least 4 log entries
I0917 02:14:23.225280    3477 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163707 has already been cleaned. No purge needed. last clean epoch: 4, purge to: 4.
I0917 02:14:23.230329    3479 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N3:1 (127.0.0.1:41058): CONNFAILED: connection failed. Trying another node.
W0917 02:14:23.235840    3479 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.013s, source: [Message sent/received: GOSSIP]
I0917 02:14:23.400247    3466 [ld:srv:WG0] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163708 has already been cleaned. No purge needed. last clean epoch: 4, purge to: 4.
I0917 02:14:23.497284    3475 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387903 has already been cleaned. No purge needed. last clean epoch: 4, purge to: 4.
I0917 02:14:23.510270    3473 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163706 has already been cleaned. No purge needed. last clean epoch: 1, purge to: 1.
I0917 02:14:23.654354    3471 [ld:srv:WG1] GET_SEQ_STATE_Message.cpp:831] shouldRedirectOrFail() Returning status=REDIRECTED to [WG1:C12 (127.0.0.1:37422)] for log:13835058055282163707. Redirect target is Node N1:1
I0917 02:14:23.666597    3473 [ld:srv:WG2] GetSeqStateRequest.cpp:531] onReplyTimeout() Timed out waiting for GET_SEQ_STATE_REPLY for GetSeqStateRequest (rqid:55834574848, ctx:start-message) for log:13835058055282163707 from node N1:1
I0917 02:14:23.667944    3473 [ld:srv:WG2] SequencerRouter.cpp:321] onDeadNode() Node N1:1 unavailable for log:13835058055282163707, status=TIMEDOUT. request[type:GET_SEQ_STATE_REQ_TYPE, handler_:0x7f95e79fc628]
I0917 02:14:23.670948    3473 [ld:srv:WG2] GetSeqStateRequest.cpp:385] onSent() Failed to send GET_SEQ_STATE message to N4:1 for log:13835058055282163707. Reason: CONNFAILED: connection failed
I0917 02:14:23.673012    3473 [ld:srv:WG2] SequencerRouter.cpp:321] onDeadNode() Node N4:1 unavailable for log:13835058055282163707, status=CONNFAILED. request[type:GET_SEQ_STATE_REQ_TYPE, handler_:0x7f95e79fc628]
I0917 02:14:23.677234    3473 [ld:srv:WG2] GET_SEQ_STATE_Message.cpp:831] shouldRedirectOrFail() Returning status=REDIRECTED to [WG2:C16 (127.0.0.1:37536)] for log:13835058055282163707. Redirect target is Node N1:1
I0917 02:14:23.679469    3473 [ld:srv:WG2] SequencerRouter.cpp:149] onRedirected() Got redirected from N2:1 to N1:1 for log:13835058055282163707, status:REDIRECTED, request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7f95e79fc628]
I0917 02:14:24.180277    3494 [ld:srv:WB3] ClientReadStream.cpp:650] sendStart() Cannot send START message to N3:S1 for log 13835058055282163711: DISABLED: server is marked down
I0917 02:14:24.190528    3494 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 2 is not available. Highest epoch known is 1.
I0917 02:14:24.206048    3494 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 3 is not available. Highest epoch known is 1.
I0917 02:14:24.229128    3494 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 5 is not available. Highest epoch known is 1.
I0917 02:14:24.244912    3494 [ld:srv:WB3] ClientReadStream.cpp:650] sendStart() skipped at least 10 log entries
I0917 02:14:24.249695    3494 [ld:srv:WB3] ClientReadStream.cpp:650] sendStart() Cannot send START message to N3:S1 for log 13835058055282163711: DISABLED: server is marked down
I0917 02:14:24.258000    3494 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 6 is not available. Highest epoch known is 1.
I0917 02:14:24.276652    3494 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 7 is not available. Highest epoch known is 1.
I0917 02:14:24.278919    3494 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [eventlog] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:14:24.286267    3494 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (1)
I0917 02:14:24.285816    3479 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() skipped at least 2 log entries
W0917 02:14:24.288297    3494 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() skipped at least 1 log entries
W0917 02:14:24.294250    3494 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.012s, source: [Message sent/received: GAP]
I0917 02:14:24.292831    3479 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N4:1 (127.0.0.1:41047): CONNFAILED: connection failed. Trying another node.
W0917 02:14:24.299390    3479 [ld:srv:WF0] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.014s, source: [Message sent/received: GOSSIP]
I0917 02:14:24.350014    3471 [ld:srv:WG1] GetSeqStateRequest.cpp:531] onReplyTimeout() Timed out waiting for GET_SEQ_STATE_REPLY for GetSeqStateRequest (rqid:55834574850, ctx:start-message) for log:13835058055282163711 from node N0:1
I0917 02:14:24.352621    3471 [ld:srv:WG1] SequencerRouter.cpp:321] onDeadNode() Node N0:1 unavailable for log:13835058055282163711, status=TIMEDOUT. request[type:GET_SEQ_STATE_REQ_TYPE, handler_:0x7f95e79fd268]
I0917 02:14:24.375043    3471 [ld:srv:WG1] SequencerRouter.cpp:149] onRedirected() Got redirected from N1:1 to N0:1 for log:13835058055282163711, status:REDIRECTED, request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7f95e79fd268]
I0917 02:14:24.419059    3473 [ld:srv:WG2] PurgeUncleanEpochs.cpp:592] complete() skipped at least 7 log entries
I0917 02:14:24.421522    3473 [ld:srv:WG2] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [3, 3] for log 13835058055282163706.
I0917 02:14:25.147133    3479 [ld:srv:WF0] FailureDetector.cpp:1285] updateNodeState() N4 transitioned from ALIVE to DEAD, FD State:(gossip: 31, instance-id: 1631844860532, failover: 0, starting: 1)
I0917 02:14:25.149091    3479 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from STARTING to DEAD
I0917 02:14:25.151914    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N4 to execute in 1200s
W0917 02:14:25.157376    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:705] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=2, #adjusted cluster size=5, threshold=35%, actual=40%
I0917 02:14:25.163029    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() skipped at least 2 log entries
I0917 02:14:25.165859    3477 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=2, #adjusted cluster size=5, threshold=35%, actual=40%
I0917 02:14:25.319912    3494 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [maintenancelog] Tail lsn of delta log is e6n0
I0917 02:14:25.323236    3494 [ld:srv:WB3] ClientReadStream.cpp:650] sendStart() skipped at least 5 log entries
I0917 02:14:25.325073    3494 [ld:srv:WB3] ClientReadStream.cpp:650] sendStart() Cannot send START message to N3:S1 for log 13835058055282163707: DISABLED: server is marked down
E0917 02:14:25.328442    3473 [ld:srv:WG2] NodeSetAccessor.cpp:224] pickWaveFromCopySet() Failed to pick a copyset for log 13835058055282163711, given exisiting nodes .
I0917 02:14:25.468670    3479 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() skipped at least 5 log entries
I0917 02:14:25.470667    3479 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N4:1 (127.0.0.1:41047): CONNFAILED: connection failed. Trying another node.
I0917 02:14:25.508790    3494 [ld:srv:WB3] ClientReadStream.cpp:650] sendStart() skipped at least 10 log entries
I0917 02:14:25.510509    3494 [ld:srv:WB3] ClientReadStream.cpp:650] sendStart() Cannot send START message to N4:S1 for log 4611686018427387899: DISABLED: server is marked down
I0917 02:14:30.305340    4397 [logdeviced-main] main.cpp:399] main() Command line arguments: --local-log-store-path /data/store/N2:1/db --num-shards 2 --server-id 05csnhrdxt --log-file /data/store/N2:1/log --name Node2 --config-path file:/data/store/logdevice.conf --client-thrift-api-port 48438 --gossip-port 48432 --server-thrift-api-port 48437 --test-mode true --server-to-server-port 48436 --admin-port 48433 --loglevel info --port 48430 --sequencers lazy 
I0917 02:14:30.306865    4397 [logdeviced-main] main.cpp:403] main() Plugins loaded: {"Thrift client factory plugin":"built-in","ZookeeperClient factory":"built-in","ConfigSource factory":["built-in"],"PermissionChecker factory":"built-in","Build Info":"built-in","Plugin provider":["Built-in plugin provider","Static plug-in loader","Dynamic plugin loader"]}
I0917 02:14:30.307693    4397 [logdeviced-main] main.cpp:405] main() server starting
I0917 02:14:30.308291    4397 [logdeviced-main] main.cpp:410] main() version 99.99.99
I0917 02:14:30.309107    4397 [logdeviced-main] main.cpp:418] main() asserts off (NDEBUG set)
I0917 02:14:30.311416    4397 [logdeviced-main] TextConfigUpdater.cpp:56] fetchFromSource() Requesting main config "/data/store/logdevice.conf" (source: file)
I0917 02:14:30.313309    4397 [logdeviced-main] TextConfigUpdater.cpp:116] onContents() Main config from file, hash = ndhqu97h59
I0917 02:14:30.552876    4397 [logdeviced-main] Server.cpp:185] operator()() Updating settings from config took 238ms
I0917 02:14:30.553686    4397 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 238ms, config update: 0ms, notifications: 0ms
I0917 02:14:30.554395    4397 [logdeviced-main] TextConfigUpdater.cpp:306] pushServerConfig() Updated config (version: 1 - hash: ndhqu97h59)
I0917 02:14:30.555120    4397 [logdeviced-main] TextConfigUpdater.cpp:397] pushLogsConfig() Ignoring changes in the 'logs' section in the config file because LogsConfigManager is ENABLED
I0917 02:14:30.555987    4397 [logdeviced-main] TextConfigUpdater.cpp:174] update() Config update result: ServerConfig=updated, ZK=skipped, LogsConfig=updated
I0917 02:14:30.556866    4397 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
I0917 02:14:30.559650    4397 [logdeviced-main] NodesConfigurationInit.cpp:233] operator()() Fetching initial nodes configuration (Attempt 1)...
I0917 02:14:30.562933    4417 [ld:file-ncs] NodesConfigurationInit.cpp:290] operator()() Got a NodesConfiguration of version: 5
I0917 02:14:30.564176    4417 [ld:file-ncs] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:30.565203    4397 [logdeviced-main] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 0ms
I0917 02:14:30.565929    4397 [logdeviced-main] Server.cpp:510] init() My Node ID is N2:1
I0917 02:14:30.566725    4397 [logdeviced-main] Server.cpp:517] init() My version is 0
I0917 02:14:30.567427    4397 [logdeviced-main] NoopTraceLogger.cpp:22] NoopTraceLogger() NOOP TraceLogger is ON, no trace samples will be published.
I0917 02:14:30.569701    4397 [logdeviced-main] FileBasedVersionedConfigStore.cpp:46] stopAndJoin() FileBasedVersionedConfigStore threads stopped.
I0917 02:14:30.570511    4397 [logdeviced-main] main.cpp:144] set_fd_limit() Limit on number of file descriptors is 1048576
W0917 02:14:30.571358    4397 [logdeviced-main] main.cpp:192] drop_root() Running under root, but no --user command line option specified. Will keep running as root
I0917 02:14:30.578891    4397 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48430
I0917 02:14:30.581002    4397 [logdeviced-main] Server.cpp:781] initListeners() Initializing a gossip listener.
I0917 02:14:30.582388    4397 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48432
I0917 02:14:30.595106    4397 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48436 (SSL)
I0917 02:14:30.596733    4397 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48440 (SSL)
I0917 02:14:30.597708    4397 [logdeviced-main] Listener.cpp:31] Listener() Created Listener: port 48439 (SSL)
I0917 02:14:30.616484    4397 [logdeviced-main] RocksDBLogStoreConfig.cpp:162] RocksDBLogStoreConfig() LD manages flushes and all memory budgets on the node. atomic_flush is set to true.
I0917 02:14:30.617051    4425 [io-stall:s0] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 0
I0917 02:14:30.627375    4434 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:30.627508    4426 [io-stall:s1] IOTracing.cpp:83] stallDetectionThreadMain() Started IO stall detection thread for shard 1
I0917 02:14:30.633279    4433 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:387] Created background thread for deletion scheduler with rate_bytes_per_sec: 100000000
I0917 02:14:30.881717    4433 [ld:open-rocks0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000076.log.trash as trash -- OK
I0917 02:14:30.896065    4435 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N2:1/db/shard0/000076.log.trash
I0917 02:14:30.948291    4434 [ld:open-rocks1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard1/000075.log.trash as trash -- OK
I0917 02:14:30.958541    4433 [ld:open-rocks0] PartitionedRocksDBStore.cpp:891] open() Partition s0:1000000 is under-replicated: Start:2021-09-17 02:10:15.550, Min:2021-09-17 02:10:00.550, Max: 2021-09-17 02:10:30.550
I0917 02:14:30.960381    4433 [ld:open-rocks0] PartitionedRocksDBStore.cpp:897] open() Shard[0] dirty ranges: [A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:30.963015    4436 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 0after deleting file /data/store/N2:1/db/shard1/000075.log.trash
I0917 02:14:30.972857    4433 [ld:open-rocks0] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.004s. Read 6 records, 448 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:31.011120    4434 [ld:open-rocks1] PartitionedRocksDBStore.cpp:891] open() Partition s1:1000000 is under-replicated: Start:2021-09-17 02:10:15.557, Min:2021-09-17 02:10:00.557, Max: 2021-09-17 02:10:30.557
I0917 02:14:31.013852    4434 [ld:open-rocks1] PartitionedRocksDBStore.cpp:897] open() Shard[1] dirty ranges: [A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:31.026302    4434 [ld:open-rocks1] PartitionedRocksDBStore.cpp:1491] convertDataKeyFormat() DataKey format conversion took 0.001s. Read 11 records, 677 bytes. Wrote 0 records, 0 bytes.
I0917 02:14:31.073730    4432 [rocks-high-0] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard0/000082.log.trash as trash -- OK
I0917 02:14:31.079308    4435 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N2:1/db/shard0/000082.log.trash
I0917 02:14:31.079860    4433 [ld:open-rocks0] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N2:1/db/shard0 in 444 ms
I0917 02:14:31.081872    4431 [rocks-high-1] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:84] Mark file: /data/store/N2:1/db/shard1/000081.log.trash as trash -- OK
I0917 02:14:31.086034    4434 [ld:open-rocks1] ShardedRocksDBLocalLogStore.cpp:232] operator()() Opened RocksDB instance at /data/store/N2:1/db/shard1 in 453 ms
I0917 02:14:31.087041    4436 [not-set] RocksDBLogger.cpp:86] Logv() [file/delete_scheduler.cc:262] Rate limiting is enabled with penalty 1after deleting file /data/store/N2:1/db/shard1/000081.log.trash
I0917 02:14:31.099563    4397 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:691] printDiskShardMapping() Disk -> Shard mapping: /data/store/N2:1/db/shard0 -> [0,1]
I0917 02:14:31.101496    4397 [logdeviced-main] ShardedRocksDBLocalLogStore.cpp:285] init() Initialized sharded RocksDB instance at /data/store/N2:1/db with 2 shards
E0917 02:14:31.111363    4841 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState0"!
E0917 02:14:31.115274    4842 [ld:populateLogS] ThreadID.cpp:26] set() Truncating thread name "ld:populateLogState1"!
I0917 02:14:31.122657    4397 [logdeviced-main] Server.cpp:1173] initLogStorageStateMap() Populating log storage state map successful.
E0917 02:14:31.131472    4397 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:31.139468    4397 [logdeviced-main] RecordCacheMonitorThread.cpp:27] RecordCacheMonitorThread() Record cache monitor thread started.
I0917 02:14:31.140538    4877 [ld:cache-evict] RecordCacheMonitorThread.cpp:44] threadMain() Record cache eviction thread started. Size limit is set to 4294967296 bytes.
I0917 02:14:31.145644    4397 [logdeviced-main] ClusterState.cpp:356] resizeClusterState() Cluster state size updated from 0 to 5
E0917 02:14:31.150976    4397 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.157228    4397 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.169477    4397 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.177775    4397 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.183948    4397 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:31.184413    4707 [ld:s0:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 1ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:14:31.187826    4397 [logdeviced-main] Processor.cpp:247] init() Initialized 5 workers of type GENERAL
E0917 02:14:31.198163    4397 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:31.202100    4397 [logdeviced-main] Processor.cpp:247] init() Initialized 1 workers of type FAILURE_DETECTOR
E0917 02:14:31.208087    4397 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.212500    4397 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.217669    4397 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
E0917 02:14:31.227062    4397 [logdeviced-main] FileConfigSource.cpp:129] stat_mtime() stat() on config file "" failed. errno=2 (No such file or directory)
I0917 02:14:31.236532    4397 [logdeviced-main] Processor.cpp:247] init() Initialized 4 workers of type BACKGROUND
I0917 02:14:31.247179    4397 [logdeviced-main] FailureDetector.cpp:139] FailureDetector() Failure Detector created with instance id: 1631844871247
I0917 02:14:31.248957    4397 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N0 changed from UNKNOWN to DEAD
I0917 02:14:31.251475    4397 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from HEALTHY to UNHEALTHY
I0917 02:14:31.253113    4397 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N1 changed from UNKNOWN to DEAD
I0917 02:14:31.255160    4397 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from HEALTHY to UNHEALTHY
I0917 02:14:31.258828    4397 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N2 changed from UNKNOWN to DEAD
I0917 02:14:31.260440    4397 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from HEALTHY to UNHEALTHY
I0917 02:14:31.261915    4397 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N3 changed from UNKNOWN to DEAD
I0917 02:14:31.264365    4397 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from HEALTHY to UNHEALTHY
I0917 02:14:31.265803    4397 [logdeviced-main] ClusterState.cpp:165] setNodeState() State of N4 changed from UNKNOWN to DEAD
I0917 02:14:31.267036    4397 [logdeviced-main] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from HEALTHY to UNHEALTHY
W0917 02:14:31.269877    4882 [ld:srv:WG3] Worker.cpp:1322] processRequest() Request queued for 22 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967299), p :HI_PRI
W0917 02:14:31.276697    4879 [ld:srv:WG1] Worker.cpp:1322] processRequest() Request queued for 34 msec: BUFFERED_WRITER_CREATE_SHARD (id: 4294967297), p :HI_PRI
W0917 02:14:31.282953    4880 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 31 msec: NODE_STATE_UPDATED (id: 4294967303), p :LO_PRI
I0917 02:14:31.296792    4397 [logdeviced-main] FileBasedVersionedConfigStore.cpp:35] FileBasedVersionedConfigStore() FileBasedVersionedConfigStore threads started.
W0917 02:14:31.297970    4880 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 46 msec: NODE_STATE_UPDATED (id: 4294967309), p :LO_PRI
W0917 02:14:31.304528    4880 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 49 msec: NODE_STATE_UPDATED (id: 4294967313), p :LO_PRI
I0917 02:14:31.303491    4892 [ld:srv:WB2] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:14:31.311167    4892 [ld:srv:WB2] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 8ms
W0917 02:14:31.309966    4880 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 54 msec: NODE_STATE_UPDATED (id: 4294967319), p :LO_PRI
W0917 02:14:31.313549    4892 [ld:srv:WB2] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.011s, source: [Request: NODES_CONFIGURATION_MANAGER]
W0917 02:14:31.316502    4880 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 56 msec: NODE_STATE_UPDATED (id: 4294967323), p :LO_PRI
W0917 02:14:31.322306    4880 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 61 msec: NODE_STATE_UPDATED (id: 4294967329), p :LO_PRI
W0917 02:14:31.328875    4880 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 64 msec: NODE_STATE_UPDATED (id: 4294967333), p :LO_PRI
W0917 02:14:31.334747    4880 [ld:srv:WG2] Worker.cpp:1322] processRequest() Request queued for 69 msec: NODE_STATE_UPDATED (id: 4294967339), p :LO_PRI
I0917 02:14:31.342471    4892 [ld:srv:WB2] NodesConfigurationManager.cpp:507] onProcessingFinished() Updated local nodes config to version 5...
I0917 02:14:31.344512    4866 [ld:s0:default:1] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:31.347035    4866 [ld:s0:default:1] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 0, totaling 0 bytes.
I0917 02:14:31.358140    4873 [ld:s1:default:0] PartitionedRocksDBStore.cpp:3527] readAllLogSnapshotBlobs() Snapshots column family does not exist
I0917 02:14:31.359482    4873 [ld:s1:default:0] RecordCacheRepopulationTask.cpp:103] execute() Repopulated record caches for 0 logs on shard 1, totaling 0 bytes.
I0917 02:14:31.362920    4397 [logdeviced-main] Server.cpp:1319] initSequencers() Initializing FileEpochStore
I0917 02:14:31.364279    4397 [logdeviced-main] Server.cpp:1398] initSequencerPlacement() using SequencerOptions::LAZY
I0917 02:14:31.366364    4397 [logdeviced-main] Server.cpp:1430] initRebuildingCoordinator() Initializing EventLog RSM and RebuildingCoordinator
I0917 02:14:31.369071    4397 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387903)
I0917 02:14:31.372648    4397 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387903, is_server:1)
I0917 02:14:31.374858    4397 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:31.376430    4397 [logdeviced-main] Server.cpp:1467] initRebuildingCoordinator() Starting RebuildingSupervisor
I0917 02:14:31.377919    4397 [logdeviced-main] Server.cpp:1480] initRebuildingCoordinator() Starting RebuildingCoordinator
I0917 02:14:31.378155    4884 [ld:srv:WG4] RebuildingSupervisor.cpp:62] init() Starting Rebuilding Supervisor
I0917 02:14:31.382327    4884 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N4 to execute in 1200s
I0917 02:14:31.386750    4884 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N3 to execute in 1200s
I0917 02:14:31.387133    4397 [logdeviced-main] LogStoreMonitor.cpp:190] start() Logstore monitoring thread started.
I0917 02:14:31.387245    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:309] subscribeToEventLogIfNeeded() RebuildingCoordinator did not start yet because LogsConfig is not fully loaded yet
I0917 02:14:31.387950    4884 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N1 to execute in 1200s
I0917 02:14:31.393157    4884 [ld:srv:WG4] RebuildingSupervisor.cpp:222] addForRebuilding() Scheduling rebuilding of N0 to execute in 1200s
I0917 02:14:31.390016    4397 [logdeviced-main] UnreleasedRecordDetector.cpp:106] start() Unreleased record detector thread started.
I0917 02:14:31.391970    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [eventlog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:31.396423    4901 [ld:srv:WB3] EventLogStateMachine.cpp:146] gotInitialState() Got base rebuilding set: {}
W0917 02:14:31.394092    4884 [ld:srv:WG4] RebuildingSupervisor.cpp:705] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:14:31.405385    4884 [ld:srv:WG4] RebuildingSupervisor.cpp:718] adjustRebuildingThrottle() Entering throttling mode: #draining=0, #rebuilding=0, #triggers=4, #adjusted cluster size=5, threshold=35%, actual=80%
I0917 02:14:31.395423    4397 [logdeviced-main] RsmServerSnapshotStoreFactory.h:25] create() Attempting to create snapshot store (type:1, key:4611686018427387901)
I0917 02:14:31.398625    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [eventlog] Retrieving tail lsn of delta log...
W0917 02:14:31.406755    4884 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.029s, source: [Request: REBUILDING_SUPERVISOR]
I0917 02:14:31.409980    4397 [logdeviced-main] RsmSnapshotStoreFactory.h:31] create() Attempting to create snapshot store (type:1, key:4611686018427387901, is_server:1)
I0917 02:14:31.434176    4397 [logdeviced-main] RsmSnapshotStoreFactory.h:58] create() Creating LogBasedRSMSnapshotStore
I0917 02:14:31.420030    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [maintenancelog] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:31.442636    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [maintenancelog] Retrieving tail lsn of delta log...
E0917 02:14:31.420774    4882 [ld:srv:WG3] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 4611686018427387903. All sequencer nodes are unavailable.
I0917 02:14:31.439771    4890 [ld:srv:WB1] LogsConfigManager.cpp:38] execute() Starting LogsConfigManager on Worker 1 in pool: BACKGROUND
I0917 02:14:31.451893    4890 [ld:srv:WB1] LogsConfigManager.cpp:165] start() Starting LogsConfig Manager RSM
E0917 02:14:31.444545    4884 [ld:srv:WG4] SequencerRouter.cpp:56] operator()() Error during sequencer lookup for log 4611686018427387899 (NOSEQUENCER), reporting NOSEQUENCER.
W0917 02:14:31.455998    4884 [ld:srv:WG4] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387899, rqid:30064771075, ctx:rsm, err(NOSEQUENCER)
E0917 02:14:31.450758    4882 [ld:srv:WG3] SequencerRouter.cpp:105] onFailure() Error during sequencer routing for log 4611686018427387903 (NOSEQUENCER), request[type:GET_SEQ_STATE_REQ_TYPE, handler:0x7fcfa65ab028].
I0917 02:14:31.453355    4890 [ld:srv:WB1] LogsConfigManager.cpp:206] start() Starting LogsConfig Replicated State Machine
I0917 02:14:31.466513    4890 [ld:srv:WB1] ReplicatedStateMachine-inl.h:38] startFetchingSnapshot() [logsconfig] Using RSMSnapshotStore...
W0917 02:14:31.460030    4884 [ld:srv:WG4] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387899 (rqid:30064771075, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
W0917 02:14:31.464822    4882 [ld:srv:WG3] GetSeqStateRequest.cpp:512] onSequencerRoutingFailure() Unable to find a sequencer node for log 4611686018427387903, rqid:30064771073, ctx:rsm, err(NOSEQUENCER)
W0917 02:14:31.491788    4882 [ld:srv:WG3] GetSeqStateRequest.cpp:700] finalize() GET_SEQ_STATE for log 4611686018427387903 (rqid:30064771073, ctx:rsm) returned NOSEQUENCER: no sequencer was found for log
I0917 02:14:31.467474    4890 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1294] initSnapshotFetchTimer() [logsconfig] Creating timer to fetch snapshots ...
E0917 02:14:31.474748    4901 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:30064771075) for log:4611686018427387899, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:14:31.497962    4397 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server LogDevice Admin API Service will listen on port 48433
I0917 02:14:31.500124    4397 [logdeviced-main] Server.cpp:1540] createAndAttachMaintenanceManager() Not initializing MaintenanceManager since it is disabled in settings
E0917 02:14:31.498078    4901 [ld:srv:WB3] SyncSequencerRequest.cpp:178] onGotSeqState() Got sequencer state (id:30064771073) for log:4611686018427387903, status:NOSEQUENCER: no sequencer was found for log,sequencer:[invalid NodeID], last_released_lsn:LSN_INVALID, next_lsn:LSN_INVALID
I0917 02:14:31.501957    4397 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: s2s-api
I0917 02:14:31.509016    4397 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server s2s-api will listen on port 48437
I0917 02:14:31.511388    4397 [logdeviced-main] Server.cpp:905] initThriftServer() Initializing Thrift Server: c2s-api
I0917 02:14:31.514661    4397 [logdeviced-main] LogDeviceThriftServer.cpp:44] LogDeviceThriftServer() Thrift server c2s-api will listen on port 48438
I0917 02:14:31.516014    4397 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:31.518916    4422 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:31.520501    4397 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:31.525825    4423 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:31.528286    4397 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server s2s-api
I0917 02:14:31.528661    4886 [ld:srv:WF0] FailureDetector.cpp:228] startGetClusterState() Sending GET_CLUSTER_STATE to build initial FD cluster view
I0917 02:14:31.533600    4886 [ld:srv:WF0] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket N4:1(127.0.0.1:48410) hit error AsyncSocketException: connect failed, type = Socket not open, errno = 111 (Connection refused)
W0917 02:14:31.535720    4880 [ld:srv:WG2] GET_SEQ_STATE_Message.cpp:862] isReady() Node N2:1 is not alive according to Failure Detector, returning E::NOTREADY for log:4611686018427387898
I0917 02:14:31.541236    4886 [ld:srv:WF0] GetClusterStateRequest.cpp:252] onError() Retrieving the state of the cluster failed. sending another wave.
E0917 02:14:31.557135    4886 [ld:srv:WF0] GetClusterStateRequest.cpp:243] onError() Retrieving the state of the cluster failed. giving up.
E0917 02:14:31.560773    4886 [ld:srv:WF0] FailureDetector.cpp:243] operator()() Unable to refresh cluster state: FAILED: request failed
I0917 02:14:31.563203    4886 [ld:srv:WF0] FailureDetector.cpp:288] buildInitialState() Wait over
I0917 02:14:31.566883    4886 [ld:srv:WF0] FailureDetector.cpp:344] buildInitialState() Initializing DomainIsolationChecker
I0917 02:14:31.572803    4886 [ld:srv:WF0] FailureDetector.cpp:915] startSuspectTimer() Starting suspect state timer
I0917 02:14:31.568816    4397 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server c2s-api
I0917 02:14:31.574900    4886 [ld:srv:WF0] FailureDetector.cpp:1285] updateNodeState() N2 transitioned from DEAD to ALIVE, FD State:(gossip: 0, instance-id: 0, failover: 0, starting: 1)
I0917 02:14:31.581774    4886 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from DEAD to STARTING
I0917 02:14:31.594330    4886 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting suspect-state-finished message.
I0917 02:14:31.602290    4886 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844871247 to node WF0:N4:1 (127.0.0.1:48410)
I0917 02:14:31.611711    4886 [ld:srv:WF0] FailureDetector.cpp:1476] broadcastBringupUpdate() Sending suspect-state-finished message with instance id:1631844871247 to node WF0:N3:1 (127.0.0.1:48421)
I0917 02:14:31.612909    4397 [logdeviced-main] SimpleThriftServer.cpp:28] start() Starting a listener thread for Thrift server LogDevice Admin API Service
I0917 02:14:31.616414    4886 [ld:srv:WF0] FailureDetector.cpp:1456] broadcastBringupUpdate() Broadcasting bringup message.
I0917 02:14:31.622666    4886 [ld:srv:WF0] FailureDetector.cpp:937] startGossiping() Start Gossiping.
I0917 02:14:31.626309    4886 [ld:srv:WF0] FailureDetector.cpp:925] operator()() Suspect timeout expired
I0917 02:14:31.654918    4397 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:31.661270    4424 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:31.667221    4397 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:31.675068    4422 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:31.677095    4397 [logdeviced-main] Listener.cpp:39] startAcceptingConnections() Start called
I0917 02:14:31.684500    4422 [not-set] Listener.cpp:63] setupAsyncSocket() Setup called
I0917 02:14:31.687002    4397 [logdeviced-main] main.cpp:464] main() Listeners initialized
I0917 02:14:31.730148    4886 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from UNHEALTHY to UNDEFINED
I0917 02:14:31.737036    4886 [ld:srv:WF0] FailureDetector.cpp:1541] onGossipMessageSent() Could not send gossip to WF0:N3:1 (127.0.0.1:48421): CONNFAILED: connection failed. Trying another node.
I0917 02:14:31.745840    4886 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N1:1 with instance id:1631844871402, sent_time:1631844871733ms
I0917 02:14:31.746453    4886 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N1 changed from DEAD to STARTING
I0917 02:14:31.748310    4886 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N1 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844871402, failover: 0, starting: 1)
I0917 02:14:31.748865    4884 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N1
I0917 02:14:31.749487    4886 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N1:1 with instance id:1631844871402, sent_time:1631844871738ms
I0917 02:14:31.757877    4886 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N1
I0917 02:14:31.845656    4886 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N2 changed from UNDEFINED to HEALTHY
I0917 02:14:31.875319    4886 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N0:1 with instance id:1631844871595, sent_time:1631844871839ms
I0917 02:14:31.876686    4886 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from DEAD to STARTING
I0917 02:14:31.881558    4886 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N0 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844871595, failover: 0, starting: 1)
I0917 02:14:31.883726    4886 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received bringup message from N0:1 with instance id:1631844871595, sent_time:1631844871844ms
I0917 02:14:31.885173    4886 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N0
I0917 02:14:31.882523    4884 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N0
I0917 02:14:32.017368    4886 [ld:srv:WF0] FailureDetector.cpp:682] processFlags() Received suspect-state-finished message from N4:1 with instance id:1631844871814, sent_time:1631844872005ms
I0917 02:14:32.018667    4886 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from DEAD to STARTING
I0917 02:14:32.020327    4884 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N4
W0917 02:14:32.021278    4884 [ld:srv:WG4] RebuildingSupervisor.cpp:734] adjustRebuildingThrottle() Exiting throttling mode: #draining=0, #rebuilding=0, #triggers=1, #adjusted cluster size=5, threshold=35%, actual=20%
I0917 02:14:32.022435    4884 [ld:srv:WG4] RebuildingSupervisor.cpp:751] adjustRebuildingThrottle() Not triggering new rebuildings until 2021-09-17 02:34:32.022: It's too soon after exiting throttling mode
I0917 02:14:32.020380    4886 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N4 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844871814, failover: 0, starting: 1)
I0917 02:14:32.026775    4886 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N4
I0917 02:14:32.089026    4886 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N3 changed from DEAD to STARTING
I0917 02:14:32.090486    4886 [ld:srv:WF0] FailureDetector.cpp:717] processFlags() N3 transitioned to STARTING as a result of receiving suspect-state-finished message, FD State:(gossip: 0, instance-id: 1631844871925, failover: 0, starting: 1)
I0917 02:14:32.090545    4884 [ld:srv:WG4] RebuildingSupervisor.cpp:256] onNodeStateChanged() Cancelling rebuilding trigger for node N3
I0917 02:14:32.091412    4886 [ld:srv:WF0] FailureDetector.cpp:1845] resetVersions() Resetting RSM and NCM Versions for N3
I0917 02:14:32.238052    4747 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() skipped at least 10 log entries
I0917 02:14:32.239118    4747 [ld:s1:db-bg-fl] PartitionedRocksDBStore.cpp:6498] flushBackgroundThreadRun() Flushing: []. Total stats: active: 0.001MB in 1 memtables, flushing: 0.000MB, pinned: 0.000MB. Eval time: 0ms, flush init: 0ms, throttle eval: 0ms, npartitions: 1. Existing memtables: metadata A:0.001MB, []
I0917 02:14:32.270210    4886 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from UNHEALTHY to UNDEFINED
I0917 02:14:32.270998    4886 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N1 changed from UNHEALTHY to HEALTHY
I0917 02:14:32.271858    4886 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from UNHEALTHY to UNDEFINED
I0917 02:14:32.476853    4886 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N0 changed from UNDEFINED to HEALTHY
I0917 02:14:32.477745    4886 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from UNHEALTHY to UNDEFINED
I0917 02:14:32.497313    4890 [ld:srv:WB1] ReplicatedStateMachine-inl.h:130] getSnapshot() [logsconfig] Fetching snapshot with ver:e0n1, (waiting_for_snapshot_:LSN_INVALID, version_:e0n1). sync_state_:0
I0917 02:14:32.556999    4874 [ld:s1:default:1] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 4611686018427387899 epoch 2: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 2.
I0917 02:14:32.580066    4886 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N3 changed from UNDEFINED to HEALTHY
I0917 02:14:32.581364    4886 [ld:srv:WF0] ClusterState.cpp:184] setNodeStatus() Status of N4 changed from UNDEFINED to HEALTHY
I0917 02:14:32.604288    4878 [ld:srv:WG0] CONFIG_FETCH_Message.cpp:70] onReceived() CONFIG_FETCH messages received. E.g., from WG0:C10 (127.0.0.1:39876)
I0917 02:14:32.639181    4878 [ld:srv:WG0] ProtocolHandler.cpp:127] notifyErrorOnSocket() skipped at least 10 log entries
I0917 02:14:32.640288    4878 [ld:srv:WG0] ProtocolHandler.cpp:127] notifyErrorOnSocket() Socket C10(127.0.0.1:39876) hit error AsyncSocketException: Socket read end of file., type = End of file
I0917 02:14:32.700067    4882 [ld:srv:WG3] RecordCache.cpp:257] getEpochRecordCache() RecordCache miss for log 4611686018427387899 epoch 2: cache not found but cannot declare no data. head epoch : 0, last_nonauthoritative_epoch: 2.
I0917 02:14:32.736277    4880 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387903 has already been cleaned. No purge needed. last clean epoch: 6, purge to: 6.
I0917 02:14:32.754718    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163707 shard 1 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 2.
I0917 02:14:32.757380    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163707 shard 1 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 3.
I0917 02:14:32.762681    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163707 shard 1 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 4.
I0917 02:14:32.763528    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163707 shard 1 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 5.
W0917 02:14:32.764390    4884 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() skipped at least 9 log entries
W0917 02:14:32.767724    4884 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.010s, source: [Message sent/received: GET_EPOCH_RECOVERY_METADATA_REPLY]
I0917 02:14:32.769710    4884 [ld:srv:WG4] PurgeUncleanEpochs.cpp:401] onGetEpochRecoveryMetadataComplete() Nothing to purge. Epoch is empty locally and EpochRecoveryMetadata consensus is also EMPTY for log: 13835058055282163707,epoch:5
I0917 02:14:32.828087    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163708 shard 0 epochs [2,6] purge_to 6 got at least one reply with E::EMPTY, for the epoch 2.
I0917 02:14:32.832371    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163708 shard 0 epochs [2,6] purge_to 6 got at least one reply with E::EMPTY, for the epoch 3.
I0917 02:14:32.834441    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163708 shard 0 epochs [2,6] purge_to 6 got at least one reply with E::EMPTY, for the epoch 4.
I0917 02:14:32.836466    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163708 shard 0 epochs [2,6] purge_to 6 got at least one reply with E::EMPTY, for the epoch 5.
I0917 02:14:32.837240    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163708 shard 0 epochs [2,6] purge_to 6 got at least one reply with E::EMPTY, for the epoch 6.
W0917 02:14:32.839726    4884 [ld:srv:WG4] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.012s, source: [Message sent/received: GET_EPOCH_RECOVERY_METADATA_REPLY]
I0917 02:14:32.846339    4880 [ld:srv:WG2] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [6, 6] for log 4611686018427387903.
I0917 02:14:32.899985    4882 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 2, purge to: 2.
I0917 02:14:32.992050    4884 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163707 has already been cleaned. No purge needed. last clean epoch: 6, purge to: 6.
I0917 02:14:33.005403    4880 [ld:srv:WG2] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387903 has already been cleaned. No purge needed. last clean epoch: 7, purge to: 7.
I0917 02:14:33.068767    4884 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163708 has already been cleaned. No purge needed. last clean epoch: 7, purge to: 7.
I0917 02:14:33.083436    4882 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387900 has already been cleaned. No purge needed. last clean epoch: 2, purge to: 2.
I0917 02:14:33.096467    4882 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 3, purge to: 3.
I0917 02:14:33.276085    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:172] checkAllFullyAuthoritativeNodesResponded() GetEpochRecoveryMetadataRequest for log 13835058055282163711 shard 1 epochs [2,3] purge_to 3 received reply from all fully authoritative nodes in thenodeset but still unable to make a decision. It is likely that some epoch has been recovered by non-authoritative recovery.
I0917 02:14:33.282012    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:199] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163711 shard 1 epochs [2,3] purge_to 3 - All nodes responded but there is no valid response for epoch:2
I0917 02:14:33.287507    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:199] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163711 shard 1 epochs [2,3] purge_to 3 - All nodes responded but there is no valid response for epoch:3
I0917 02:14:33.293838    4884 [ld:srv:WG4] PurgeUncleanEpochs.cpp:387] onGetEpochRecoveryMetadataComplete() GetEpochRecoveryMetadataRequest for log 13835058055282163711 did not get a valid response for epoch 3. Skipping purging for this epoch
I0917 02:14:33.294738    4884 [ld:srv:WG4] PurgeUncleanEpochs.cpp:387] onGetEpochRecoveryMetadataComplete() GetEpochRecoveryMetadataRequest for log 13835058055282163711 did not get a valid response for epoch 2. Skipping purging for this epoch
I0917 02:14:33.368679    4882 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387899 has already been cleaned. No purge needed. last clean epoch: 4, purge to: 4.
I0917 02:14:33.383609    4882 [ld:srv:WG3] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 4611686018427387900 has already been cleaned. No purge needed. last clean epoch: 3, purge to: 3.
I0917 02:14:33.527307    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [maintenancelog] Tail lsn of delta log is e8n0
I0917 02:14:33.570515    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [eventlog] Tail lsn of delta log is e9n0
I0917 02:14:33.584133    4901 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387903 epoch 2 is not available. Highest epoch known is 1.
I0917 02:14:33.599136    4884 [ld:srv:WG4] PurgeUncleanEpochs.cpp:99] getPurgeEpochs() log 13835058055282163711 has already been cleaned. No purge needed. last clean epoch: 4, purge to: 4.
I0917 02:14:33.603943    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [eventlog] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:14:33.608855    4901 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (1)
I0917 02:14:33.711332    4884 [ld:srv:WG4] PurgeUncleanEpochs.cpp:592] complete() skipped at least 10 log entries
I0917 02:14:33.711983    4884 [ld:srv:WG4] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [4, 4] for log 13835058055282163711.
I0917 02:14:33.849805    4878 [ld:srv:WG0] PurgeUncleanEpochs.cpp:592] complete() skipped at least 1 log entries
I0917 02:14:33.850739    4878 [ld:srv:WG0] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [1, 1] for log 4611686018427387898.
I0917 02:14:34.103378    4901 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387899 epoch 2 is not available. Highest epoch known is 1.
W0917 02:14:34.107218    4901 [ld:srv:WB3] ClientReadStream.cpp:2476] updateCurrentMetaData() Existing epoch metadata has changed for log 4611686018427387899 on epoch 1, check metadata log!
I0917 02:14:34.119592    4901 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387899 epoch 3 is not available. Highest epoch known is 1.
W0917 02:14:34.120272    4901 [ld:srv:WB3] ClientReadStream.cpp:2476] updateCurrentMetaData() Existing epoch metadata has changed for log 4611686018427387899 on epoch 1, check metadata log!
I0917 02:14:34.139925    4901 [ld:srv:WB3] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387899 epoch 7 is not available. Highest epoch known is 1.
W0917 02:14:34.141188    4901 [ld:srv:WB3] ClientReadStream.cpp:2476] updateCurrentMetaData() Existing epoch metadata has changed for log 4611686018427387899 on epoch 1, check metadata log!
I0917 02:14:34.157517    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [maintenancelog] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:14:34.161833    4901 [ld:srv:WB3] ClusterMaintenanceStateMachine.cpp:112] onUpdate() [maintenancelog] Published new ClusterMaintenanceState version (1)
I0917 02:14:34.265241    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163706 shard 0 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 2.
I0917 02:14:34.266203    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163706 shard 0 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 3.
I0917 02:14:34.266760    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163706 shard 0 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 4.
I0917 02:14:34.268329    4884 [ld:srv:WG4] GetEpochRecoveryMetadataRequest.cpp:226] buildEpochRecoveryStateMap() GetEpochRecoveryMetadataRequest for log 13835058055282163706 shard 0 epochs [2,5] purge_to 5 got at least one reply with E::EMPTY, for the epoch 5.
I0917 02:14:34.270460    4884 [ld:srv:WG4] PurgeUncleanEpochs.cpp:401] onGetEpochRecoveryMetadataComplete() skipped at least 8 log entries
I0917 02:14:34.271063    4884 [ld:srv:WG4] PurgeUncleanEpochs.cpp:401] onGetEpochRecoveryMetadataComplete() Nothing to purge. Epoch is empty locally and EpochRecoveryMetadata consensus is also EMPTY for log: 13835058055282163706,epoch:5
I0917 02:14:34.468244    4878 [ld:srv:WG0] PurgeUncleanEpochs.cpp:592] complete() skipped at least 10 log entries
I0917 02:14:34.468962    4878 [ld:srv:WG0] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [4, 4] for log 4611686018427387898.
I0917 02:14:34.927423    4878 [ld:srv:WG0] PurgeUncleanEpochs.cpp:592] complete() skipped at least 4 log entries
I0917 02:14:34.928473    4878 [ld:srv:WG0] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [6, 6] for log 4611686018427387898.
I0917 02:14:35.566982    4890 [ld:srv:WB1] LogBasedRSMSnapshotStore.cpp:298] onGotLastReleased() Returning EMPTY for log:4611686018427387900, last_released_real_lsn:LSN_INVALID
I0917 02:14:35.567746    4890 [ld:srv:WB1] ReplicatedStateMachine-inl.h:83] operator()() [logsconfig] getSnapshot()'s callback. st:EMPTY, snapshot blob size:0, attrs:(base_ver:LSN_INVALID, ts:0)
I0917 02:14:35.568411    4890 [ld:srv:WB1] ReplicatedStateMachine-inl.h:667] onBaseSnapshotRetrieved() [logsconfig] Base snapshot has version:e0n1, delta_log_read_ptr:LSN_INVALID
I0917 02:14:35.569109    4890 [ld:srv:WB1] ReplicatedStateMachine-inl.h:684] getDeltaLogTailLSN() [logsconfig] Retrieving tail lsn of delta log...
I0917 02:14:35.572154    4890 [ld:srv:WB1] ReplicatedStateMachine-inl.h:712] onGotDeltaLogTailLSN() [logsconfig] Tail lsn of delta log is e6n0
I0917 02:14:35.672286    4890 [ld:srv:WB1] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387901 epoch 2 is not available. Highest epoch known is 1.
I0917 02:14:35.675378    4890 [ld:srv:WB1] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [logsconfig] Applied delta record with lsn=e2n1 ts=2021-09-17 02:10:19.558
I0917 02:14:35.680442    4890 [ld:srv:WB1] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [logsconfig] Applied delta record with lsn=e2n2 ts=2021-09-17 02:11:11.944
I0917 02:14:35.689725    4890 [ld:srv:WB1] ClientReadStream.cpp:4571] operator()() Requested epoch metadata for log 4611686018427387901 epoch 3 is not available. Highest epoch known is 1.
W0917 02:14:35.690673    4890 [ld:srv:WB1] ClientReadStream.cpp:2476] updateCurrentMetaData() Existing epoch metadata has changed for log 4611686018427387901 on epoch 1, check metadata log!
W0917 02:14:35.707709    4882 [ld:srv:WG3] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:1 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.709911    4882 [ld:srv:WG3] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:11 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.710773    4882 [ld:srv:WG3] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:13 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.712552    4882 [ld:srv:WG3] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:15 (status=NOTFOUND), replying with E::NOSEQUENCER.
W0917 02:14:35.715001    4882 [ld:srv:WG3] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:21 (status=NOTFOUND), replying with E::NOSEQUENCER.
I0917 02:14:35.716934    4890 [ld:srv:WB1] ReplicatedStateMachine-inl.h:1052] onReachedDeltaLogTailLSN() [logsconfig] Reached tail of delta log. deliver_while_replaying:0, stop_at_tail_:0
I0917 02:14:35.717915    4890 [ld:srv:WB1] LogsConfigManager.cpp:193] operator()() Received update from LogsConfigStateMachine, version 8589934594
I0917 02:14:35.721216    4890 [ld:srv:WB1] AllSequencers.cpp:981] noteConfigurationChanged() Acquiring lock for sequencer map took 0ms
I0917 02:14:35.723537    4890 [ld:srv:WB1] UpdateableConfigTmpl.h:442] updateIfEqual() Config updated. Timings: Acquiring lock: 0ms, applying overrides: 0ms, hook execution: 0ms, config update: 0ms, notifications: 3ms
I0917 02:14:35.724707    4890 [ld:srv:WB1] LogsConfigManager.cpp:331] updateLogsConfig() Published new LogsConfig (fully loaded? yes) version (8589934594) from LogsConfigManager
I0917 02:14:35.726671    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1740] publishDirtyShards() Publishing dirty shards.
I0917 02:14:35.727433    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 1, reason=Node came back with data intact
I0917 02:14:35.729412    4901 [ld:srv:WB3] EventLogWriter.cpp:86] writeEvent() (Queue size: 0) Enqueueing event SHARD_NEEDS_REBUILD(nodeIdx=2, shardIdx=1, source=N2, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:35.730898    4901 [ld:srv:WB3] EventLogWriter.cpp:50] writeNextEventInQueue() (Queue size: 1) Writing event SHARD_NEEDS_REBUILD(nodeIdx=2, shardIdx=1, source=N2, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:35.732779    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 0, reason=Node came back with data intact
I0917 02:14:35.734393    4901 [ld:srv:WB3] EventLogWriter.cpp:86] writeEvent() (Queue size: 1) Enqueueing event SHARD_NEEDS_REBUILD(nodeIdx=2, shardIdx=0, source=N2, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:35.744714    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:2064] subscribeToEventLog() Subscribed to EventLog
W0917 02:14:35.748231    4901 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() skipped at least 1 log entries
E0917 02:14:35.745407    4880 [ld:srv:WG2] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 73. All sequencer nodes are unavailable.
W0917 02:14:35.749771    4901 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.025s, source: [Request: LOGS_CONFIG_UPDATED]
E0917 02:14:35.752047    4880 [ld:srv:WG2] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 77. All sequencer nodes are unavailable.
E0917 02:14:35.754950    4880 [ld:srv:WG2] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 85. All sequencer nodes are unavailable.
E0917 02:14:35.759776    4880 [ld:srv:WG2] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 92. All sequencer nodes are unavailable.
E0917 02:14:35.761772    4880 [ld:srv:WG2] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 99. All sequencer nodes are unavailable.
E0917 02:14:35.764811    4880 [ld:srv:WG2] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 33. All sequencer nodes are unavailable.
E0917 02:14:35.765963    4880 [ld:srv:WG2] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 51. All sequencer nodes are unavailable.
E0917 02:14:35.767644    4880 [ld:srv:WG2] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 70. All sequencer nodes are unavailable.
E0917 02:14:35.770416    4880 [ld:srv:WG2] HashBasedSequencerLocator.cpp:208] locateSequencer() No available sequencer node for log 74. All sequencer nodes are unavailable.
W0917 02:14:35.772513    4880 [ld:srv:WG2] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() skipped at least 10 log entries
W0917 02:14:35.773471    4880 [ld:srv:WG2] GET_SEQ_STATE_Message.cpp:812] shouldRedirectOrFail() No sequencer node found for log:96 (status=NOSEQUENCER), replying with E::NOSEQUENCER.
I0917 02:14:35.773868    4886 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N2 changed from STARTING to FULLY_STARTED
I0917 02:14:35.780745    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [eventlog] Successfully wrote delta with lsn e9n1
I0917 02:14:35.804871    4901 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.754, e9n1: SHARD_NEEDS_REBUILD(nodeIdx=2, shardIdx=1, source=N2, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:35.806810    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n1 ts=2021-09-17 02:14:35.754
I0917 02:14:35.807946    4901 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705665)
I0917 02:14:35.808988    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 1 after 1ms
W0917 02:14:35.798303    4880 [ld:srv:WG2] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.026s, source: [Message sent/received: GET_SEQ_STATE]
I0917 02:14:35.809939    4901 [ld:srv:WB3] EventLogWriter.cpp:67] operator()() Wrote record with lsn e9n1
I0917 02:14:35.812374    4901 [ld:srv:WB3] EventLogWriter.cpp:50] writeNextEventInQueue() (Queue size: 1) Writing event SHARD_NEEDS_REBUILD(nodeIdx=2, shardIdx=0, source=N2, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:35.816770    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 1, reason=Shard came back with data intact
I0917 02:14:35.817514    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 1 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:35.818830    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:35.820112    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:35.821306    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1883] abortForMyShard() Dirty ranges for my shard 1 successfully published
I0917 02:14:35.821953    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:472] noteRangesPublished() Noting dirty ranges published for shard 1
I0917 02:14:35.825484    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n1 ts=2021-09-17 02:14:35.812 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:35.828713    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n1
I0917 02:14:35.834065    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [eventlog] Successfully wrote delta with lsn e9n2
I0917 02:14:35.836317    4901 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n1
I0917 02:14:35.838187    4901 [ld:srv:WB3] EventLogWriter.cpp:67] operator()() Wrote record with lsn e9n2
I0917 02:14:35.840437    4901 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.823, e9n2: SHARD_NEEDS_REBUILD(nodeIdx=2, shardIdx=0, source=N2, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:35.841339    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n2 ts=2021-09-17 02:14:35.823
I0917 02:14:35.843172    4901 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705666)
I0917 02:14:35.844498    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 0 after 1ms
I0917 02:14:35.847171    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 0, reason=Shard came back with data intact
I0917 02:14:35.848256    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 0 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:35.850146    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:35.851797    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:35.853131    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1883] abortForMyShard() Dirty ranges for my shard 0 successfully published
I0917 02:14:35.854429    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:472] noteRangesPublished() Noting dirty ranges published for shard 0
I0917 02:14:35.858628    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n2
I0917 02:14:35.863315    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n2 ts=2021-09-17 02:14:35.840 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:35.865336    4901 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n2
I0917 02:14:35.878343    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n3
I0917 02:14:35.879970    4901 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n3
I0917 02:14:35.898249    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n3 ts=2021-09-17 02:14:35.869 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:35.903801    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n5
I0917 02:14:35.907282    4901 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n5
I0917 02:14:35.915845    4901 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.881, e9n3: SHARD_NEEDS_REBUILD(nodeIdx=1, shardIdx=1, source=N1, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}]
I0917 02:14:35.924262    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n3 ts=2021-09-17 02:14:35.881
I0917 02:14:35.925704    4901 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705667)
I0917 02:14:35.926817    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 1 after 1ms
I0917 02:14:35.931163    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 1, reason=Shard came back with data intact
I0917 02:14:35.932461    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 1 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:35.933636    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:35.937463    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:35.939501    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 1. Converting abort into no-op.
I0917 02:14:35.942950    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 1 and rebuilding set N1:S1[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}],N2:S1[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:35.951209    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n4 ts=2021-09-17 02:14:35.881 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:35.952387    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n5 ts=2021-09-17 02:14:35.892 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:35.954425    4901 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.929, e9n4: SHARD_NEEDS_REBUILD(nodeIdx=1, shardIdx=0, source=N1, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}]
I0917 02:14:35.960138    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n4 ts=2021-09-17 02:14:35.929
I0917 02:14:35.968526    4901 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705668)
I0917 02:14:35.974976    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 0 after 1ms
I0917 02:14:35.978794    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 0, reason=Shard came back with data intact
I0917 02:14:35.982255    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 0 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:35.983890    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:35.986844    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:35.990916    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 0. Converting abort into no-op.
I0917 02:14:35.993202    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 0 and rebuilding set N1:S0[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}],N2:S0[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:36.012839    4879 [ld:srv:WG1] PurgeUncleanEpochs.cpp:592] complete() skipped at least 6 log entries
I0917 02:14:36.019851    4879 [ld:srv:WG1] PurgeUncleanEpochs.cpp:592] complete() Successfully purged epochs [1, 1] for log 13835058055282163710.
I0917 02:14:36.018924    4901 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.933, e9n5: SHARD_NEEDS_REBUILD(nodeIdx=0, shardIdx=1, source=N0, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:09:59.858,2021-09-17 02:10:29.858]}}]
I0917 02:14:36.029688    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n5 ts=2021-09-17 02:14:35.933
I0917 02:14:36.031851    4901 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705669)
I0917 02:14:36.034976    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 1 after 1ms
I0917 02:14:36.037344    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n7
I0917 02:14:36.040301    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 1, reason=Shard came back with data intact
I0917 02:14:36.042097    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 1 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.043977    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:36.046145    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:36.051520    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 1. Converting abort into no-op.
I0917 02:14:36.057929    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 1 and rebuilding set N0:S1[A:{{[2021-09-17 02:09:59.858,2021-09-17 02:10:29.858]}}],N1:S1[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}],N2:S1[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:36.058903    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n6 ts=2021-09-17 02:14:35.928 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.060260    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n7 ts=2021-09-17 02:14:35.952 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.063738    4901 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:35.965, e9n6: SHARD_NEEDS_REBUILD(nodeIdx=0, shardIdx=0, source=N0, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:09:59.859,2021-09-17 02:10:29.859]}}]
I0917 02:14:36.068141    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n6 ts=2021-09-17 02:14:35.965
I0917 02:14:36.070137    4901 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705670)
I0917 02:14:36.072287    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 0 after 1ms
I0917 02:14:36.074101    4901 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n7
I0917 02:14:36.077746    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 0, reason=Shard came back with data intact
I0917 02:14:36.079178    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 0 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.080833    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:36.081865    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:36.083492    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 0. Converting abort into no-op.
I0917 02:14:36.088364    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 0 and rebuilding set N0:S0[A:{{[2021-09-17 02:09:59.859,2021-09-17 02:10:29.859]}}],N1:S0[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}],N2:S0[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:36.098340    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n8 ts=2021-09-17 02:14:36.040 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.099231    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n9 ts=2021-09-17 02:14:36.059 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.100223    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n10 ts=2021-09-17 02:14:36.063 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.111711    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n11 ts=2021-09-17 02:14:36.068 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.119053    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n12 ts=2021-09-17 02:14:36.080 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.122678    4901 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:36.083, e9n7: SHARD_NEEDS_REBUILD(nodeIdx=4, shardIdx=1, source=N4, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
I0917 02:14:36.128654    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n7 ts=2021-09-17 02:14:36.083
I0917 02:14:36.132266    4901 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705671)
I0917 02:14:36.148434    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 1 after 1ms
I0917 02:14:36.150090    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n15
I0917 02:14:36.152462    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 1, reason=Shard came back with data intact
I0917 02:14:36.154061    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 1 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.156399    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:36.159106    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:36.166358    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 1. Converting abort into no-op.
I0917 02:14:36.172001    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 1 and rebuilding set N0:S1[A:{{[2021-09-17 02:09:59.858,2021-09-17 02:10:29.858]}}],N1:S1[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}],N2:S1[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}],N4:S1[A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
W0917 02:14:36.174015    4901 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() skipped at least 10 log entries
W0917 02:14:36.176194    4901 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.022s, source: [Message sent/received: RECORD]
I0917 02:14:36.177539    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n13 ts=2021-09-17 02:14:36.084 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.179255    4901 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n15
I0917 02:14:36.186155    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n14 ts=2021-09-17 02:14:36.092 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.189777    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n15 ts=2021-09-17 02:14:36.094 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
W0917 02:14:36.201222    4901 [ld:srv:WB3] Worker.cpp:1000] onStoppedRunning() Slow request/timer callback: 0.015s, source: [Message sent/received: RECORD]
I0917 02:14:36.212731    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n16 ts=2021-09-17 02:14:36.144 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.214891    4901 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:36.125, e9n8: SHARD_NEEDS_REBUILD(nodeIdx=4, shardIdx=0, source=N4, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
I0917 02:14:36.216550    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n8 ts=2021-09-17 02:14:36.125
I0917 02:14:36.218002    4901 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705672)
I0917 02:14:36.221979    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 0 after 1ms
I0917 02:14:36.225571    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 0, reason=Shard came back with data intact
I0917 02:14:36.235781    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 0 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.236963    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:36.242034    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:36.248216    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 0. Converting abort into no-op.
I0917 02:14:36.255888    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 0 and rebuilding set N0:S0[A:{{[2021-09-17 02:09:59.859,2021-09-17 02:10:29.859]}}],N1:S0[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}],N2:S0[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}],N4:S0[A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
I0917 02:14:36.263327    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n17 ts=2021-09-17 02:14:36.171 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.267422    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n18 ts=2021-09-17 02:14:36.182 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.272117    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n19 ts=2021-09-17 02:14:36.225 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.272925    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n20 ts=2021-09-17 02:14:36.230 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.276730    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n21 ts=2021-09-17 02:14:36.237 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
W0917 02:14:36.278184    4901 [ld:srv:WB3] Worker.cpp:1322] processRequest() skipped at least 11 log entries
W0917 02:14:36.280716    4901 [ld:srv:WB3] Worker.cpp:1322] processRequest() Request queued for 35 msec: WORKER_CALLBACK_HELPER (id: 17179869205), p :LO_PRI
I0917 02:14:36.281694    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n20
I0917 02:14:36.284174    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n22 ts=2021-09-17 02:14:36.271 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.289308    4901 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n20
I0917 02:14:36.290740    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n23 ts=2021-09-17 02:14:36.276 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.309736    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n24 ts=2021-09-17 02:14:36.285 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.313236    4901 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:36.286, e9n9: SHARD_NEEDS_REBUILD(nodeIdx=3, shardIdx=1, source=N3, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:09:59.669,2021-09-17 02:10:29.669]}}]
I0917 02:14:36.316258    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n9 ts=2021-09-17 02:14:36.286
I0917 02:14:36.317182    4901 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705673)
I0917 02:14:36.319232    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 1 after 1ms
I0917 02:14:36.324815    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n25 ts=2021-09-17 02:14:36.285 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.329323    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 1, reason=Shard came back with data intact
I0917 02:14:36.335514    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 1 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.340373    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:36.342067    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}]
I0917 02:14:36.344238    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 1. Converting abort into no-op.
I0917 02:14:36.345743    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 1 and rebuilding set N0:S1[A:{{[2021-09-17 02:09:59.858,2021-09-17 02:10:29.858]}}],N1:S1[A:{{[2021-09-17 02:10:00.088,2021-09-17 02:10:30.088]}}],N2:S1[A:{{[2021-09-17 02:10:00.557,2021-09-17 02:10:30.557]}}],N3:S1[A:{{[2021-09-17 02:09:59.669,2021-09-17 02:10:29.669]}}],N4:S1[A:{{[2021-09-17 02:10:00.332,2021-09-17 02:10:30.332]}}]
I0917 02:14:36.347763    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n26 ts=2021-09-17 02:14:36.291 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.349140    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n27 ts=2021-09-17 02:14:36.304 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.350640    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n27
I0917 02:14:36.352341    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n28 ts=2021-09-17 02:14:36.342 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.358468    4901 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n27
I0917 02:14:36.363371    4901 [ld:srv:WB3] EventLogStateMachine.cpp:171] applyDelta() Applying delta ts=2021-09-17 02:14:36.350, e9n10: SHARD_NEEDS_REBUILD(nodeIdx=3, shardIdx=0, source=N3, details=RebuildingCoordinator, flags=TIME_RANGED|FILTER_RELOCATE_SHARDS)[A:{{[2021-09-17 02:09:59.666,2021-09-17 02:10:29.666]}}]
I0917 02:14:36.365804    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:841] onDeltaRecord() [eventlog] Applied delta record with lsn=e9n10 ts=2021-09-17 02:14:36.350
I0917 02:14:36.368371    4901 [ld:srv:WB3] EventLogStateMachine.cpp:93] publishRebuildingSet() [eventlog] Published new EventLogRebuildingSet version (38654705674)
I0917 02:14:36.370654    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:777] scheduleRestartForShard() Scheduling a restart for shard 0 after 1ms
I0917 02:14:36.374091    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1036] writeRemoveMaintenance() Remove maintenance request for shard 0, reason=Shard came back with data intact
I0917 02:14:36.375925    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1869] abortForMyShard() Request to abort rebuilding of my shard 0 because: data is intact. But shard is dirty. Downgrading to time ranged rebuild.
I0917 02:14:36.378966    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1871] abortForMyShard() EventLogRebuildingSet NodeInfo: [A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:36.381312    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1872] abortForMyShard() Local dirty ranges: [A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}]
I0917 02:14:36.386434    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:1880] abortForMyShard() Cluster already rebuilding the correct dirty ranges for my shard 0. Converting abort into no-op.
I0917 02:14:36.389430    4901 [ld:srv:WB3] RebuildingCoordinator.cpp:683] trySlideGlobalWindow() Moving global window from +inf to -inf for shard 0 and rebuilding set N0:S0[A:{{[2021-09-17 02:09:59.859,2021-09-17 02:10:29.859]}}],N1:S0[A:{{[2021-09-17 02:10:00.092,2021-09-17 02:10:30.092]}}],N2:S0[A:{{[2021-09-17 02:10:00.550,2021-09-17 02:10:30.550]}}],N3:S0[A:{{[2021-09-17 02:09:59.666,2021-09-17 02:10:29.666]}}],N4:S0[A:{{[2021-09-17 02:10:00.337,2021-09-17 02:10:30.337]}}]
I0917 02:14:36.397841    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n29 ts=2021-09-17 02:14:36.353 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.405460    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n30 ts=2021-09-17 02:14:36.358 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.407350    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n31
I0917 02:14:36.411008    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n31 ts=2021-09-17 02:14:36.362 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.413536    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n32 ts=2021-09-17 02:14:36.375 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.425460    4901 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n31
I0917 02:14:36.429996    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n33 ts=2021-09-17 02:14:36.412 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.432908    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n34 ts=2021-09-17 02:14:36.412 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.435088    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n35 ts=2021-09-17 02:14:36.417 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.450901    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n36
I0917 02:14:36.456465    4901 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n36
I0917 02:14:36.458917    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n36 ts=2021-09-17 02:14:36.429 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.460909    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n37 ts=2021-09-17 02:14:36.433 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.466534    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n38 ts=2021-09-17 02:14:36.453 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.475297    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n39
I0917 02:14:36.480469    4901 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n39
I0917 02:14:36.484807    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n39 ts=2021-09-17 02:14:36.463 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.504095    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:1179] operator()() [maintenancelog] Successfully wrote delta with lsn e8n40
I0917 02:14:36.507466    4890 [ld:srv:WB1] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [logsconfig] Could not apply delta record with lsn=e6n1 ts=2021-09-17 02:14:36.493 on base with version e2n2: EXISTS, Adding LogGroup with the path "/test_logs" which already exists in the tree!
I0917 02:14:36.513830    4901 [ld:srv:WB3] MaintenanceLogWriter.cpp:55] operator()() Wrote record with lsn e8n40
I0917 02:14:36.516158    4901 [ld:srv:WB3] ReplicatedStateMachine-inl.h:835] onDeltaRecord() [maintenancelog] Could not apply delta record with lsn=e8n40 ts=2021-09-17 02:14:36.496 on base with version e0n1: NOTFOUND, The filter did not match any maintenances
I0917 02:14:36.517847    4886 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N0 changed from STARTING to FULLY_STARTED
I0917 02:14:36.519741    4886 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N1 changed from STARTING to FULLY_STARTED
I0917 02:14:36.521309    4886 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N3 changed from STARTING to FULLY_STARTED
I0917 02:14:36.524949    4886 [ld:srv:WF0] ClusterState.cpp:165] setNodeState() State of N4 changed from STARTING to FULLY_STARTED
